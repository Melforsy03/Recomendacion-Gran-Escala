# Sistema de Recomendaci√≥n en Gran Escala
## Arquitectura de Big Data con HDFS + YARN + Spark + Kafka

### üìã Descripci√≥n del Sistema

Este proyecto configura una infraestructura completa de Big Data que incluye:

- **HDFS (Hadoop Distributed File System)**: Sistema de archivos distribuido
- **YARN (Yet Another Resource Negotiator)**: Gestor de recursos del cluster
- **Apache Spark**: Motor de procesamiento distribuido (versi√≥n 3.4.1)
- **Apache Kafka**: Plataforma de streaming distribuido (versi√≥n 3.5)
- **Zookeeper**: Coordinaci√≥n de servicios distribuidos

### üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAPA DE ALMACENAMIENTO                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ  ‚îÇ  NameNode   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  DataNode   ‚îÇ  (HDFS)               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 CAPA DE GESTI√ìN DE RECURSOS                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ ResourceManager  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ NodeManager  ‚îÇ  (YARN)         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CAPA DE PROCESAMIENTO                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ Spark Master ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Spark Worker ‚îÇ  (Spark 3.4.1)      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CAPA DE STREAMING                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ  ‚îÇ Zookeeper  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ     Kafka      ‚îÇ  (Kafka 3.5)        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üöÄ Inicio R√°pido

#### 1. Levantar todos los servicios

```bash
docker-compose up -d
```

#### 2. Verificar que todos los contenedores est√°n corriendo

```bash
docker-compose ps
```

#### 3. Ejecutar tests de verificaci√≥n

```bash
# Dar permisos de ejecuci√≥n
chmod +x *.sh

# Test de conectividad
./test-connectivity.sh

# Test completo (todos los componentes)
./run-all-tests.sh
```

### üß™ Tests Disponibles

1. **test-connectivity.sh**: Verifica que todos los servicios est√°n accesibles
2. **test-hdfs.sh**: Prueba operaciones b√°sicas de HDFS
3. **test-kafka.sh**: Prueba producci√≥n y consumo de mensajes en Kafka
4. **test-spark-standalone.sh**: Ejecuta un job de prueba en Spark
5. **test-spark-kafka.sh**: Prueba la integraci√≥n Spark Streaming + Kafka
6. **run-all-tests.sh**: Ejecuta todos los tests anteriores

### üåê Interfaces Web

Una vez que los servicios est√©n corriendo, puedes acceder a las siguientes interfaces:

- **HDFS NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **YARN NodeManager**: http://localhost:8042
- **Spark Master**: http://localhost:8080
- **Spark Worker**: http://localhost:8081
- **Spark Application UI**: http://localhost:4040 (cuando hay una app corriendo)

### üîå Puertos de Servicios

| Servicio | Puerto | Descripci√≥n |
|----------|--------|-------------|
| HDFS NameNode | 9000 | RPC |
| HDFS NameNode | 9870 | Web UI |
| YARN ResourceManager | 8032 | RPC |
| YARN ResourceManager | 8088 | Web UI |
| YARN NodeManager | 8042 | Web UI |
| Spark Master | 7077 | RPC |
| Spark Master | 8080 | Web UI |
| Spark Worker | 8081 | Web UI |
| Kafka (Internal) | 9092 | Bootstrap Server |
| Kafka (External) | 9093 | External Access |
| Zookeeper | 2181 | Client Port |

### üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ docker-compose.yml          # Configuraci√≥n de servicios
‚îú‚îÄ‚îÄ hadoop-conf/                # Configuraciones de Hadoop/YARN
‚îÇ   ‚îú‚îÄ‚îÄ core-site.xml
‚îÇ   ‚îú‚îÄ‚îÄ hdfs-site.xml
‚îÇ   ‚îî‚îÄ‚îÄ yarn-site.xml
‚îú‚îÄ‚îÄ shared/                     # Directorio compartido entre contenedores
‚îú‚îÄ‚îÄ test-connectivity.sh        # Test de conectividad
‚îú‚îÄ‚îÄ test-hdfs.sh               # Test de HDFS
‚îú‚îÄ‚îÄ test-kafka.sh              # Test de Kafka
‚îú‚îÄ‚îÄ test-spark-standalone.sh   # Test de Spark
‚îú‚îÄ‚îÄ test-spark-kafka.sh        # Test de integraci√≥n Spark+Kafka
‚îî‚îÄ‚îÄ run-all-tests.sh           # Ejecuta todos los tests
```

### üîß Comandos √ötiles

#### Docker Compose

```bash
# Iniciar servicios
docker-compose up -d

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio espec√≠fico
docker-compose logs -f spark-master

# Detener servicios
docker-compose down

# Detener y eliminar vol√∫menes (limpieza completa)
docker-compose down -v

# Reiniciar un servicio espec√≠fico
docker-compose restart spark-master
```

#### HDFS

```bash
# Listar archivos en HDFS
docker exec namenode hadoop fs -ls /

# Crear directorio
docker exec namenode hadoop fs -mkdir -p /data

# Subir archivo
docker exec namenode hadoop fs -put /shared/archivo.txt /data/

# Descargar archivo
docker exec namenode hadoop fs -get /data/archivo.txt /shared/

# Ver contenido de archivo
docker exec namenode hadoop fs -cat /data/archivo.txt

# Obtener estad√≠sticas
docker exec namenode hadoop fs -df -h
```

#### Kafka

```bash
# Listar topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Crear topic
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 3 \
    --topic mi-topic

# Describir topic
docker exec kafka kafka-topics --describe \
    --bootstrap-server localhost:9092 \
    --topic mi-topic

# Producir mensajes (interactivo)
docker exec -it kafka kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic mi-topic

# Consumir mensajes
docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic mi-topic \
    --from-beginning
```

#### Spark

```bash
# Enviar job a Spark (modo standalone)
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    --class org.apache.spark.examples.SparkPi \
    /opt/spark/examples/jars/spark-examples_2.12-3.4.1.jar \
    10

# Abrir Spark Shell
docker exec -it spark-master spark-shell \
    --master spark://spark-master:7077

# Abrir PySpark
docker exec -it spark-master pyspark \
    --master spark://spark-master:7077

# Enviar job Python
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    /shared/mi_script.py

# Enviar job con dependencias de Kafka (requiere root para descargar dependencias)
docker exec -u root spark-master spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 \
    /shared/mi_script_kafka.py
```

### üí° Ejemplo: Spark Streaming con Kafka

```python
from pyspark.sql import SparkSession

# Crear SparkSession
spark = SparkSession.builder \
    .appName("KafkaSparkStreaming") \
    .master("spark://spark-master:7077") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1") \
    .getOrCreate()

# Leer desde Kafka
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "mi-topic") \
    .option("startingOffsets", "earliest") \
    .load()

# Procesar datos
messages = df.selectExpr("CAST(value AS STRING)")

# Escribir a consola
query = messages \
    .writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

query.awaitTermination()
```

### üõ†Ô∏è Configuraci√≥n de Recursos

Los recursos asignados est√°n configurados en `docker-compose.yml`:

- **YARN NodeManager**: 4GB RAM, 2 vCPUs
- **Spark Worker**: 2GB RAM, 2 Cores
- **Kafka**: 3 particiones por defecto, replicaci√≥n factor 1

Puedes ajustar estos valores modificando las variables de entorno en el archivo `docker-compose.yml`.

### üîç Soluci√≥n de Problemas

#### Los contenedores no inician

```bash
# Ver logs detallados
docker-compose logs

# Verificar recursos del sistema
docker stats

# Limpiar y reiniciar
docker-compose down -v
docker-compose up -d
```

#### Problemas de conectividad

```bash
# Verificar que todos los servicios est√°n en la misma red
docker network inspect recomendacion-gran-escala_datapipeline

# Verificar DNS interno
docker exec spark-master ping namenode
docker exec spark-master ping kafka
```

#### HDFS no est√° accesible

```bash
# Verificar estado de NameNode
docker exec namenode hdfs dfsadmin -report

# Verificar logs
docker-compose logs namenode
docker-compose logs datanode
```

### üìä Monitoreo

Para monitorear el sistema, accede a las interfaces web:

1. **HDFS**: Verifica el estado del cluster, espacio disponible, y bloques
2. **YARN**: Monitorea aplicaciones corriendo, recursos utilizados
3. **Spark**: Verifica jobs activos, executors, y m√©tricas de rendimiento

### üö¢ Crear Imagen Docker Personalizada

Si necesitas crear una imagen personalizada con configuraciones adicionales:

```bash
# Crear Dockerfile para Spark personalizado
cat > Dockerfile.spark << 'EOF'
FROM bitnami/spark:3.4.1

USER root

# Instalar dependencias adicionales
RUN pip install kafka-python pandas numpy

# Copiar scripts personalizados
COPY ./scripts /opt/spark-scripts

USER 1001
EOF

# Construir imagen
docker build -f Dockerfile.spark -t mi-spark:3.4.1 .

# Actualizar docker-compose.yml para usar la nueva imagen
# Cambiar: image: bitnami/spark:3.4.1
# Por: image: mi-spark:3.4.1
```

### üìù Pr√≥ximos Pasos

1. ‚úÖ Verificar que todos los servicios est√°n corriendo
2. ‚úÖ Ejecutar los tests de conectividad y funcionalidad
3. ‚è≠Ô∏è Desarrollar tu sistema de recomendaci√≥n
4. ‚è≠Ô∏è Implementar pipelines de procesamiento de datos
5. ‚è≠Ô∏è Configurar Spark Streaming para datos en tiempo real
6. ‚è≠Ô∏è Optimizar configuraciones seg√∫n tus necesidades

### üìö Recursos Adicionales

- [Documentaci√≥n de Hadoop](https://hadoop.apache.org/docs/)
- [Documentaci√≥n de Spark](https://spark.apache.org/docs/latest/)
- [Documentaci√≥n de Kafka](https://kafka.apache.org/documentation/)
- [Spark Structured Streaming + Kafka Guide](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)

### ü§ù Contribuciones

Este es un proyecto educativo para sistemas de recomendaci√≥n en gran escala. Si√©ntete libre de adaptarlo a tus necesidades.

### üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible bajo la licencia MIT.

## üß† Sistema de Recomendaci√≥n a Gran Escala (Streaming + Dashboard)

Esta repo incluye un pipeline de referencia para recomendaciones y m√©tricas en tiempo real usando el dataset de ejemplo `movies/data/raw/movies.json`:

Arquitectura l√≥gica:

```text
Kafka topic 'events'  <-- productor simulado (recomendaciones + interacciones)
           ‚îÇ
           ‚ñº
Spark Structured Streaming (metrics_streaming.py)
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚ñ∫ Kafka topic 'metrics' (acceptance_rate, precision, active_users, engagement, top_products)
           ‚ñº
API FastAPI (WebSocket/REST) ‚îÄ‚îÄ‚îÄ‚ñ∫ Dashboard (Chart.js)
```

### C√≥mo ejecutarlo

1) Inicia la infraestructura:

```bash
./scripts/start-system.sh
```

1) Lanza el job de m√©tricas (Spark Streaming):

```bash
./scripts/run-streaming-metrics.sh
```

1) Arranca el productor de eventos (host):

```bash
./scripts/run-producer-events.sh
```

1) Abre el dashboard en tu navegador:

- API + Dashboard: <http://localhost:8000>

Ver√°s en tiempo real:

- Tasa de aceptaci√≥n (CTR) y precisi√≥n (proxy)
- Productos m√°s sugeridos (Top 10)
- Usuarios activos por minuto
- Impacto en engagement (eventos promedio por usuario)

Notas:

- El t√≥pico Kafka `events` se auto-crea al enviar los primeros mensajes.
- El job publica m√©tricas en `metrics`; la API las consume y hace broadcast por WebSocket.
