# Sistema de RecomendaciÃ³n en Gran Escala
## Arquitectura de Big Data con HDFS + YARN + Spark + Kafka

### ðŸ“‹ DescripciÃ³n del Sistema

Este proyecto configura una infraestructura completa de Big Data que incluye:

- **HDFS (Hadoop Distributed File System)**: Sistema de archivos distribuido
- **YARN (Yet Another Resource Negotiator)**: Gestor de recursos del cluster
- **Apache Spark**: Motor de procesamiento distribuido (versiÃ³n 3.4.1)
- **Apache Kafka**: Plataforma de streaming distribuido (versiÃ³n 3.5)
- **Zookeeper**: CoordinaciÃ³n de servicios distribuidos

### ðŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA DE ALMACENAMIENTO                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚  NameNode   â”‚â”€â”€â”€â”€â”€â”€â”‚  DataNode   â”‚  (HDFS)               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAPA DE GESTIÃ“N DE RECURSOS                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ ResourceManager  â”‚â”€â”€â”€â”€â”€â”€â”‚ NodeManager  â”‚  (YARN)         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CAPA DE PROCESAMIENTO                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Spark Master â”‚â”€â”€â”€â”€â”€â”€â”‚ Spark Worker â”‚  (Spark 3.4.1)      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CAPA DE STREAMING                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Zookeeper  â”‚â”€â”€â”€â”€â”€â”€â”‚     Kafka      â”‚  (Kafka 3.5)        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸš€ Inicio RÃ¡pido

#### 1. Levantar todos los servicios

```bash
docker-compose up -d
```

#### 2. Verificar que todos los contenedores estÃ¡n corriendo

```bash
docker-compose ps
```

#### 3. Ejecutar tests de verificaciÃ³n

```bash
# Dar permisos de ejecuciÃ³n
chmod +x *.sh

# Test de conectividad
./test-connectivity.sh

# Test completo (todos los componentes)
./run-all-tests.sh
```

### ðŸ§ª Tests Disponibles

1. **test-connectivity.sh**: Verifica que todos los servicios estÃ¡n accesibles
2. **test-hdfs.sh**: Prueba operaciones bÃ¡sicas de HDFS
3. **test-kafka.sh**: Prueba producciÃ³n y consumo de mensajes en Kafka
4. **test-spark-standalone.sh**: Ejecuta un job de prueba en Spark
5. **test-spark-kafka.sh**: Prueba la integraciÃ³n Spark Streaming + Kafka
6. **run-all-tests.sh**: Ejecuta todos los tests anteriores

### ðŸŒ Interfaces Web

Una vez que los servicios estÃ©n corriendo, puedes acceder a las siguientes interfaces:

- **HDFS NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **YARN NodeManager**: http://localhost:8042
- **Spark Master**: http://localhost:8080
- **Spark Worker**: http://localhost:8081
- **Spark Application UI**: http://localhost:4040 (cuando hay una app corriendo)

### ðŸ”Œ Puertos de Servicios

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| HDFS NameNode | 9000 | RPC |
| HDFS NameNode | 9870 | Web UI |
| YARN ResourceManager | 8032 | RPC |
| YARN ResourceManager | 8088 | Web UI |
| YARN NodeManager | 8042 | Web UI |
| Spark Master | 7077 | RPC |
| Spark Master | 8080 | Web UI |
| Spark Worker | 8081 | Web UI |
| Kafka (Internal) | 9092 | Bootstrap Server |
| Kafka (External) | 9093 | External Access |
| Zookeeper | 2181 | Client Port |

### ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ docker-compose.yml          # ConfiguraciÃ³n de servicios
â”œâ”€â”€ hadoop-conf/                # Configuraciones de Hadoop/YARN
â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â””â”€â”€ yarn-site.xml
â”œâ”€â”€ shared/                     # Directorio compartido entre contenedores
â”œâ”€â”€ test-connectivity.sh        # Test de conectividad
â”œâ”€â”€ test-hdfs.sh               # Test de HDFS
â”œâ”€â”€ test-kafka.sh              # Test de Kafka
â”œâ”€â”€ test-spark-standalone.sh   # Test de Spark
â”œâ”€â”€ test-spark-kafka.sh        # Test de integraciÃ³n Spark+Kafka
â””â”€â”€ run-all-tests.sh           # Ejecuta todos los tests
```

### ðŸ”§ Comandos Ãštiles

#### Docker Compose

```bash
# Iniciar servicios
docker-compose up -d

# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio especÃ­fico
docker-compose logs -f spark-master

# Detener servicios
docker-compose down

# Detener y eliminar volÃºmenes (limpieza completa)
docker-compose down -v

# Reiniciar un servicio especÃ­fico
docker-compose restart spark-master
```

#### HDFS

```bash
# Listar archivos en HDFS
docker exec namenode hadoop fs -ls /

# Crear directorio
docker exec namenode hadoop fs -mkdir -p /data

# Subir archivo
docker exec namenode hadoop fs -put /shared/archivo.txt /data/

# Descargar archivo
docker exec namenode hadoop fs -get /data/archivo.txt /shared/

# Ver contenido de archivo
docker exec namenode hadoop fs -cat /data/archivo.txt

# Obtener estadÃ­sticas
docker exec namenode hadoop fs -df -h
```

#### Kafka

```bash
# Listar topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Crear topic
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --replication-factor 1 \
    --partitions 3 \
    --topic mi-topic

# Describir topic
docker exec kafka kafka-topics --describe \
    --bootstrap-server localhost:9092 \
    --topic mi-topic

# Producir mensajes (interactivo)
docker exec -it kafka kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic mi-topic

# Consumir mensajes
docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic mi-topic \
    --from-beginning
```

#### Spark

```bash
# Enviar job a Spark (modo standalone)
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    --class org.apache.spark.examples.SparkPi \
    /opt/spark/examples/jars/spark-examples_2.12-3.4.1.jar \
    10

# Abrir Spark Shell
docker exec -it spark-master spark-shell \
    --master spark://spark-master:7077

# Abrir PySpark
docker exec -it spark-master pyspark \
    --master spark://spark-master:7077

# Enviar job Python
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    /shared/mi_script.py

# Enviar job con dependencias de Kafka (requiere root para descargar dependencias)
docker exec -u root spark-master spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 \
    /shared/mi_script_kafka.py
```

### ðŸ’¡ Ejemplo: Spark Streaming con Kafka

```python
from pyspark.sql import SparkSession

# Crear SparkSession
spark = SparkSession.builder \
    .appName("KafkaSparkStreaming") \
    .master("spark://spark-master:7077") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1") \
    .getOrCreate()

# Leer desde Kafka
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "mi-topic") \
    .option("startingOffsets", "earliest") \
    .load()

# Procesar datos
messages = df.selectExpr("CAST(value AS STRING)")

# Escribir a consola
query = messages \
    .writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

query.awaitTermination()
```

### ðŸ› ï¸ ConfiguraciÃ³n de Recursos

Los recursos asignados estÃ¡n configurados en `docker-compose.yml`:

- **YARN NodeManager**: 4GB RAM, 2 vCPUs
- **Spark Worker**: 2GB RAM, 2 Cores
- **Kafka**: 3 particiones por defecto, replicaciÃ³n factor 1

Puedes ajustar estos valores modificando las variables de entorno en el archivo `docker-compose.yml`.

### ðŸ” SoluciÃ³n de Problemas

#### Los contenedores no inician

```bash
# Ver logs detallados
docker-compose logs

# Verificar recursos del sistema
docker stats

# Limpiar y reiniciar
docker-compose down -v
docker-compose up -d
```

#### Problemas de conectividad

```bash
# Verificar que todos los servicios estÃ¡n en la misma red
docker network inspect recomendacion-gran-escala_datapipeline

# Verificar DNS interno
docker exec spark-master ping namenode
docker exec spark-master ping kafka
```

#### HDFS no estÃ¡ accesible

```bash
# Verificar estado de NameNode
docker exec namenode hdfs dfsadmin -report

# Verificar logs
docker-compose logs namenode
docker-compose logs datanode
```

### ðŸ“Š Monitoreo

Para monitorear el sistema, accede a las interfaces web:

1. **HDFS**: Verifica el estado del cluster, espacio disponible, y bloques
2. **YARN**: Monitorea aplicaciones corriendo, recursos utilizados
3. **Spark**: Verifica jobs activos, executors, y mÃ©tricas de rendimiento

### ðŸš¢ Crear Imagen Docker Personalizada

Si necesitas crear una imagen personalizada con configuraciones adicionales:

```bash
# Crear Dockerfile para Spark personalizado
cat > Dockerfile.spark << 'EOF'
FROM bitnami/spark:3.4.1

USER root

# Instalar dependencias adicionales
RUN pip install kafka-python pandas numpy

# Copiar scripts personalizados
COPY ./scripts /opt/spark-scripts

USER 1001
EOF

# Construir imagen
docker build -f Dockerfile.spark -t mi-spark:3.4.1 .

# Actualizar docker-compose.yml para usar la nueva imagen
# Cambiar: image: bitnami/spark:3.4.1
# Por: image: mi-spark:3.4.1
```

### ðŸ“ PrÃ³ximos Pasos

1. âœ… Verificar que todos los servicios estÃ¡n corriendo
2. âœ… Ejecutar los tests de conectividad y funcionalidad
3. â­ï¸ Desarrollar tu sistema de recomendaciÃ³n
4. â­ï¸ Implementar pipelines de procesamiento de datos
5. â­ï¸ Configurar Spark Streaming para datos en tiempo real
6. â­ï¸ Optimizar configuraciones segÃºn tus necesidades

### ðŸ“š Recursos Adicionales

- [DocumentaciÃ³n de Hadoop](https://hadoop.apache.org/docs/)
- [DocumentaciÃ³n de Spark](https://spark.apache.org/docs/latest/)
- [DocumentaciÃ³n de Kafka](https://kafka.apache.org/documentation/)
- [Spark Structured Streaming + Kafka Guide](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)

### ðŸ¤ Contribuciones

Este es un proyecto educativo para sistemas de recomendaciÃ³n en gran escala. SiÃ©ntete libre de adaptarlo a tus necesidades.

### ðŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.
