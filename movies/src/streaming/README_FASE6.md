# FASE 6: Topics Kafka y Esquema de Eventos

## üìã Objetivo

Configurar la infraestructura de streaming con Kafka para el sistema de recomendaciones en tiempo real:
- Crear topics de Kafka para ratings y m√©tricas
- Definir y validar esquema JSON de eventos
- Implementar producer/consumer "hello world" funcional

---

## üéØ Topics Creados

### 1. **ratings** (Input Streaming)
- **Prop√≥sito**: Recibir ratings de usuarios en tiempo real
- **Particiones**: 3
- **Replication Factor**: 1
- **Retention**: 7 d√≠as
- **Compression**: LZ4
- **Key**: userId (para particionamiento consistente)

### 2. **metrics** (Output M√©tricas)
- **Prop√≥sito**: Publicar m√©tricas de streaming (throughput, latencia, RMSE)
- **Particiones**: 1
- **Replication Factor**: 1
- **Retention**: 30 d√≠as
- **Compression**: GZIP

---

## üìê Esquema JSON - Topic `ratings`

```json
{
    "userId": 123,
    "movieId": 456,
    "rating": 4.5,
    "timestamp": 1730232000000
}
```

### Validaciones del Esquema

| Campo | Tipo | Restricciones | Descripci√≥n |
|-------|------|---------------|-------------|
| `userId` | `int` | > 0, rango 1-138493 | ID del usuario √∫nico |
| `movieId` | `int` | > 0, rango 1-27278 | ID de la pel√≠cula √∫nica |
| `rating` | `double` | {0.5, 1.0, 1.5, ..., 5.0} | Rating en escala 0.5-5.0 (incrementos de 0.5) |
| `timestamp` | `long` | > 0 | Unix timestamp en milisegundos |

**Ejemplo v√°lido**:
```json
{
    "userId": 12345,
    "movieId": 1234,
    "rating": 4.5,
    "timestamp": 1730232000000
}
```

**Ejemplo inv√°lido**:
```json
{
    "userId": -1,          // ‚ùå userId debe ser > 0
    "movieId": "abc",      // ‚ùå movieId debe ser int
    "rating": 6.0,         // ‚ùå rating fuera de rango
    "timestamp": "2024"    // ‚ùå timestamp debe ser long
}
```

---

## üõ†Ô∏è Archivos Implementados

```
movies/src/streaming/
‚îú‚îÄ‚îÄ create_kafka_topics.py       # Creaci√≥n de topics con validaci√≥n
‚îú‚îÄ‚îÄ kafka_producer_hello.py      # Producer de prueba (hello world)
‚îî‚îÄ‚îÄ kafka_consumer_hello.py      # Consumer de prueba (hello world)

scripts/
‚îî‚îÄ‚îÄ verify_kafka_phase6.sh       # Script de verificaci√≥n completa

requirements.txt                 # +kafka-python>=2.0.2
```

---

## üöÄ Ejecuci√≥n

### Paso 1: Iniciar Kafka y Zookeeper

```bash
cd /home/abraham/Escritorio/PGVD/Recomendacion-Gran-Escala
docker-compose up -d zookeeper kafka
```

**Esperar ~30 segundos** para que Kafka est√© completamente operativo.

### Paso 2: Instalar Dependencias

```bash
# Instalar kafka-python en contenedores Spark
docker exec -u root spark-master pip install kafka-python>=2.0.2
docker exec -u root spark-worker pip install kafka-python>=2.0.2
```

### Paso 3: Crear Topics

```bash
# Copiar scripts a directorio compartido
mkdir -p shared/streaming
cp movies/src/streaming/*.py shared/streaming/

# Ejecutar creaci√≥n de topics
docker exec spark-master python3 /opt/spark/work-dir/streaming/create_kafka_topics.py
```

**Salida esperada**:
```
‚úÖ Conectado a Kafka en ['kafka:9092']
‚úÖ Topic 'ratings' creado exitosamente
‚úÖ Topic 'metrics' creado exitosamente
```

### Paso 4: Verificar Topics Creados

```bash
# Listar topics
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Describir topic 'ratings'
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ratings
```

**Salida esperada**:
```
Topic: ratings  Partitions: 3  Replication: 1
```

### Paso 5: Producer Hello World

```bash
# Enviar 10 mensajes de prueba
docker exec spark-master python3 /opt/spark/work-dir/streaming/kafka_producer_hello.py --count 10
```

**Salida esperada**:
```
‚úÖ Producer conectado a Kafka en ['kafka:9092']
üì§ Enviando 10 ratings de prueba a topic 'ratings'...

[1/10] Generado:
  {
    "userId": 45678,
    "movieId": 1234,
    "rating": 4.5,
    "timestamp": 1730232000000
  }
‚úÖ Enviado - userId=45678, movieId=1234, rating=4.5 | Partition=2, Offset=0

...

üìä RESUMEN DE ENV√çO
‚úÖ Mensajes enviados: 10
‚ùå Mensajes fallidos: 0
üìà Total: 10
‚è±Ô∏è  Tiempo total: 5.23 segundos
üöÄ Throughput: 1.91 mensajes/seg
‚úì  Tasa de √©xito: 100.0%

‚úÖ PRODUCER HELLO WORLD COMPLETADO EXITOSAMENTE
```

### Paso 6: Consumer Hello World

```bash
# Consumir mensajes (timeout 30s)
docker exec spark-master python3 /opt/spark/work-dir/streaming/kafka_consumer_hello.py --max-messages 10
```

**Salida esperada**:
```
‚úÖ Consumer conectado a Kafka en ['kafka:9092']
   Topic: ratings
   Group ID: ratings-consumer-hello-world

üì• Consumiendo mensajes del topic 'ratings'...

‚úÖ Mensaje recibido:
   Partition: 2, Offset: 0
   Key: 45678
   Timestamp: 2024-10-29 15:20:00
   Value: {
      "userId": 45678,
      "movieId": 1234,
      "rating": 4.5,
      "timestamp": 1730232000000
   }

...

üìä RESUMEN DE CONSUMO
üìà Mensajes procesados:
   Total: 10
   V√°lidos: 10 (100.0%)
   Inv√°lidos: 0

‚≠ê Distribuci√≥n de ratings:
   4.5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (3)
   5.0: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (2)
   ...

‚úÖ CONSUMER HELLO WORLD COMPLETADO EXITOSAMENTE
```

---

## ‚úÖ Verificaci√≥n Completa (Script Automatizado)

```bash
# Ejecutar script de verificaci√≥n completa
./scripts/verify_kafka_phase6.sh
```

Este script ejecuta autom√°ticamente:
1. ‚úÖ Verificar Zookeeper y Kafka
2. ‚úÖ Instalar dependencias Python
3. ‚úÖ Crear topics
4. ‚úÖ Listar y describir topics
5. ‚úÖ Ejecutar producer (10 mensajes)
6. ‚úÖ Ejecutar consumer (leer mensajes)
7. ‚úÖ Verificar offsets

**Salida final esperada**:
```
‚úÖ FASE 6 COMPLETADA EXITOSAMENTE

Pr√≥ximos pasos:
  - Fase 7: Streaming de recomendaciones con Spark Structured Streaming
  - Fase 8: Dashboard en tiempo real con m√©tricas
```

---

## üîç Comandos √ötiles de Kafka

### Listar Topics
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

### Describir Topic
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ratings
```

### Ver Mensajes en Topic (desde el inicio)
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ratings \
  --from-beginning \
  --max-messages 10
```

### Ver Offsets de Particiones
```bash
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic ratings
```

### Eliminar Topic (si es necesario)
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic ratings
```

### Consumir con Consumer Group
```bash
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ratings \
  --group my-consumer-group \
  --from-beginning
```

### Ver Consumer Groups
```bash
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
```

### Describir Consumer Group
```bash
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group ratings-consumer-hello-world
```

---

## üìä M√©tricas y Monitoreo

### Ver Logs de Kafka
```bash
docker logs kafka --tail 100 -f
```

### Ver Logs de Zookeeper
```bash
docker logs zookeeper --tail 100 -f
```

### Verificar Conectividad
```bash
# Desde host
telnet localhost 9093

# Desde contenedor Spark
docker exec spark-master telnet kafka 9092
```

---

## üêõ Troubleshooting

### Problema: Topics no se crean

**S√≠ntoma**:
```
‚ùå Error creando topic 'ratings': TimeoutError
```

**Soluci√≥n**:
```bash
# 1. Verificar que Kafka est√© corriendo
docker ps | grep kafka

# 2. Ver logs de Kafka
docker logs kafka --tail 50

# 3. Reiniciar Kafka
docker-compose restart kafka

# 4. Esperar ~30s y reintentar
```

### Problema: Producer no puede conectar

**S√≠ntoma**:
```
‚ùå Error creando producer: NoBrokersAvailable
```

**Soluci√≥n**:
```bash
# Verificar que Kafka est√© aceptando conexiones
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092

# Verificar advertised.listeners
docker exec kafka env | grep KAFKA_ADVERTISED_LISTENERS
```

### Problema: Consumer no recibe mensajes

**S√≠ntoma**:
```
‚è±Ô∏è  Timeout: 30s sin mensajes nuevos
```

**Soluci√≥n**:
```bash
# 1. Verificar que hay mensajes en el topic
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic ratings

# 2. Resetear consumer group offset
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group ratings-consumer-hello-world \
  --reset-offsets \
  --to-earliest \
  --topic ratings \
  --execute

# 3. Reintentar consumo
```

### Problema: kafka-python no instalado

**S√≠ntoma**:
```
ModuleNotFoundError: No module named 'kafka'
```

**Soluci√≥n**:
```bash
# Instalar en contenedores
docker exec -u root spark-master pip install kafka-python
docker exec -u root spark-worker pip install kafka-python
```

---

## üìö Pr√≥ximos Pasos

### Fase 7: Streaming de Recomendaciones
- Spark Structured Streaming consumiendo topic `ratings`
- Generaci√≥n de recomendaciones en tiempo real usando modelo ALS
- Publicaci√≥n de m√©tricas en topic `metrics`

### Fase 8: Dashboard de M√©tricas
- Consumir topic `metrics` en API REST
- Dashboard en tiempo real con throughput, latencia, RMSE
- Visualizaci√≥n de distribuci√≥n de ratings

---

## ‚úÖ Criterios de Aceptaci√≥n

- [x] Topics `ratings` y `metrics` creados y visibles en Kafka
- [x] Esquema JSON definido y documentado
- [x] Producer hello world funcional (env√≠a mensajes v√°lidos)
- [x] Consumer hello world funcional (consume y valida mensajes)
- [x] Validaci√≥n de esquema implementada
- [x] Script de verificaci√≥n automatizado
- [x] Documentaci√≥n completa con ejemplos

---

**Documentado**: 29 de octubre de 2025  
**Siguiente fase**: Streaming con Spark Structured Streaming
