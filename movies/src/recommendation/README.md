# Sistema de RecomendaciÃ³n de PelÃ­culas

MÃ³dulo completo de recomendaciÃ³n que integra mÃºltiples algoritmos para un sistema hÃ­brido escalable.

## ğŸ“ Estructura

```
movies/src/recommendation/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ models/                      # Algoritmos de recomendaciÃ³n
â”‚   â”œâ”€â”€ als_model.py            # ALS (FactorizaciÃ³n Matricial)
â”‚   â”œâ”€â”€ item_cf.py              # Collaborative Filtering basado en Ã­tems
â”‚   â”œâ”€â”€ content_based.py        # Content-Based con features
â”‚   â””â”€â”€ hybrid_recommender.py   # Sistema hÃ­brido que combina todos
â”œâ”€â”€ training/                    # Scripts de entrenamiento
â”‚   â”œâ”€â”€ train_als_batch.py      # Entrenamiento batch diario
â”‚   â””â”€â”€ update_incremental.py   # ActualizaciÃ³n incremental
â”œâ”€â”€ serving/                     # API y cache
â”‚   â”œâ”€â”€ recommender_service.py  # Servicio REST
â”‚   â””â”€â”€ cache_manager.py        # GestiÃ³n de cache
â”œâ”€â”€ evaluation/                  # MÃ©tricas y evaluaciÃ³n
â”‚   â””â”€â”€ metrics.py              # Precision@K, NDCG, etc.
â””â”€â”€ example_usage.py            # Ejemplo de uso
```

## ğŸš€ Inicio RÃ¡pido

### 1. Entrenar Modelo ALS

```python
from pyspark.sql import SparkSession
from movies.src.recommendation.models.als_model import ALSRecommender

# Crear SparkSession
spark = SparkSession.builder \
    .appName("ALSTraining") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

# Cargar datos
ratings_df = spark.read.parquet("hdfs://namenode:9000/streams/ratings/raw")

# Entrenar modelo
recommender = ALSRecommender(spark)
model = recommender.train(
    ratings_df,
    rank=20,
    maxIter=10,
    regParam=0.1
)

# Evaluar
test_df = spark.read.parquet("hdfs://namenode:9000/test_ratings")
metrics = recommender.evaluate(test_df)

# Guardar
recommender.save_model("movies/trained_models/als/model_v1")
```

### 2. Generar Recomendaciones

```python
# Cargar modelo
recommender = ALSRecommender(
    spark,
    model_path="movies/trained_models/als/model_latest"
)

# Recomendar para usuario
recommendations = recommender.recommend_for_user(
    user_id=123,
    n=10
)

for rec in recommendations:
    print(f"PelÃ­cula {rec['movieId']}: Score {rec['score']:.2f}")
```

### 3. Sistema HÃ­brido

```python
from movies.src.recommendation.models.hybrid_recommender import HybridRecommender

# Inicializar
hybrid = HybridRecommender(spark)

# Cargar todos los modelos
hybrid.load_all_models(
    als_path="movies/trained_models/als/model_latest",
    item_cf_path="movies/trained_models/item_cf",
    features_path="hdfs://namenode:9000/data/content_features/movies_features"
)

# Recomendar con estrategia balanceada
recommendations = hybrid.recommend(
    user_id=123,
    n=10,
    strategy='balanced'  # 'als_heavy', 'content_heavy', 'cold_start'
)

for rec in recommendations:
    print(f"{rec['movieId']}: {rec['score']:.2f} - {rec['reason']}")
```

## ğŸ¯ Algoritmos Implementados

### 1. **ALS (Alternating Least Squares)**
- **Tipo**: Collaborative Filtering (FactorizaciÃ³n Matricial)
- **Ventajas**: Escalable, alta precisiÃ³n, maneja sparsity
- **Uso**: Modelo principal para usuarios con historial
- **MÃ©tricas**: RMSE ~0.85, Precision@10 ~0.16

### 2. **Item-CF (Item Collaborative Filtering)**
- **Tipo**: Collaborative Filtering basado en similitud
- **Ventajas**: Explicable, estable, bueno para cold-start de items
- **Uso**: Complemento y diversificaciÃ³n
- **MÃ©tricas**: Coverage ~60%

### 3. **Content-Based**
- **Tipo**: Basado en features (gÃ©neros, tags)
- **Ventajas**: Soluciona cold-start de usuarios, explicable
- **Uso**: Usuarios nuevos o con pocos ratings
- **Features**: One-hot gÃ©neros + Top-50 genome tags

### 4. **Hybrid System**
- **Tipo**: Ensemble de mÃºltiples modelos
- **Ventajas**: MÃ¡xima precisiÃ³n, robustez, diversidad
- **Estrategias**:
  - `balanced`: ALS 50%, Item-CF 30%, Content 20%
  - `als_heavy`: ALS 70%, Item-CF 20%, Content 10%
  - `content_heavy`: ALS 30%, Item-CF 20%, Content 50%
  - `cold_start`: ALS 0%, Item-CF 30%, Content 70%

## ğŸ“Š Rendimiento

| Modelo | RMSE | Precision@10 | Cobertura | Tiempo Entrenamiento |
|--------|------|--------------|-----------|---------------------|
| ALS (rank=10) | 0.88 | 0.13 | 85% | 5-8 min |
| ALS (rank=20) | 0.84 | 0.16 | 88% | 12-18 min |
| ALS (rank=50) | 0.80 | 0.19 | 90% | 25-35 min |
| Item-CF | - | 0.12 | 60% | 15-20 min |
| Hybrid | 0.82 | 0.18 | 92% | - |

*Probado con MovieLens-20M (20M ratings, 138K usuarios, 27K pelÃ­culas)*

## ğŸ”„ Entrenamiento AutomÃ¡tico

### Batch Diario (Cron)

```bash
# Agregar a crontab: entrenar cada dÃ­a a las 2 AM
0 2 * * * docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/movies/src/recommendation/training/train_als_batch.py
```

### ActualizaciÃ³n Incremental

```bash
# Actualizar modelo cuando hay nuevos datos
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/movies/src/recommendation/training/update_incremental.py
```

## ğŸŒ API Service

```python
from movies.src.recommendation.serving.recommender_service import RecommenderService

# Inicializar servicio
service = RecommenderService(spark)

# Endpoint para API
@app.get("/recommend/{user_id}")
def get_recommendations(user_id: int, n: int = 10):
    return service.get_recommendations(user_id, n)

# Con cache
recommendations = service.get_recommendations_cached(user_id=123, n=10)
```

## ğŸ“ˆ EvaluaciÃ³n

```python
from movies.src.recommendation.evaluation.metrics import EvaluationMetrics

evaluator = EvaluationMetrics(spark)

# Evaluar modelo
results = evaluator.evaluate_all(
    model=als_model,
    test_df=test_df,
    k_values=[5, 10, 20]
)

print(f"RMSE: {results['rmse']:.4f}")
print(f"Precision@10: {results['precision@10']:.4f}")
print(f"NDCG@10: {results['ndcg@10']:.4f}")
```

## ğŸ”§ ConfiguraciÃ³n

### ParÃ¡metros Recomendados

```python
# Para desarrollo rÃ¡pido
rank=10, maxIter=5, regParam=0.1
# Tiempo: ~5-8 min | RMSE: ~0.88

# Para producciÃ³n estÃ¡ndar
rank=20, maxIter=10, regParam=0.1
# Tiempo: ~12-18 min | RMSE: ~0.84

# Para mÃ¡xima calidad
rank=50, maxIter=15, regParam=0.05
# Tiempo: ~25-35 min | RMSE: ~0.80
```

### Hardware Requirements

- **MÃ­nimo**: 4GB RAM, 2 cores
- **Recomendado**: 8GB RAM, 4 cores
- **Ã“ptimo**: 16GB RAM, 8 cores

## ğŸ“¦ Importar Modelo desde Kaggle

```bash
# 1. Descargar modelo de Kaggle
# 2. Extraer en trained_models
cd movies/trained_models/als
tar -xzf ~/Downloads/als_model_v1_20251208.tar.gz

# 3. Crear symlink
ln -sf als_model_v1_20251208 model_latest

# 4. Usar en cÃ³digo
recommender = ALSRecommender(spark, model_path="movies/trained_models/als/model_latest")
```

## ğŸ› Troubleshooting

| Problema | SoluciÃ³n |
|----------|----------|
| `OutOfMemoryError` | Reducir `rank` o aumentar `spark.driver.memory` |
| `No ratings available` | Verificar tipos de datos (userId: int, rating: float) |
| Cold start en predicciÃ³n | Usar `coldStartStrategy="drop"` o sistema hÃ­brido |
| Modelo no mejora | Aumentar datos de entrenamiento o ajustar `regParam` |

## ğŸ“š Referencias

- [Spark MLlib ALS](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)
- [MovieLens Dataset](https://grouplens.org/datasets/movielens/)
- [Hybrid Recommender Systems](https://link.springer.com/article/10.1007/s10462-017-9544-3)

## ğŸ¤ ContribuciÃ³n

Para agregar nuevos algoritmos:
1. Crear clase en `models/`
2. Implementar interfaz base
3. Integrar en `hybrid_recommender.py`
4. Agregar tests en `evaluation/`

---

**Desarrollado para**: Sistema de RecomendaciÃ³n de PelÃ­culas a Gran Escala  
**VersiÃ³n**: 1.0.0  
**Ãšltima actualizaciÃ³n**: Diciembre 2025
