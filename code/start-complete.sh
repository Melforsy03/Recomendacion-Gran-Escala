#!/bin/bash

echo "ğŸš€ INICIANDO SISTEMA BIG DATA COMPLETO (HDFS + YARN + Spark + Kafka)"

# Limpiar
docker compose down

# Crear directorios necesarios
mkdir -p hadoop-data
mkdir -p spark-config
cp movies.json hadoop-data/ 2>/dev/null || echo "âš ï¸ movies.json ya copiado"

# Construir imÃ¡genes
echo "ğŸ”¨ Construyendo imÃ¡genes..."
docker compose build

# Iniciar infraestructura base
echo "ğŸ˜ Iniciando Zookeeper..."
docker compose up -d zookeeper
sleep 20

echo "ğŸ“¢ Iniciando Kafka..."
docker compose up -d kafka
sleep 20

echo "ğŸ—„ï¸  Iniciando HDFS..."
docker compose up -d hadoop-namenode hadoop-datanode
sleep 30

echo "ğŸ”„ Iniciando YARN..."
docker compose up -d hadoop-resourcemanager hadoop-nodemanager
sleep 30

# Inicializar Hadoop
chmod +x init-hadoop-yarn.sh
./init-hadoop-yarn.sh

echo "âš¡ Iniciando Spark..."
docker compose up -d spark-master spark-worker spark-history-server
sleep 25

echo "ğŸ”´ Iniciando aplicaciones..."
docker compose up -d redis dashboard producer consumer batch-processor mapreduce-processor
sleep 20

echo "ğŸ“Š Estado final del sistema:"
docker compose ps

echo ""
echo "ğŸ‰ SISTEMA BIG DATA COMPLETO INICIADO!"
echo ""
echo "ğŸŒ URLs IMPORTANTES:"
echo "   ğŸ“Š Dashboard: http://localhost:8050"
echo "   ğŸ—„ï¸  HDFS: http://localhost:9870"
echo "   ğŸ”„ YARN: http://localhost:8088"
echo "   âš¡ Spark: http://localhost:8080"
echo "   ğŸ“œ Spark History: http://localhost:18080"
echo ""
echo "ğŸ”§ COMANDOS ÃšTILES:"
echo "   Ejecutar MapReduce: docker compose exec mapreduce-processor python mapreduce_processor.py"
echo "   Ver YARN: docker compose exec resourcemanager yarn application -list"
echo "   Ver HDFS: docker compose exec hadoop-namenode hdfs dfs -ls /results/"
echo "   Parar todo: docker compose down"