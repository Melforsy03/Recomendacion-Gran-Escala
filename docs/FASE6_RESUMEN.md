# FASE 6: Topics Kafka y Esquema de Eventos - RESUMEN

## üìã Informaci√≥n General

- **Fase**: 6 - Topics Kafka y Esquema de Eventos
- **Fecha de Ejecuci√≥n**: 29 de octubre de 2025
- **Duraci√≥n**: ~5 minutos (incluyendo pruebas)
- **Estado**: ‚úÖ COMPLETADA Y VERIFICADA

---

## üéØ Objetivos

1. **Crear topics Kafka** para streaming de ratings y m√©tricas
2. **Definir esquema JSON** para eventos de ratings
3. **Implementar producer hello world** para env√≠o de eventos
4. **Implementar consumer hello world** para consumo y validaci√≥n
5. **Verificar infraestructura** de streaming completa

---

## üõ†Ô∏è Implementaci√≥n

### 1. Topics Creados

#### Topic: `ratings` (Input)
```yaml
Prop√≥sito: Recibir ratings de usuarios en tiempo real
Particiones: 6
Replication Factor: 1
Retention: 7 d√≠as (604800000 ms)
Compression: LZ4
Key: userId (para particionamiento consistente)
```

#### Topic: `metrics` (Output)
```yaml
Prop√≥sito: Publicar m√©tricas de streaming
Particiones: 3
Replication Factor: 1
Retention: 30 d√≠as (2592000000 ms)
Compression: GZIP
```

### 2. Esquema JSON de Eventos

**Estructura del evento `ratings`**:
```json
{
  "userId": 44176,
  "movieId": 21373,
  "rating": 3.5,
  "timestamp": 1761763121809
}
```

**Validaciones implementadas**:
- `userId`: int > 0, rango 1-138,493
- `movieId`: int > 0, rango 1-131,262
- `rating`: double ‚àà {0.5, 1.0, 1.5, ..., 5.0}
- `timestamp`: long > 0 (Unix epoch en milisegundos)

### 3. Archivos Implementados

```
movies/src/streaming/
‚îú‚îÄ‚îÄ create_kafka_topics.py          # 340 l√≠neas - Creaci√≥n y validaci√≥n de topics
‚îú‚îÄ‚îÄ kafka_producer_hello.py         # 280 l√≠neas - Producer de prueba
‚îú‚îÄ‚îÄ kafka_consumer_hello.py         # 335 l√≠neas - Consumer con validaci√≥n
‚îî‚îÄ‚îÄ README_FASE6.md                 # 450 l√≠neas - Documentaci√≥n completa

scripts/
‚îî‚îÄ‚îÄ verify_kafka_phase6.sh          # 180 l√≠neas - Script de verificaci√≥n

requirements.txt                     # +kafka-python>=2.0.2
```

### 4. Caracter√≠sticas del Producer

**Archivo**: `kafka_producer_hello.py`

- ‚úÖ Generaci√≥n de ratings sint√©ticos aleatorios
- ‚úÖ Validaci√≥n de esquema antes de enviar
- ‚úÖ Particionamiento por `userId` (key)
- ‚úÖ Compresi√≥n LZ4
- ‚úÖ Acks='all' para confiabilidad
- ‚úÖ Estad√≠sticas de env√≠o (throughput, √©xito/fallo)
- ‚úÖ CLI con argumentos `--count` y `--delay`

**Ejemplo de uso**:
```bash
python3 kafka_producer_hello.py --count 10 --delay 0.3
```

### 5. Caracter√≠sticas del Consumer

**Archivo**: `kafka_consumer_hello.py`

- ‚úÖ Consumo desde topic `ratings`
- ‚úÖ Validaci√≥n de esquema en mensajes recibidos
- ‚úÖ Estad√≠sticas detalladas (v√°lidos/inv√°lidos)
- ‚úÖ Distribuci√≥n de ratings visualizada
- ‚úÖ Consumer group para tracking de offsets
- ‚úÖ Signal handling (Ctrl+C graceful)
- ‚úÖ CLI con `--max-messages`, `--timeout`, `--reset`

**Ejemplo de uso**:
```bash
python3 kafka_consumer_hello.py --max-messages 10 --timeout 10
```

---

## ‚úÖ Resultados de Verificaci√≥n

### Prueba Producer (10 mensajes)

```
======================================================================
üìä RESUMEN DE ENV√çO
======================================================================

‚úÖ Mensajes enviados: 10
‚ùå Mensajes fallidos: 0
üìà Total: 10
‚è±Ô∏è  Tiempo total: 2.76 segundos
üöÄ Throughput: 3.63 mensajes/seg
‚úì  Tasa de √©xito: 100.0%
```

**Distribuci√≥n por partici√≥n**:
- Partition 0: 3 mensajes (offsets 0-2)
- Partition 2: 2 mensajes (offsets 0-1)
- Partition 3: 1 mensaje (offset 0)
- Partition 4: 3 mensajes (offsets 0-2)
- Partition 5: 1 mensaje (offset 0)

### Prueba Consumer (10 mensajes)

```
======================================================================
üìä RESUMEN DE CONSUMO
======================================================================

üìà Mensajes procesados:
   Total: 10
   V√°lidos: 10 (100.0%)
   Inv√°lidos: 0
   Errores de deserializaci√≥n: 0
   Errores de procesamiento: 0

‚è±Ô∏è  Duraci√≥n: 3.29 segundos
üöÄ Throughput: 3.04 mensajes/seg

‚≠ê Distribuci√≥n de ratings:
   0.5: ‚ñà (1)    1.0: ‚ñà (1)    1.5: ‚ñà‚ñà (2)
   2.0: ‚ñà (1)    3.5: ‚ñà (1)    4.0: ‚ñà (1)
   4.5: ‚ñà‚ñà (2)   5.0: ‚ñà (1)
```

### Verificaci√≥n de Offsets

**Consumer Group**: `ratings-consumer-hello-world`

```
PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
0          3               3               0
1          0               0               0
2          2               2               0
3          1               1               0
4          3               3               0
5          1               1               0

Total LAG: 0 (todos los mensajes consumidos)
```

---

## üìä M√©tricas de Performance

| M√©trica | Producer | Consumer |
|---------|----------|----------|
| **Mensajes procesados** | 10 | 10 |
| **Duraci√≥n** | 2.76 s | 3.29 s |
| **Throughput** | 3.63 msg/s | 3.04 msg/s |
| **Tasa de √©xito** | 100% | 100% |
| **Errores** | 0 | 0 |
| **Latencia end-to-end** | ~3 segundos | - |

---

## üîß Dependencias Instaladas

### Python Packages (Spark containers)

```bash
pip install kafka-python>=2.0.2  # Cliente Kafka para Python
pip install lz4>=4.3.3           # Compresi√≥n LZ4
pip install python-snappy        # Compresi√≥n Snappy
```

**Instalaci√≥n ejecutada**:
```bash
docker exec -u root spark-master pip install kafka-python lz4 python-snappy
docker exec -u root spark-worker pip install kafka-python lz4 python-snappy
```

---

## üéì Lecciones Aprendidas

### 1. Librer√≠as de Compresi√≥n

**Problema encontrado**:
```
‚ùå Error creando producer: Libraries for lz4 compression codec not found
```

**Soluci√≥n**:
- Instalar `lz4` y `python-snappy` adem√°s de `kafka-python`
- Las librer√≠as de compresi√≥n no vienen incluidas por defecto
- Necesarias para producer con `compression_type='lz4'`

### 2. Particionamiento Consistente

- Uso de `userId` como **key** del mensaje
- Garantiza que ratings del mismo usuario vayan a la misma partici√≥n
- Facilita procesamiento con estado (stateful streaming)
- Permite paralelismo sin conflictos de usuarios

### 3. Validaci√≥n de Esquema

- **Doble validaci√≥n**: producer (antes de enviar) + consumer (al recibir)
- Previene mensajes malformados en el topic
- **Resultado**: 100% de mensajes v√°lidos en pruebas
- Rating con incrementos de 0.5 evita valores inv√°lidos como 3.7 o 4.3

### 4. Consumer Group Offsets

- Consumer group autom√°ticamente rastrea offsets
- Permite reanudar consumo desde √∫ltima posici√≥n
- LAG=0 indica que todos los mensajes fueron consumidos
- √ötil para monitoreo y troubleshooting

### 5. Topics Pre-existentes

- Topics ya exist√≠an de ejecuci√≥n anterior
- `TopicAlreadyExistsError` es esperado, no fatal
- Configuraciones pueden diferir (6 vs 3 particiones para `ratings`)
- En producci√≥n: usar scripts idempotentes

---

## üöÄ Pr√≥ximos Pasos - Fase 7

### Spark Structured Streaming para Recomendaciones

**Objetivo**: Consumir ratings en tiempo real y generar recomendaciones usando modelo ALS de Fase 5

**Componentes a implementar**:

1. **Streaming Consumer**
   ```python
   # spark_streaming_recommendations.py
   - Leer topic 'ratings' con Spark Structured Streaming
   - Procesar micro-batches cada 10 segundos
   - Checkpointing en HDFS
   ```

2. **Model Loader**
   ```python
   # model_loader.py
   - Cargar modelo ALS desde HDFS
   - Cache de modelo en memoria
   - Validaci√≥n de versi√≥n del modelo
   ```

3. **Recommendation Generator**
   ```python
   # recommendation_generator.py
   - Generar top-10 recomendaciones por usuario
   - Filtrar pel√≠culas ya vistas
   - Calcular scores de confianza
   ```

4. **Metrics Publisher**
   ```python
   # metrics_publisher.py
   - Publicar m√©tricas en topic 'metrics'
   - Rastrear: throughput, latencia, RMSE, cobertura
   - Formato JSON para dashboard
   ```

**M√©tricas esperadas**:
- Throughput: ratings procesados/segundo
- Latencia: end-to-end (rating ‚Üí recomendaci√≥n)
- RMSE: error de predicci√≥n vs ratings reales
- Cobertura: % de usuarios con recomendaciones

---

## üìÅ Estructura de Archivos Actualizada

```
Recomendacion-Gran-Escala/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ FASE6_RESUMEN.md           # ‚Üê Este archivo
‚îÇ   ‚îú‚îÄ‚îÄ FASE6_VERIFICACION.md      # Resultados de pruebas
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ movies/src/streaming/
‚îÇ   ‚îú‚îÄ‚îÄ create_kafka_topics.py     # Admin client Kafka
‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer_hello.py    # Producer de prueba
‚îÇ   ‚îú‚îÄ‚îÄ kafka_consumer_hello.py    # Consumer de prueba
‚îÇ   ‚îî‚îÄ‚îÄ README_FASE6.md            # Documentaci√≥n t√©cnica
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ verify_kafka_phase6.sh     # Script de verificaci√≥n
‚îú‚îÄ‚îÄ shared/streaming/               # Scripts copiados para Docker
‚îÇ   ‚îú‚îÄ‚îÄ create_kafka_topics.py
‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer_hello.py
‚îÇ   ‚îî‚îÄ‚îÄ kafka_consumer_hello.py
‚îî‚îÄ‚îÄ requirements.txt                # +kafka-python>=2.0.2
```

---

## ‚úÖ Criterios de Aceptaci√≥n

| # | Criterio | Estado | Evidencia |
|---|----------|--------|-----------|
| 1 | Topics `ratings` y `metrics` creados | ‚úÖ | `kafka-topics --list` |
| 2 | Esquema JSON definido y documentado | ‚úÖ | README_FASE6.md |
| 3 | Validaci√≥n de esquema implementada | ‚úÖ | 10/10 mensajes v√°lidos |
| 4 | Producer hello world funcional | ‚úÖ | 10 mensajes enviados, 0 errores |
| 5 | Consumer hello world funcional | ‚úÖ | 10 mensajes consumidos, LAG=0 |
| 6 | Particionamiento por userId | ‚úÖ | 5 particiones activas |
| 7 | Script de verificaci√≥n | ‚úÖ | verify_kafka_phase6.sh |
| 8 | Documentaci√≥n completa | ‚úÖ | README + RESUMEN + VERIFICACION |

**Todos los criterios cumplidos**: ‚úÖ **8/8 (100%)**

---

## üê≥ Servicios Docker Activos

```
CONTAINER          IMAGE                              STATUS    PORTS
kafka             confluentinc/cp-kafka:6.2.0        Up        9092, 9093
zookeeper         confluentinc/cp-zookeeper:6.2.0    Up        2181
spark-master      apache/spark:3.4.1                 Up        7077, 8080, 4040
spark-worker      apache/spark:3.4.1                 Up        8081
namenode          bde2020/hadoop-namenode:2.0.0      Up        9000, 9870
datanode          bde2020/hadoop-datanode:2.0.0      Up        9864
resourcemanager   bde2020/hadoop-resourcemanager     Up        8032, 8088
nodemanager       bde2020/hadoop-nodemanager         Up        8042
recs-api          recomendacion-gran-escala-api      Up        8000
```

---

## üìö Comandos de Referencia

### Iniciar Kafka
```bash
docker compose up -d zookeeper kafka
sleep 30  # Esperar inicializaci√≥n
```

### Instalar Dependencias
```bash
docker exec -u root spark-master pip install kafka-python lz4 python-snappy
```

### Crear Topics
```bash
docker exec spark-master python3 /opt/spark/work-dir/streaming/create_kafka_topics.py
```

### Listar Topics
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

### Describir Topic
```bash
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic ratings
```

### Ejecutar Producer
```bash
docker exec spark-master python3 /opt/spark/work-dir/streaming/kafka_producer_hello.py \
  --count 10 --delay 0.3
```

### Ejecutar Consumer
```bash
docker exec spark-master python3 /opt/spark/work-dir/streaming/kafka_consumer_hello.py \
  --max-messages 10 --timeout 10
```

### Ver Offsets
```bash
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 --topic ratings
```

### Ver Consumer Groups
```bash
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
docker exec kafka kafka-consumer-groups --bootstrap-server localhost:9092 \
  --describe --group ratings-consumer-hello-world
```

### Verificaci√≥n Completa
```bash
./scripts/verify_kafka_phase6.sh
```

---

## üîç Troubleshooting

### Problema: Error de compresi√≥n LZ4
```
‚ùå Libraries for lz4 compression codec not found
```
**Soluci√≥n**: `pip install lz4 python-snappy`

### Problema: Topics ya existen
```
‚ùå TopicAlreadyExistsError
```
**Soluci√≥n**: Esperado, verificar con `kafka-topics --describe`

### Problema: Consumer no recibe mensajes
```
‚è±Ô∏è  Timeout: 30s sin mensajes nuevos
```
**Soluci√≥n**: 
1. Verificar offsets con `GetOffsetShell`
2. Resetear consumer group: `--reset-offsets --to-earliest`
3. Verificar que producer envi√≥ mensajes

### Problema: Kafka no arranca
```
‚ùå Error creando producer: NoBrokersAvailable
```
**Soluci√≥n**:
1. `docker compose up -d kafka`
2. Esperar ~30 segundos
3. Verificar logs: `docker logs kafka --tail 50`

---

## üìä Comparaci√≥n con Dise√±o Original

| Aspecto | Dise√±o (Fase 6) | Implementado | Estado |
|---------|----------------|--------------|--------|
| Topic ratings | 3 particiones | 6 particiones | ‚ö†Ô∏è Diferente |
| Topic metrics | 1 partici√≥n | 3 particiones | ‚ö†Ô∏è Diferente |
| Esquema JSON | Definido | Implementado + Validaci√≥n | ‚úÖ Mejorado |
| Producer | Hello world | CLI + Stats + Validaci√≥n | ‚úÖ Mejorado |
| Consumer | Hello world | CLI + Stats + Distribuci√≥n | ‚úÖ Mejorado |
| Documentaci√≥n | B√°sica | README + Scripts + Resumen | ‚úÖ Mejorado |

**Nota**: Diferencias en particiones debido a ejecuci√≥n previa. Funcionalidad no afectada.

---

## üí° Conclusiones

### Logros Principales

1. ‚úÖ **Infraestructura de streaming operativa** con Kafka + Zookeeper
2. ‚úÖ **Topics configurados** para flujo de datos (ratings ‚Üí metrics)
3. ‚úÖ **Esquema JSON robusto** con validaci√≥n completa
4. ‚úÖ **Producer/Consumer funcionales** con 100% de √©xito en pruebas
5. ‚úÖ **Particionamiento inteligente** por userId para stateful streaming
6. ‚úÖ **Documentaci√≥n completa** con ejemplos y troubleshooting

### Preparaci√≥n para Fase 7

- ‚úÖ Topics listos para Spark Structured Streaming
- ‚úÖ Esquema validado para procesamiento batch
- ‚úÖ Consumer group configurado para tracking de progreso
- ‚úÖ Modelo ALS disponible (Fase 5) para inferencia en tiempo real
- ‚úÖ Infraestructura Hadoop/HDFS para checkpointing

### Valor Agregado

- **Producer/Consumer robustos** m√°s all√° de "hello world"
- **CLI arguments** para testing flexible
- **Estad√≠sticas detalladas** (throughput, distribuci√≥n, errores)
- **Validaci√≥n exhaustiva** previene datos corruptos
- **Scripts de automatizaci√≥n** para verificaci√≥n end-to-end

---

**Estado Final**: ‚úÖ **FASE 6 COMPLETADA Y VERIFICADA**

**Siguiente**: Fase 7 - Spark Structured Streaming para Recomendaciones en Tiempo Real

---

**Documentado por**: GitHub Copilot  
**Fecha**: 29 de octubre de 2025  
**Duraci√≥n total de implementaci√≥n**: ~2 horas (c√≥digo + pruebas + documentaci√≥n)
