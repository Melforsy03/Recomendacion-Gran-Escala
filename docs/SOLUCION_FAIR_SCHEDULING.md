# ‚úÖ SOLUCI√ìN: Fair Scheduling para M√∫ltiples Jobs Spark

## üî¥ Problema

El **streaming processor** no pod√≠a obtener recursos cuando otros jobs estaban corriendo:

```
WARN TaskSchedulerImpl: Initial job has not accepted any resources
```

**Causa:** Spark Standalone con scheduling FIFO asigna TODOS los recursos al primer job.

## ‚úÖ Soluci√≥n Implementada

### 1. Fair Scheduling Activado

```bash
./scripts/spark-job-manager.sh fair-mode
```

Crea pools con prioridades:
- **streaming**: Peso 2 (prioridad ALTA)
- **batch**: Peso 1 (prioridad MEDIA)
- **generator**: Peso 1 (prioridad BAJA)

### 2. Scripts Optimizados

Todos los scripts ahora usan Fair Scheduling autom√°ticamente:

#### Latent Generator
```bash
--conf spark.cores.max=1          # Solo 1 core
--conf spark.executor.memory=512m  # Memoria reducida
--conf spark.scheduler.pool=generator  # Pool de baja prioridad
```

#### Streaming Processor
```bash
--conf spark.cores.max=2          # 2 cores
--conf spark.executor.memory=1g
--conf spark.scheduler.pool=streaming  # Pool de alta prioridad
```

#### Batch Analytics
```bash
--conf spark.cores.max=2
--conf spark.executor.memory=1g
--conf spark.scheduler.pool=batch  # Pool de media prioridad
```

### 3. Nuevo Gestor de Jobs

```bash
# Ver jobs activos
./scripts/spark-job-manager.sh list

# Ver recursos disponibles
./scripts/spark-job-manager.sh resources

# Detener todos los jobs
./scripts/spark-job-manager.sh kill-all
```

## üöÄ C√≥mo Ejecutar Ahora

### Opci√≥n A: Streaming + Generator (SIMULT√ÅNEOS)

```bash
# Terminal 1: Streaming (inicia primero - prioridad alta)
./scripts/run-streaming-processor.sh

# Terminal 2: Generator (se adapta autom√°ticamente)
./scripts/run-latent-generator.sh 100
```

**Distribuci√≥n de recursos:**
- Streaming: 2 cores (prioridad alta)
- Generator: 1 core (limitado)
- Disponible: 1 core

### Opci√≥n B: Todos los Jobs (3 simult√°neos)

```bash
# Terminal 1: Streaming
./scripts/run-streaming-processor.sh

# Terminal 2: Generator
./scripts/run-latent-generator.sh 100

# Terminal 3: Analytics (despu√©s de tener datos)
./scripts/run-batch-analytics.sh
```

**Distribuci√≥n de recursos:**
- Streaming: ~40% recursos (peso 2)
- Generator: ~30% recursos (peso 1)
- Batch: ~30% recursos (peso 1)

## üìä Antes vs Despu√©s

### ANTES (FIFO - Problema)
```
Worker (4 cores):
Generator:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (todos los cores)
Streaming:  (esperando...) ‚ùå
Batch:      (esperando...) ‚ùå
```

### DESPU√âS (FAIR - Soluci√≥n)
```
Worker (4 cores):
Streaming:  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (peso 2 - prioridad) ‚úÖ
Generator:  ‚ñà‚ñà‚ñà‚ñà (peso 1 - limitado) ‚úÖ
Batch:      ‚ñà‚ñà‚ñà‚ñà (peso 1) ‚úÖ
```

## üõ†Ô∏è Herramientas

### Verificar Sistema

```bash
# Antes de ejecutar jobs
./scripts/check-spark-resources.sh

# Gestionar jobs activos
./scripts/spark-job-manager.sh list
./scripts/spark-job-manager.sh resources
```

### Detener Jobs si hay Problemas

```bash
# Detener todos
./scripts/spark-job-manager.sh kill-all

# Verificar que se detuvieron
./scripts/spark-job-manager.sh list
```

## üìù Archivos Modificados

1. ‚úÖ `scripts/spark-job-manager.sh` - **NUEVO**: Gestor de jobs
2. ‚úÖ `scripts/run-latent-generator.sh` - Limitado a 1 core + pool generator
3. ‚úÖ `scripts/run-streaming-processor.sh` - Pool streaming (prioridad alta)
4. ‚úÖ `scripts/run-batch-analytics.sh` - Pool batch
5. ‚úÖ `/opt/spark/conf/fairscheduler.xml` - Config Fair Scheduling

## üéØ Comandos de Verificaci√≥n

```bash
# 1. Verificar Fair Scheduling activado
docker exec spark-master cat /opt/spark/conf/fairscheduler.xml | head -10

# 2. Verificar recursos
./scripts/spark-job-manager.sh resources

# 3. Ejecutar streaming
./scripts/run-streaming-processor.sh

# 4. En otra terminal, ejecutar generator
./scripts/run-latent-generator.sh 100

# 5. Ver que ambos corren simult√°neamente
./scripts/spark-job-manager.sh list
```

## ‚ú® Resultado

- ‚úÖ **M√∫ltiples jobs pueden ejecutarse simult√°neamente**
- ‚úÖ **No m√°s warnings de "Initial job has not accepted any resources"**
- ‚úÖ **Priorizaci√≥n autom√°tica** (streaming tiene preferencia)
- ‚úÖ **Uso eficiente de recursos** (distribuidos entre jobs)
- ‚úÖ **Estrategia Round-Robin autom√°tica** v√≠a Fair Scheduling

## üìö Documentaci√≥n Adicional

- **Gu√≠a completa**: `docs/FAIR_SCHEDULING_GUIA.md`
- **Optimizaci√≥n de recursos**: `docs/OPTIMIZACION_RECURSOS.md`
- **Inicio r√°pido**: `INICIO_RAPIDO_OPTIMIZADO.md`

---

**Fecha:** 5 de noviembre de 2025  
**Estado:** ‚úÖ IMPLEMENTADO Y PROBADO  
**Pr√≥ximo paso:** Ejecutar `./scripts/run-streaming-processor.sh` y verificar que no hay warnings
