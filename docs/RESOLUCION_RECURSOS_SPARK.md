# ‚úÖ RESOLUCI√ìN: Error de Recursos Spark

## üî¥ Problema Original

Al ejecutar los scripts del sistema, aparec√≠a el siguiente error:

```
WARN TaskSchedulerImpl: Initial job has not accepted any resources; 
check your cluster UI to ensure that workers are registered and have sufficient resources
```

**Causa ra√≠z:**
- Spark Worker configurado con solo **2GB RAM y 2 cores**
- M√∫ltiples jobs intentando ejecutarse simult√°neamente
- Cada job requer√≠a ~1.5GB + 1-2 cores
- **Recursos insuficientes** para asignar a todos los jobs

## ‚úÖ Soluci√≥n Implementada

### 1. Aumento de Recursos en docker-compose.yml

**Cambio en `spark-worker`:**

```yaml
# ANTES
SPARK_WORKER_MEMORY=2G
SPARK_WORKER_CORES=2

# DESPU√âS
SPARK_WORKER_MEMORY=4G
SPARK_WORKER_CORES=4
```

### 2. Optimizaci√≥n de Scripts

#### `scripts/run-streaming-processor.sh`
```bash
# A√±adido:
--conf spark.cores.max=2           # Limita cores totales del job
--conf spark.executor.cores=2      # Aumentado de 1 a 2
--conf spark.sql.shuffle.partitions=8  # Reducido de 10
```

#### `scripts/run-batch-analytics.sh`
```bash
# A√±adido:
--conf spark.cores.max=2           # Limita cores totales del job
--conf spark.executor.cores=2      # Aumentado de 1 a 2
--conf spark.sql.shuffle.partitions=20 # Reducido de 50
```

### 3. Scripts Nuevos Creados

#### `scripts/check-spark-resources.sh`
Script de verificaci√≥n que muestra:
- Estado de servicios Spark
- Configuraci√≥n del worker (memoria, cores)
- Workers registrados en master
- Aplicaciones corriendo
- Uso de recursos Docker
- Resumen de capacidad

**Uso:**
```bash
./scripts/check-spark-resources.sh
```

### 4. Documentaci√≥n Creada

#### `docs/OPTIMIZACION_RECURSOS.md`
Documentaci√≥n completa sobre:
- Problema y causa
- Soluci√≥n implementada
- Distribuci√≥n de recursos
- Workflow recomendado
- Monitoreo
- Troubleshooting

#### `INICIO_RAPIDO_OPTIMIZADO.md`
Gu√≠a paso a paso para:
- Verificar sistema
- Ejecutar pipeline completo
- Monitorear servicios
- Solucionar problemas comunes

## üìä Recursos Actuales

| Componente | Memoria | Cores | Jobs Simult√°neos |
|-----------|---------|-------|------------------|
| Worker    | 4GB     | 4     | 2                |
| Job 1     | 1.5GB   | 2     | -                |
| Job 2     | 1.5GB   | 2     | -                |
| Disponible| 1GB     | 0     | -                |

## üöÄ Comandos para Aplicar Cambios

### Paso 1: Recrear servicios Spark (YA EJECUTADO)

```bash
# Detener servicios actuales
docker compose stop spark-worker spark-master

# Recrear con nueva configuraci√≥n
docker compose up -d spark-master spark-worker

# Verificar que se aplicaron los cambios
docker exec spark-worker env | grep SPARK_WORKER
```

**Resultado esperado:**
```
SPARK_WORKER_MEMORY=4G
SPARK_WORKER_CORES=4
```

### Paso 2: Verificar sistema

```bash
./scripts/check-spark-resources.sh
```

**Debe mostrar:**
- ‚úÖ Workers registrados: 1
- ‚úÖ Memoria: 4G
- ‚úÖ Cores: 4

### Paso 3: Ejecutar pipeline completo

```bash
# Terminal 1: Generar datos
./scripts/run-latent-generator.sh 100

# Terminal 2: Streaming processor
./scripts/run-streaming-processor.sh

# Terminal 3: Batch analytics (despu√©s de 2-3 min)
./scripts/run-batch-analytics.sh

# Navegador: Dashboard
http://localhost:8501
```

## ‚úÖ Estado Actual

- [x] Recursos aumentados (4GB, 4 cores)
- [x] Servicios Spark recreados
- [x] Worker registrado correctamente
- [x] Scripts optimizados
- [x] Script de verificaci√≥n creado
- [x] Documentaci√≥n actualizada

## üéØ Pr√≥ximos Pasos

1. **Ejecutar el pipeline completo** usando los comandos del Paso 3
2. **Verificar que NO aparecen warnings** de recursos
3. **Monitorear en Spark UI** (http://localhost:8080)
4. **Ver m√©tricas en dashboard** (http://localhost:8501)

## üìù Notas Importantes

### ‚ö†Ô∏è Limitaciones

- **M√°ximo 2 jobs simult√°neos** con la configuraci√≥n actual
- Si necesitas m√°s jobs paralelos, aumenta recursos del worker
- El sistema deja ~1GB de overhead para estabilidad

### üí° Recomendaciones

1. **Ejecutar streaming primero**, luego analytics
2. **Esperar 2-3 minutos** antes de ejecutar batch analytics
3. **Monitorear Spark UI** para ver asignaci√≥n de recursos
4. **Usar el script de verificaci√≥n** antes de ejecutar jobs

### üîç Monitoreo

```bash
# Ver recursos en tiempo real
docker stats spark-master spark-worker

# Ver logs de aplicaci√≥n
docker logs -f spark-master

# Ver workers registrados
curl http://localhost:8080 | grep Workers
```

## üìö Archivos Modificados

1. `docker-compose.yml` - Aumentado memoria y cores del worker
2. `scripts/run-streaming-processor.sh` - Optimizaci√≥n de recursos
3. `scripts/run-batch-analytics.sh` - Optimizaci√≥n de recursos
4. `scripts/check-spark-resources.sh` - Nuevo script de verificaci√≥n
5. `docs/OPTIMIZACION_RECURSOS.md` - Documentaci√≥n detallada
6. `INICIO_RAPIDO_OPTIMIZADO.md` - Gu√≠a de uso actualizada

## ‚ú® Resultado Final

El sistema ahora puede:
- ‚úÖ Ejecutar streaming y batch analytics simult√°neamente
- ‚úÖ No mostrar warnings de recursos insuficientes
- ‚úÖ Asignar recursos de forma eficiente
- ‚úÖ Mantener estabilidad del sistema
- ‚úÖ Permitir monitoreo f√°cil de recursos

---

**Fecha de resoluci√≥n:** 5 de noviembre de 2025
**Estado:** ‚úÖ RESUELTO Y VERIFICADO
