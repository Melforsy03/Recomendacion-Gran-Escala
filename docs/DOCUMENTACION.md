# ğŸ“š DocumentaciÃ³n TÃ©cnica - Sistema de RecomendaciÃ³n a Gran Escala

**Sistema de RecomendaciÃ³n de PelÃ­culas en Gran Escala**  
**VersiÃ³n:** 1.0  
**Ãšltima actualizaciÃ³n:** Diciembre 2025  
**Repositorio:** Melforsy03/Recomendacion-Gran-Escala  
**Branch:** dev_abraham

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n General](#1-descripciÃ³n-general)
2. [Arquitectura del Sistema](#2-arquitectura-del-sistema)
3. [Componentes](#3-componentes)
4. [ConfiguraciÃ³n](#4-configuraciÃ³n)
5. [API REST](#5-api-rest)
6. [Flujo de Datos](#6-flujo-de-datos)
7. [Scripts Disponibles](#7-scripts-disponibles)
8. [Interfaces Web](#8-interfaces-web)
9. [Persistencia y VolÃºmenes](#9-persistencia-y-volÃºmenes)
10. [Fair Scheduler](#10-fair-scheduler)
11. [Consumo de Recursos](#11-consumo-de-recursos)
12. [Seguridad](#12-seguridad)
13. [Estructura del Proyecto](#13-estructura-del-proyecto)

---

## 1. DescripciÃ³n General

### 1.1. PropÃ³sito

Sistema de recomendaciÃ³n de pelÃ­culas a gran escala que implementa:

- **Procesamiento Batch:** ETL, entrenamiento de modelos ALS
- **Procesamiento Streaming:** Agregaciones en tiempo real con ventanas
- **VisualizaciÃ³n:** Dashboard interactivo con mÃ©tricas en tiempo real
- **API REST:** Acceso programÃ¡tico a las mÃ©tricas y recomendaciones

### 1.2. Dataset

Utiliza el dataset **MovieLens** con aproximadamente:

- ~32 millones de registros totales
- 6 archivos CSV: movies, ratings, tags, genome_tags, genome_scores, links

### 1.3. TecnologÃ­as

| Componente | TecnologÃ­a | VersiÃ³n |
|------------|------------|---------|
| Almacenamiento Distribuido | Apache HDFS | 3.2.1 |
| GestiÃ³n de Recursos | Apache YARN | 3.2.1 |
| Procesamiento | Apache Spark | 3.4.1 |
| MensajerÃ­a | Apache Kafka | 3.5 |
| CoordinaciÃ³n | Apache Zookeeper | 3.9 |
| API | FastAPI | 0.100+ |
| Dashboard | Streamlit | 1.25+ |
| Contenedores | Docker | 20.10+ |

---

## 2. Arquitectura del Sistema

### 2.1. Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA DE PRESENTACIÃ“N                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Streamlit Dashboard         â”‚           FastAPI                 â”‚
â”‚     (http://localhost:8501)     â”‚     (http://localhost:8000)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CAPA DE MENSAJERÃA                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         Apache Kafka                                â”‚
â”‚              Topics: ratings (6 particiones)                        â”‚
â”‚                       metrics (3 particiones)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAPA DE PROCESAMIENTO                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Spark Streaming      â”‚              Spark Batch                    â”‚
â”‚  - Latent Generator   â”‚              - ETL Pipeline                 â”‚
â”‚  - Stream Processor   â”‚              - Feature Engineering          â”‚
â”‚  - Metrics Publisher  â”‚              - ALS Model Training           â”‚
â”‚                       â”‚              - Batch Analytics              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CAPA DE ALMACENAMIENTO                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                         Apache HDFS                                 â”‚
â”‚  /data/movielens/csv/      - Datos CSV originales                  â”‚
â”‚  /data/movielens_parquet/  - Datos en formato Parquet              â”‚
â”‚  /data/content_features/   - Features de contenido                  â”‚
â”‚  /models/als/              - Modelo ALS entrenado                   â”‚
â”‚  /streams/ratings/         - Agregaciones de streaming              â”‚
â”‚  /outputs/analytics/       - Resultados de anÃ¡lisis batch           â”‚
â”‚  /checkpoints/             - Checkpoints de Spark Streaming         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2. Flujo de Datos Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Latent Generator    â”‚  (Spark Job)
â”‚ â€¢ Matrix Factoriza. â”‚  â†’ 100 ratings/seg
â”‚ â€¢ Synthetic Ratings â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Kafka Topic â”‚
    â”‚  "ratings"  â”‚  â†’ 240K+ mensajes
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streaming Processor  â”‚  (Spark Structured Streaming)
â”‚ â€¢ Tumbling: 1 min    â”‚
â”‚ â€¢ Sliding: 5 min     â”‚
â”‚ â€¢ Agregaciones       â”‚
â”‚ â€¢ Top-N              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                      â”‚
           â–¼                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ HDFS        â”‚      â”‚ Kafka Topic  â”‚
    â”‚ /streams/*  â”‚      â”‚  "metrics"   â”‚  â†’ 74+ mensajes
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ FastAPI      â”‚
                         â”‚ Consumer     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Streamlit    â”‚
                         â”‚ Dashboard    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Componentes

### 3.1. Infraestructura Docker

| Contenedor | Imagen | Puertos | DescripciÃ³n |
|------------|--------|---------|-------------|
| `namenode` | bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8 | 9870, 9000 | HDFS NameNode |
| `datanode` | bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8 | 9864 | HDFS DataNode |
| `resourcemanager` | bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8 | 8088 | YARN ResourceManager |
| `nodemanager` | bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8 | 8042 | YARN NodeManager |
| `spark-master` | bitnami/spark:3.4.1 | 8080, 7077 | Spark Master |
| `spark-worker` | bitnami/spark:3.4.1 | 8081 | Spark Worker |
| `zookeeper` | confluentinc/cp-zookeeper:7.5.0 | 2181 | Zookeeper |
| `kafka` | confluentinc/cp-kafka:7.5.0 | 9092, 9093 | Kafka Broker |
| `recs-api` | Custom (FastAPI) | 8000 | API REST |
| `recs-dashboard` | Custom (Streamlit) | 8501 | Dashboard |

### 3.2. Jobs de Spark

#### Latent Generator (`latent_generator.py`)

- **FunciÃ³n:** Genera ratings sintÃ©ticos basados en factorizaciÃ³n matricial
- **Pool:** `generator` (prioridad baja)
- **Recursos:** 1 core, 512MB RAM
- **Output:** Topic Kafka `ratings`

#### Streaming Processor (`ratings_stream_processor.py`)

- **FunciÃ³n:** Procesa ratings en tiempo real con ventanas
- **Pool:** `streaming` (prioridad alta)
- **Recursos:** 2 cores, 1GB RAM
- **Ventanas:**
  - Tumbling: 1 minuto
  - Sliding: 5 minutos
- **Output:** HDFS + Topic Kafka `metrics`

#### Batch Analytics (`batch_analytics.py`)

- **FunciÃ³n:** AnÃ¡lisis histÃ³rico y trending
- **Pool:** `batch` (prioridad media)
- **Recursos:** 2 cores, 1GB RAM
- **Output:** HDFS `/outputs/analytics/`

### 3.3. ETL Pipeline

1. **etl_movielens.py:** Convierte CSV a Parquet con schemas tipados
2. **generate_content_features.py:** Genera vectores de features (gÃ©neros + genome tags)

---

## 4. ConfiguraciÃ³n

### 4.1. Archivos de ConfiguraciÃ³n

| Archivo | UbicaciÃ³n | DescripciÃ³n |
|---------|-----------|-------------|
| `docker-compose.yml` | RaÃ­z | DefiniciÃ³n de servicios Docker |
| `fairscheduler.xml` | RaÃ­z | ConfiguraciÃ³n Fair Scheduler Spark |
| `core-site.xml` | hadoop-conf/ | ConfiguraciÃ³n core de Hadoop |
| `hdfs-site.xml` | hadoop-conf/ | ConfiguraciÃ³n HDFS |
| `yarn-site.xml` | hadoop-conf/ | ConfiguraciÃ³n YARN |

### 4.2. Variables de Entorno Principales

#### Spark Worker

```yaml
SPARK_MODE: worker
SPARK_MASTER_URL: spark://spark-master:7077
SPARK_WORKER_MEMORY: 4G
SPARK_WORKER_CORES: 4
```

#### Kafka

```yaml
KAFKA_BROKER_ID: 1
KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
```

### 4.3. ConfiguraciÃ³n de Spark Submit

```bash
spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --conf spark.scheduler.mode=FAIR \
  --conf spark.scheduler.allocation.file=/opt/spark/conf/fairscheduler.xml \
  --conf spark.scheduler.pool=<pool_name> \
  --executor-memory 1G \
  --total-executor-cores 2 \
  <script.py>
```

---

## 5. API REST

### 5.1. Endpoints Disponibles

#### Health Check

```http
GET /metrics/health
```

**Response:**

```json
{
  "status": "healthy",
  "last_update": "2025-12-03T10:00:00.000Z",
  "metrics_available": true
}
```

#### Resumen de MÃ©tricas

```http
GET /metrics/summary
```

**Response:**

```json
{
  "window_start": "2025-12-03T09:59:00.000Z",
  "window_end": "2025-12-03T10:00:00.000Z",
  "window_type": "tumbling_1min",
  "total_ratings": 6000,
  "avg_rating": 3.50,
  "p50_rating": 3.5,
  "p95_rating": 4.5,
  "timestamp": "2025-12-03T10:00:24.000Z",
  "last_update": "2025-12-03T10:00:24.000Z"
}
```

#### Top-N PelÃ­culas

```http
GET /metrics/topn?limit=10
```

**Response:**

```json
{
  "window_start": "2025-12-03T09:59:00.000Z",
  "window_end": "2025-12-03T10:00:00.000Z",
  "movies": [32518, 103135, 68435, 87191, 74226],
  "timestamp": "2025-12-03T10:00:24.000Z",
  "count": 5
}
```

#### MÃ©tricas por GÃ©nero

```http
GET /metrics/genres
```

**Response:**

```json
{
  "window_start": "2025-12-03T09:59:00.000Z",
  "window_end": "2025-12-03T10:00:00.000Z",
  "genres": {
    "Action": {"count": 150, "avg_rating": 3.8},
    "Comedy": {"count": 200, "avg_rating": 3.5}
  },
  "timestamp": "2025-12-03T10:00:24.000Z"
}
```

#### Historial de MÃ©tricas

```http
GET /metrics/history?limit=50
```

**Response:**

```json
{
  "count": 50,
  "history": [
    {"type": "summary", "timestamp": "...", "data": {...}},
    {"type": "topn", "timestamp": "...", "data": {...}}
  ]
}
```

### 5.2. DocumentaciÃ³n Interactiva

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

---

## 6. Flujo de Datos

### 6.1. Pipeline Batch (Primera EjecuciÃ³n)

```
CSV Files â†’ HDFS â†’ ETL (Parquet) â†’ Features â†’ HDFS
```

**Fases:**

1. **Fase 3:** ETL CSV â†’ Parquet
2. **Fase 4:** Feature Engineering

### 6.2. Pipeline Streaming (EjecuciÃ³n Continua)

```
Latent Generator â†’ Kafka (ratings) â†’ Stream Processor â†’ Kafka (metrics) â†’ API â†’ Dashboard
                                                     â†“
                                                   HDFS
```

**Componentes:**

1. **Latent Generator:** Produce ratings sintÃ©ticos
2. **Streaming Processor:** Consume, agrega, publica mÃ©tricas
3. **API Consumer:** Consume mÃ©tricas de Kafka
4. **Dashboard:** Visualiza mÃ©tricas en tiempo real

---

## 7. Scripts Disponibles

### 7.1. Scripts de Inicio

| Script | DescripciÃ³n | Uso |
|--------|-------------|-----|
| `start-system.sh` | Inicia toda la infraestructura | `./scripts/start-system.sh` |
| `run-latent-generator.sh` | Inicia generador de ratings | `./scripts/run-latent-generator.sh 100` |
| `run-streaming-processor.sh` | Inicia procesador streaming | `./scripts/run-streaming-processor.sh` |
| `run-batch-analytics.sh` | Ejecuta analytics batch | `./scripts/run-batch-analytics.sh` |
| `quickstart.sh` | Inicio rÃ¡pido completo | `./scripts/quickstart.sh` |

### 7.2. Scripts de VerificaciÃ³n

| Script | DescripciÃ³n | Uso |
|--------|-------------|-----|
| `check-spark-resources.sh` | Ver recursos de Spark | `./scripts/check-spark-resources.sh` |
| `check-status.sh` | Estado de servicios | `./scripts/check-status.sh` |
| `run-all-tests.sh` | Suite completa de tests | `./scripts/run-all-tests.sh` |
| `verify_fase9_system.sh` | VerificaciÃ³n completa | `./scripts/verify_fase9_system.sh` |

### 7.3. Scripts de Mantenimiento

| Script | DescripciÃ³n | Uso |
|--------|-------------|-----|
| `stop-system.sh` | Detener todo el sistema | `./scripts/stop-system.sh` |
| `clean-checkpoints.sh` | Limpiar checkpoints | `./scripts/clean-checkpoints.sh all` |
| `spark-job-manager.sh` | GestiÃ³n de jobs Spark | `./scripts/spark-job-manager.sh list` |
| `instalar-dependencias-spark.sh` | Instalar deps Python | `./scripts/instalar-dependencias-spark.sh` |

### 7.4. Scripts de Utilidad

| Script | DescripciÃ³n | Uso |
|--------|-------------|-----|
| `recsys-utils.sh` | Utilidades generales HDFS/Kafka | `source ./scripts/recsys-utils.sh` |
| `verify_csv_integrity.py` | Verificar integridad CSV | `spark-submit scripts/verify_csv_integrity.py` |

---

## 8. Interfaces Web

| Servicio | URL | Puerto | DescripciÃ³n |
|----------|-----|--------|-------------|
| Dashboard Streamlit | `localhost:8501` | 8501 | Visualizaciones en tiempo real |
| API Docs (Swagger) | `localhost:8000/docs` | 8000 | DocumentaciÃ³n interactiva API |
| API Health | `localhost:8000/metrics/health` | 8000 | Estado del sistema |
| Spark Master UI | `localhost:8080` | 8080 | Jobs y recursos Spark |
| Spark Worker UI | `localhost:8081` | 8081 | Estado del worker |
| HDFS NameNode | `localhost:9870` | 9870 | Explorador de archivos |
| YARN ResourceManager | `localhost:8088` | 8088 | Gestor de recursos |
| YARN NodeManager | `localhost:8042` | 8042 | Estado del node |

---

## 9. Persistencia y VolÃºmenes

### 9.1. VolÃºmenes Docker

Los siguientes datos persisten entre reinicios:

| Volumen | Contenedor | DescripciÃ³n |
|---------|------------|-------------|
| `namenode_data` | namenode | Metadatos HDFS |
| `datanode_data` | datanode | Datos HDFS |
| `spark_master_data` | spark-master | Checkpoints Spark |
| `spark_worker_data` | spark-worker | Logs de trabajo |
| `kafka_data` | kafka | Datos de topics |
| `zookeeper_data` | zookeeper | Estado del cluster |
| `spark-ivy-cache` | spark-* | CachÃ© de dependencias |
| `spark-pip-cache` | spark-* | CachÃ© de paquetes Python |

### 9.2. Estructura HDFS

```
/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ movielens/
â”‚   â”‚   â””â”€â”€ csv/           # Datos CSV originales
â”‚   â”œâ”€â”€ movielens_parquet/ # Datos en Parquet
â”‚   â””â”€â”€ content_features/  # Features de pelÃ­culas
â”œâ”€â”€ streams/
â”‚   â””â”€â”€ ratings/           # Agregaciones de streaming
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ analytics/         # Resultados batch
â””â”€â”€ checkpoints/           # Checkpoints Streaming
```

---

## 10. Fair Scheduler

### 10.1. ConfiguraciÃ³n de Pools

```xml
<?xml version="1.0"?>
<allocations>
  <!-- Pool para Streaming Processor - Prioridad ALTA -->
  <pool name="streaming">
    <schedulingMode>FAIR</schedulingMode>
    <weight>2</weight>
    <minShare>1</minShare>
  </pool>

  <!-- Pool para Batch Analytics - Prioridad MEDIA -->
  <pool name="batch">
    <schedulingMode>FAIR</schedulingMode>
    <weight>1</weight>
    <minShare>1</minShare>
  </pool>

  <!-- Pool para Latent Generator - Prioridad BAJA -->
  <pool name="generator">
    <schedulingMode>FAIR</schedulingMode>
    <weight>1</weight>
    <minShare>1</minShare>
  </pool>

  <!-- Pool por defecto -->
  <pool name="default">
    <schedulingMode>FAIR</schedulingMode>
    <weight>1</weight>
    <minShare>0</minShare>
  </pool>
</allocations>
```

### 10.2. DistribuciÃ³n de Recursos

```
Worker Total: 4 cores, 4GB RAM

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pool        â”‚ Cores   â”‚ RAM    â”‚ Prioridad      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ streaming   â”‚ 2 cores â”‚ 1GB    â”‚ ALTA (peso 2)  â”‚
â”‚ batch       â”‚ 2 cores â”‚ 1GB    â”‚ MEDIA (peso 1) â”‚
â”‚ generator   â”‚ 1 core  â”‚ 512MB  â”‚ BAJA (peso 1)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.3. VerificaciÃ³n

```bash
# Verificar configuraciÃ³n en contenedores
docker exec spark-master cat /opt/spark/conf/fairscheduler.xml
docker exec spark-worker cat /opt/spark/conf/fairscheduler.xml
```

---

## 11. Consumo de Recursos

### 11.1. Recursos por Servicio

| Servicio | CPU | RAM | DescripciÃ³n |
|----------|-----|-----|-------------|
| HDFS (namenode + datanode) | 0.5 cores | 2GB | Almacenamiento distribuido |
| YARN (RM + NM) | 0.5 cores | 2GB | GestiÃ³n de recursos |
| Spark Master | 0.5 cores | 512MB | Coordinador Spark |
| Spark Worker | 4-6 cores | 4GB | Ejecutor de trabajos |
| Kafka + Zookeeper | 1 core | 2GB | MensajerÃ­a |
| API + Dashboard | 0.5 cores | 1GB | VisualizaciÃ³n |
| **TOTAL** | **~8-10 cores** | **~12GB** | |

### 11.2. Requisitos MÃ­nimos

| Recurso | MÃ­nimo | Recomendado |
|---------|--------|-------------|
| RAM | 8 GB | 12-16 GB |
| CPU | 4 cores | 6-8 cores |
| Disco | 20 GB | 50+ GB |

### 11.3. MÃ©tricas de Rendimiento

| Componente | MÃ©trica | Valor Esperado |
|------------|---------|----------------|
| Latent Generator | Throughput | ~10-20 ratings/segundo |
| Streaming Processor | Latencia | <1 segundo por batch |
| Streaming Processor | Throughput | 100+ ratings/segundo |
| Batch Analytics | DuraciÃ³n | 30-60 segundos |
| Dashboard | ActualizaciÃ³n | Cada 5 segundos |

---

## 12. Seguridad

### 12.1. Estado Actual

âš ï¸ **Este sistema es para desarrollo/demostraciÃ³n.**

- Sin autenticaciÃ³n en servicios
- Sin encriptaciÃ³n de datos
- Puertos expuestos sin firewall

### 12.2. Recomendaciones para ProducciÃ³n

- [ ] Implementar autenticaciÃ³n en API
- [ ] Habilitar SSL/TLS en todas las comunicaciones
- [ ] Configurar Kerberos para Hadoop
- [ ] Implementar network policies
- [ ] Usar secrets management (Vault, etc.)
- [ ] Configurar firewalls y ACLs
- [ ] Habilitar auditorÃ­a y logging

---

## 13. Estructura del Proyecto

```
Recomendacion-Gran-Escala/
â”œâ”€â”€ docker-compose.yml          # DefiniciÃ³n de servicios
â”œâ”€â”€ fairscheduler.xml           # ConfiguraciÃ³n Fair Scheduler
â”œâ”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ README.md                   # DocumentaciÃ³n principal
â”‚
â”œâ”€â”€ Dataset/                    # Datos MovieLens
â”‚   â”œâ”€â”€ movie.csv
â”‚   â”œâ”€â”€ rating.csv
â”‚   â”œâ”€â”€ tag.csv
â”‚   â”œâ”€â”€ genome_tags.csv
â”‚   â”œâ”€â”€ genome_scores.csv
â”‚   â””â”€â”€ link.csv
â”‚
â”œâ”€â”€ docs/                       # DocumentaciÃ³n
â”‚   â”œâ”€â”€ DOCUMENTACION.md        # Este archivo
â”‚   â”œâ”€â”€ GUIA_DESPLIEGUE_INICIAL_UNICO.md
â”‚   â””â”€â”€ GUIA_DESPLIEGUE_REGULAR.md
â”‚
â”œâ”€â”€ hadoop-conf/                # ConfiguraciÃ³n Hadoop
â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â””â”€â”€ yarn-site.xml
â”‚
â”œâ”€â”€ movies/                     # CÃ³digo principal
â”‚   â”œâ”€â”€ api/                    # API FastAPI
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ dashboard/              # Dashboard Streamlit
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ etl/                # Pipeline ETL
â”‚       â”œâ”€â”€ features/           # Feature Engineering
â”‚       â”œâ”€â”€ models/             # Modelos ML
â”‚       â””â”€â”€ streaming/          # Procesamiento Streaming
â”‚
â”œâ”€â”€ scripts/                    # Scripts de gestiÃ³n
â”‚   â”œâ”€â”€ start-system.sh
â”‚   â”œâ”€â”€ stop-system.sh
â”‚   â”œâ”€â”€ run-latent-generator.sh
â”‚   â”œâ”€â”€ run-streaming-processor.sh
â”‚   â”œâ”€â”€ run-batch-analytics.sh
â”‚   â”œâ”€â”€ check-spark-resources.sh
â”‚   â”œâ”€â”€ spark-job-manager.sh
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ tests/                      # Scripts de prueba
    â”œâ”€â”€ test-connectivity.sh
    â”œâ”€â”€ test-hdfs.sh
    â”œâ”€â”€ test-kafka.sh
    â””â”€â”€ ...
```

---

## DocumentaciÃ³n Adicional

Para mÃ¡s informaciÃ³n, consultar:

- **Primera EjecuciÃ³n:** `docs/GUIA_DESPLIEGUE_INICIAL_UNICO.md`
- **Ejecuciones Regulares:** `docs/GUIA_DESPLIEGUE_REGULAR.md`
- **Comandos RÃ¡pidos:** `COMANDOS_RAPIDOS.md` (raÃ­z del proyecto)

---

**Mantenido por:** Equipo de Desarrollo  
**Ãšltima actualizaciÃ³n:** Diciembre 2025
