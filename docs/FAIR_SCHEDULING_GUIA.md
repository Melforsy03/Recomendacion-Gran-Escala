# üîÑ Gesti√≥n de Recursos con Fair Scheduling

## üéØ Problema Resuelto

El sistema ten√≠a un problema cr√≠tico: **Spark Standalone asigna TODOS los recursos al primer job que llega**, dejando a los dem√°s jobs sin recursos disponibles.

### S√≠ntoma
```
WARN TaskSchedulerImpl: Initial job has not accepted any resources
```

### Causa Ra√≠z
- El **latent generator** usa 4 cores (todos los disponibles)
- El **streaming processor** no puede obtener recursos
- Configuraci√≥n por defecto de Spark: FIFO scheduling

## ‚úÖ Soluci√≥n Implementada

### 1. Fair Scheduling con Pools

Hemos configurado **Fair Scheduling** que permite a m√∫ltiples jobs compartir recursos de forma justa:

```xml
<allocations>
  <pool name="streaming">
    <weight>2</weight>        <!-- Prioridad ALTA -->
    <minShare>1</minShare>
  </pool>
  
  <pool name="batch">
    <weight>1</weight>        <!-- Prioridad MEDIA -->
    <minShare>1</minShare>
  </pool>
  
  <pool name="generator">
    <weight>1</weight>        <!-- Prioridad BAJA -->
    <minShare>1</minShare>
  </pool>
</allocations>
```

### 2. Asignaci√≥n de Recursos por Job

| Job | Pool | Cores Max | Memory | Prioridad |
|-----|------|-----------|--------|-----------|
| **Streaming Processor** | streaming | 2 | 1GB | ‚≠ê‚≠ê ALTA |
| **Batch Analytics** | batch | 2 | 1GB | ‚≠ê MEDIA |
| **Latent Generator** | generator | 1 | 512MB | BAJA |

### 3. Estrategia Round-Robin Autom√°tica

Con Fair Scheduling, Spark autom√°ticamente:
- ‚úÖ Divide recursos entre jobs activos
- ‚úÖ Respeta pesos (streaming tiene prioridad 2x)
- ‚úÖ Garantiza m√≠nimo 1 core a cada job
- ‚úÖ Redistribuye recursos cuando un job termina

## üöÄ C√≥mo Usar

### Paso 1: Activar Fair Scheduling (YA HECHO)

```bash
./scripts/spark-job-manager.sh fair-mode
```

### Paso 2: Ejecutar Jobs (Orden Recomendado)

```bash
# Terminal 1: Streaming (prioridad ALTA)
./scripts/run-streaming-processor.sh

# Terminal 2: Generator (prioridad BAJA - se adapta)
./scripts/run-latent-generator.sh 100

# Terminal 3: Analytics (cuando haya datos)
./scripts/run-batch-analytics.sh
```

**Ahora los jobs pueden ejecutarse simult√°neamente sin conflictos!**

## üìä Distribuci√≥n de Recursos

### Escenario 1: Solo Streaming
```
Worker: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 4 cores
Streaming: [‚ñà‚ñà‚ñà‚ñà] 2 cores (usa lo asignado)
Disponible: [‚ñà‚ñà‚ñà‚ñà] 2 cores
```

### Escenario 2: Streaming + Generator
```
Worker: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 4 cores
Streaming: [‚ñà‚ñà‚ñà‚ñà] 2 cores (prioridad alta)
Generator: [‚ñà‚ñà] 1 core (limitado)
Disponible: [‚ñà‚ñà] 1 core
```

### Escenario 3: Streaming + Generator + Batch
```
Worker: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 4 cores
Streaming: [‚ñà‚ñà‚ñà] ~1.7 cores (peso 2)
Generator: [‚ñà] ~1.1 cores (peso 1)
Batch: [‚ñà] ~1.2 cores (peso 1)
```

## üõ†Ô∏è Herramientas de Gesti√≥n

### Script: spark-job-manager.sh

```bash
# Ver jobs activos
./scripts/spark-job-manager.sh list

# Ver recursos disponibles
./scripts/spark-job-manager.sh resources

# Detener todos los jobs
./scripts/spark-job-manager.sh kill-all

# Configurar fair scheduling
./scripts/spark-job-manager.sh fair-mode
```

### Ejemplo de Uso

```bash
# 1. Verificar estado
./scripts/spark-job-manager.sh resources

# Output:
# Worker Configuration:
#   SPARK_WORKER_MEMORY=4G
#   SPARK_WORKER_CORES=4
# 
# Slots de Ejecuci√≥n:
#   Total: 2 jobs (con 2 cores cada uno)
#   Usados: 1
#   Libres: 1

# 2. Ver jobs corriendo
./scripts/spark-job-manager.sh list

# Output:
# Aplicaciones activas: 1
# Detalles:
#   PID: 1234
#   CMD: /opt/spark/bin/spark-submit ... ratings_stream_processor.py
```

## üéõÔ∏è Configuraci√≥n Avanzada

### Cambiar Recursos de un Pool

Editar archivo en spark-master:
```bash
docker exec -it spark-master vi /opt/spark/conf/fairscheduler.xml
```

Luego reiniciar los jobs para que tomen la nueva configuraci√≥n.

### Aumentar Prioridad de Batch

```xml
<pool name="batch">
  <weight>2</weight>  <!-- Cambiar de 1 a 2 -->
  <minShare>2</minShare>  <!-- Garantizar 2 cores -->
</pool>
```

### Limitar Generator M√°s Agresivamente

Ya est√° limitado a 1 core en el script:
```bash
--conf spark.cores.max=1
```

## üîç Monitoreo en Tiempo Real

### Spark Master UI
```
http://localhost:8080
```

**Verificar:**
- Running Applications: 1-3
- Cada app muestra cores asignados
- Estado: RUNNING

### Logs de Fair Scheduler

```bash
docker exec spark-master cat /opt/spark/logs/*.out | grep -i "fair"
```

## üìà Ventajas de Fair Scheduling

### Antes (FIFO)
```
Job 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (todos los recursos)
Job 2: (esperando...)
Job 3: (esperando...)
```

### Despu√©s (FAIR)
```
Job 1 (streaming): ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (peso 2)
Job 2 (generator): ‚ñà‚ñà‚ñà‚ñà (peso 1)
Job 3 (batch): ‚ñà‚ñà‚ñà‚ñà (peso 1)
```

### Beneficios
- ‚úÖ M√∫ltiples jobs simult√°neos
- ‚úÖ Priorizaci√≥n autom√°tica
- ‚úÖ No m√°s "waiting for resources"
- ‚úÖ Mejor utilizaci√≥n de recursos
- ‚úÖ Streaming siempre tiene recursos garantizados

## üö® Troubleshooting

### Job sigue sin recursos

**Verificar configuraci√≥n:**
```bash
# Ver logs del job
docker logs spark-master | grep -i "fair\|pool"

# Verificar que el archivo existe
docker exec spark-master ls -la /opt/spark/conf/fairscheduler.xml
```

### Pool no reconocido

**Reconfigurar:**
```bash
./scripts/spark-job-manager.sh fair-mode
```

### Demasiados jobs

**Detener todos y empezar de nuevo:**
```bash
./scripts/spark-job-manager.sh kill-all
sleep 5
./scripts/spark-job-manager.sh resources
```

## üìö Referencias

- [Spark Fair Scheduler](https://spark.apache.org/docs/3.4.1/job-scheduling.html#fair-scheduler-pools)
- [Scheduling Pools](https://spark.apache.org/docs/3.4.1/job-scheduling.html#scheduling-within-an-application)
- [Resource Allocation](https://spark.apache.org/docs/3.4.1/configuration.html#dynamic-allocation)

## ‚ú® Resumen

| Aspecto | Antes | Despu√©s |
|---------|-------|---------|
| Scheduling | FIFO | FAIR |
| Jobs simult√°neos | 1 | 3 |
| Uso de recursos | 100% a 1 job | Distribuido |
| Priorizaci√≥n | No | S√≠ (por peso) |
| Waiting | Com√∫n | Raro |

**El sistema ahora puede manejar m√∫ltiples cargas de trabajo simult√°neamente con priorizaci√≥n inteligente!** üéâ
