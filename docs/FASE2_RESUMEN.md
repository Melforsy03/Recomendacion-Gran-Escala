# âœ… Fase 2 COMPLETADA - Staging de Datos en HDFS

**Fecha**: 28 de octubre de 2025  
**DuraciÃ³n**: ~5 minutos  
**Estado**: âœ… **Ã‰XITO TOTAL**

---

## ğŸ“‹ Resumen Ejecutivo

Los datos de MovieLens han sido **cargados y verificados exitosamente** en HDFS:

- âœ… **6 archivos CSV** subidos (885.4 MB)
- âœ… **32.2 millones** de registros totales
- âœ… **100% de integridad** verificada con Spark
- âœ… **Estructura de directorios** creada para todo el pipeline
- âœ… **Permisos** configurados para lectura por Spark

---

## ğŸ¯ Criterios de AceptaciÃ³n âœ“

### 1. Estructura HDFS Creada âœ“

```bash
./scripts/recsys-utils.sh hdfs-ls /
```

Directorios creados:
- `/data/movielens/csv` - Datos CSV crudos (885.4 MB)
- `/data/movielens_parquet` - Para ETL Parquet (prÃ³xima fase)
- `/models/als` - Para modelo ALS entrenado
- `/streams/ratings` - Para datos de streaming
- `/checkpoints` - Para checkpoints de Spark Streaming

### 2. Archivos CSV Subidos âœ“

```bash
./scripts/recsys-utils.sh hdfs-ls /data/movielens/csv
```

| Archivo | TamaÃ±o (bytes) | Registros | Estado |
|---------|---------------|-----------|--------|
| movie.csv | 1,493,648 | 27,278 | âœ“ OK |
| rating.csv | 690,353,377 | 20,000,263 | âœ“ OK |
| tag.csv | 21,725,514 | 465,564 | âœ“ OK |
| genome_tags.csv | 20,363 | 1,128 | âœ“ OK |
| genome_scores.csv | 214,322,450 | 11,709,768 | âœ“ OK |
| link.csv | 539,334 | 27,278 | âœ“ OK |

**Total**: 885.4 MB (~2.6 GB con replicaciÃ³n HDFS)

### 3. VerificaciÃ³n de Integridad âœ“

Ejecutado script `verify_csv_integrity.py` con Spark:

```
============================================================
COMPARACIÃ“N CON DATOS LOCALES:
------------------------------------------------------------
movie.csv                 HDFS:       27,278  Local:    27,278  âœ“ MATCH
rating.csv                HDFS:   20,000,263  Local:20,000,263  âœ“ MATCH
tag.csv                   HDFS:      465,564  Local:   465,564  âœ“ MATCH
genome_tags.csv           HDFS:        1,128  Local:     1,128  âœ“ MATCH
genome_scores.csv         HDFS:   11,709,768  Local:11,709,768  âœ“ MATCH
link.csv                  HDFS:       27,278  Local:    27,278  âœ“ MATCH
------------------------------------------------------------
TOTAL                     HDFS:   32,231,279
============================================================

âœ… VERIFICACIÃ“N EXITOSA: Todos los archivos coinciden
```

**Resultado**: 0 discrepancias, 100% de integridad.

### 4. Schema Validation âœ“

Todos los archivos tienen el schema esperado:

**movie.csv**:
- Columnas: `movieId`, `title`, `genres`
- Muestra verificada: "Toy Story (1995)" con gÃ©neros correctos

**rating.csv**:
- Columnas: `userId`, `movieId`, `rating`, `timestamp`
- 20M+ ratings de usuarios verificados

**tag.csv**:
- Columnas: `userId`, `movieId`, `tag`, `timestamp`
- Tags de usuarios libres

**genome_tags.csv**:
- Columnas: `tagId`, `tag`
- 1,128 tags del Tag Genome

**genome_scores.csv**:
- Columnas: `movieId`, `tagId`, `relevance`
- 11.7M scores de relevancia tag-pelÃ­cula

**link.csv**:
- Columnas: `movieId`, `imdbId`, `tmdbId`
- Enlaces a IMDb y TMDb

### 5. Permisos y Acceso âœ“

```bash
docker exec namenode hdfs dfs -ls /data/movielens/csv
```

Permisos: `-rw-r--r--` (lectura para todos, escritura para root)  
ReplicaciÃ³n: Factor 3 (configurado en HDFS)  
Usuario: root  
Grupo: supergroup

**Spark puede leer**: âœ“ Verificado con job de verificaciÃ³n

---

## ğŸ“Š Desglose de Datos

### Registros por Archivo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Archivo              â”‚ Registros    â”‚ % del Total â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ rating.csv           â”‚ 20,000,263   â”‚ 62.0%       â”‚
â”‚ genome_scores.csv    â”‚ 11,709,768   â”‚ 36.3%       â”‚
â”‚ tag.csv              â”‚    465,564   â”‚  1.4%       â”‚
â”‚ movie.csv            â”‚     27,278   â”‚  0.1%       â”‚
â”‚ link.csv             â”‚     27,278   â”‚  0.1%       â”‚
â”‚ genome_tags.csv      â”‚      1,128   â”‚  0.0%       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                â”‚ 32,231,279   â”‚ 100.0%      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### TamaÃ±o por Archivo

```
rating.csv         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 690 MB (77.8%)
genome_scores.csv  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 214 MB (24.1%)
tag.csv            â–ˆ 21 MB (2.4%)
movie.csv          â–ˆ 1.5 MB (0.2%)
link.csv           â–ˆ 0.5 MB (0.1%)
genome_tags.csv    â–ˆ 20 KB (0.0%)
```

---

## ğŸ” Detalles de los Datos

### MovieLens Dataset
- **VersiÃ³n**: MovieLens 20M (2019)
- **PelÃ­culas**: 27,278 tÃ­tulos Ãºnicos
- **Usuarios**: ~138,000 (estimado de rating.csv)
- **Ratings**: 20,000,263 valoraciones (escala 0.5-5.0)
- **Tags de usuarios**: 465,564 etiquetas libres
- **Tag Genome**: 1,128 tags con relevancia para 13,816 pelÃ­culas
- **Periodo temporal**: Varios aÃ±os (verificable en timestamps)

### GÃ©nero Distribution (a explorar en ETL)
Los gÃ©neros estÃ¡n en formato pipe-separated:
```
Adventure|Animation|Children|Comedy|Fantasy
Action|Crime|Thriller
Comedy|Romance
```

Total de gÃ©neros Ãºnicos: ~20 (estimado)

---

## ğŸ› ï¸ Herramientas Creadas

### Script de VerificaciÃ³n
**UbicaciÃ³n**: `scripts/verify_csv_integrity.py`

Funcionalidad:
- Lee todos los CSV desde HDFS con Spark
- Cuenta registros y valida schema
- Compara con conteos locales
- Muestra primeras filas de cada archivo
- Genera reporte detallado

**EjecuciÃ³n**:
```bash
./scripts/recsys-utils.sh spark-submit scripts/verify_csv_integrity.py
```

**Tiempo de ejecuciÃ³n**: ~2 minutos para 885 MB

---

## ğŸ“ Comandos Ejecutados

### CreaciÃ³n de Estructura
```bash
./scripts/recsys-utils.sh hdfs-mkdir /data/movielens/csv
./scripts/recsys-utils.sh hdfs-mkdir /data/movielens_parquet
./scripts/recsys-utils.sh hdfs-mkdir /models/als
./scripts/recsys-utils.sh hdfs-mkdir /streams/ratings
./scripts/recsys-utils.sh hdfs-mkdir /checkpoints
```

### Carga de Datos
```bash
# Para cada CSV (movie, rating, tag, genome_tags, genome_scores, link)
docker cp Dataset/<file>.csv namenode:/tmp/<file>.csv
docker exec namenode hdfs dfs -put /tmp/<file>.csv /data/movielens/csv/
docker exec namenode rm /tmp/<file>.csv
```

### VerificaciÃ³n
```bash
./scripts/recsys-utils.sh hdfs-ls /data/movielens/csv
./scripts/recsys-utils.sh hdfs-du /data/movielens
./scripts/recsys-utils.sh spark-submit scripts/verify_csv_integrity.py
```

---

## ğŸ’¾ Uso de Disco HDFS

```bash
./scripts/recsys-utils.sh hdfs-status
```

**Estado del cluster**:
- Capacidad total: 936.8 GB
- Usado: ~2.6 GB (con replicaciÃ³n factor 3)
- Disponible: 771.6 GB
- Uso: 0.3%

**Espacio por directorio**:
```
/data/movielens/csv     885.4 MB (raw)  â†’  2.6 GB (con replicaciÃ³n 3x)
```

Espacio reservado para prÃ³ximas fases:
- Parquet (estimado): ~300-400 MB (mejor compresiÃ³n)
- Modelos ALS: ~50-100 MB
- Datos streaming: depende de retenciÃ³n (configurar truncate)

---

## ğŸš€ PrÃ³ximos Pasos (Fase 3)

La infraestructura y datos estÃ¡n listos para el ETL.

### Fase 3: ETL a Parquet Tipado
Objetivos:
1. Leer CSV desde `/data/movielens/csv`
2. Tipar columnas correctamente (int, double, timestamp, string)
3. Limpiar nulos y datos inconsistentes
4. Normalizar gÃ©neros (explode pipe-separated)
5. Escribir Parquet optimizado en `/data/movielens_parquet/`

**Archivos a generar**:
- `movies.parquet` - PelÃ­culas tipadas con gÃ©neros normalizados
- `ratings.parquet` - Ratings con tipos correctos, particionado por date
- `tags.parquet` - Tags de usuarios tipados
- `genome_tags.parquet` - Tags del Genome
- `genome_scores.parquet` - Scores de relevancia
- `links.parquet` - Enlaces externos

**Beneficios esperados**:
- âœ… ReducciÃ³n de tamaÃ±o ~60-70% (885 MB â†’ ~300 MB)
- âœ… Lectura 5-10x mÃ¡s rÃ¡pida
- âœ… Tipos fuertemente tipados (sin parsing)
- âœ… CompresiÃ³n columnar (Snappy)
- âœ… Particionado eficiente para queries

**Script a crear**: `movies/src/etl/etl_movielens.py`

---

## ğŸ“ Lecciones Aprendidas

### Optimizaciones Aplicadas
1. **Copia a contenedor primero**: Evita timeouts en `docker cp` â†’ `hdfs dfs -put`
2. **Limpieza temporal**: Borrar `/tmp/` del namenode despuÃ©s de cada upload
3. **VerificaciÃ³n con Spark**: MÃ¡s confiable que `wc -l` para grandes archivos
4. **ReplicaciÃ³n HDFS**: Factor 3 aplicado automÃ¡ticamente (885 MB â†’ 2.6 GB)

### Tiempos de Carga
- movie.csv (1.5 MB): ~2 segundos
- rating.csv (690 MB): ~40 segundos
- genome_scores.csv (214 MB): ~35 segundos
- Resto (~22 MB total): ~5 segundos cada uno

**Total**: ~3 minutos de carga + 2 minutos verificaciÃ³n = **5 minutos**

---

## âœ… Checklist de Completitud

- [x] Estructura HDFS creada (`/data`, `/models`, `/streams`, `/checkpoints`)
- [x] 6 archivos CSV subidos a `/data/movielens/csv`
- [x] Conteos verificados (32.2M registros totales)
- [x] Schema validado para todos los archivos
- [x] Integridad 100% confirmada (conteos locales == HDFS)
- [x] Permisos de lectura para Spark confirmados
- [x] Script de verificaciÃ³n creado y probado
- [x] DocumentaciÃ³n generada

---

## ğŸ” VerificaciÃ³n RÃ¡pida

Para confirmar que todo estÃ¡ OK:

```bash
# Listar archivos
./scripts/recsys-utils.sh hdfs-ls /data/movielens/csv

# Ver uso
./scripts/recsys-utils.sh hdfs-du /data/movielens

# Verificar integridad (2 min)
./scripts/recsys-utils.sh spark-submit scripts/verify_csv_integrity.py
```

**Esperado**:
- 6 archivos CSV visibles
- 885.4 MB de uso (2.6 GB con replicaciÃ³n)
- VerificaciÃ³n exitosa con 0 errores

---

## ğŸ“Š MÃ©tricas de la Fase

| MÃ©trica | Valor |
|---------|-------|
| Archivos cargados | 6/6 (100%) |
| Registros totales | 32,231,279 |
| TamaÃ±o total (raw) | 885.4 MB |
| TamaÃ±o HDFS (3x repl) | 2.6 GB |
| Integridad | 100% |
| Tiempo total | 5 minutos |
| Errores | 0 |

---

**Fase 2 COMPLETADA** âœ…  
**Sistema listo para**: Fase 3 (ETL a Parquet)

---

**Verificado por**: Script Spark automatizado + ValidaciÃ³n manual  
**Ãšltima verificaciÃ³n**: 2025-10-28 09:50 UTC

Para continuar con la Fase 3:
```bash
# Crear script ETL
vim Recomendacion-Gran-Escala/movies/src/etl/etl_movielens.py

# Ejecutar ETL (prÃ³ximo paso)
./scripts/recsys-utils.sh spark-submit movies/src/etl/etl_movielens.py
```
