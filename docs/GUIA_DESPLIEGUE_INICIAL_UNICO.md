# ğŸš€ GuÃ­a de Despliegue Inicial - Primera EjecuciÃ³n

**Sistema de RecomendaciÃ³n de PelÃ­culas en Gran Escala**  
**VersiÃ³n:** 1.0  
**Ãšltima actualizaciÃ³n:** Diciembre 2025

---

> âš ï¸ **IMPORTANTE:** Esta guÃ­a es **solo para la primera vez** que ejecutas el sistema o despuÃ©s de eliminar los volÃºmenes de Docker.
> Para ejecuciones posteriores, consulta `GUIA_DESPLIEGUE_REGULAR.md`.

---

## ğŸ“‹ Tabla de Contenidos

1. [Requisitos Previos](#1-requisitos-previos)
2. [Paso 1: Preparar el Entorno](#paso-1-preparar-el-entorno)
3. [Paso 2: Iniciar Infraestructura Docker](#paso-2-iniciar-infraestructura-docker)
4. [Paso 3: Verificar Servicios](#paso-3-verificar-servicios)
5. [Paso 4: Configurar Fair Scheduler](#paso-4-configurar-fair-scheduler)
6. [Paso 5: Crear Estructura HDFS](#paso-5-crear-estructura-hdfs)
7. [Paso 6: Cargar Datos CSV](#paso-6-cargar-datos-csv)
8. [Paso 7: Ejecutar Pipeline ETL](#paso-7-ejecutar-pipeline-etl)
9. [Paso 8: Configurar Kafka](#paso-8-configurar-kafka)
10. [Paso 9: Iniciar Pipeline de Streaming](#paso-9-iniciar-pipeline-de-streaming)
11. [Paso 10: Verificar Sistema Completo](#paso-10-verificar-sistema-completo)
12. [Checklist Final](#checklist-final)

---

## 1. Requisitos Previos

### Hardware MÃ­nimo

| Recurso | MÃ­nimo | Recomendado |
|---------|--------|-------------|
| **RAM** | 8 GB | 12 GB |
| **CPU** | 4 cores | 6+ cores |
| **Disco** | 20 GB libres | 50 GB libres |

### Software Requerido

- **Docker Engine:** 20.10 o superior
- **Docker Compose:** v2.0 o superior
- **Python:** 3.8+ (para scripts auxiliares)

### Verificar InstalaciÃ³n

```bash
# Verificar Docker
docker --version
docker compose version

# Verificar que Docker estÃ¡ corriendo
docker info

# Verificar recursos disponibles
docker info | grep -E "CPUs|Total Memory"

# Verificar Python
python3 --version
```

### Puertos Necesarios (Deben estar libres)

| Puerto | Servicio |
|--------|----------|
| `8000` | API de Recomendaciones |
| `8080` | Spark Master UI |
| `8081` | Spark Worker UI |
| `8088` | YARN ResourceManager UI |
| `8501` | Dashboard Streamlit |
| `9000` | HDFS NameNode RPC |
| `9092` | Kafka (interno) |
| `9093` | Kafka (externo) |
| `9870` | HDFS NameNode UI |

Verificar puertos libres:
```bash
# Verificar si algÃºn puerto estÃ¡ en uso
sudo lsof -i :8080,8081,8088,8000,8501,9870,9092,9093,9000
```

---

## Paso 1: Preparar el Entorno

### 1.1. Navegar al Proyecto

```bash
cd /home/abraham/Escritorio/PGVD/Recomendacion-Gran-Escala
```

### 1.2. Dar Permisos a Scripts

```bash
chmod +x scripts/*.sh
```

### 1.3. Verificar Estructura del Proyecto

```bash
# Verificar que existen los archivos necesarios
ls -la docker-compose.yml fairscheduler.xml
ls -la Dataset/
ls -la scripts/
```

**Archivos esperados en Dataset/:**
- `movie.csv`
- `rating.csv`
- `tag.csv`
- `genome_tags.csv`
- `genome_scores.csv`
- `link.csv`

---

## Paso 2: Iniciar Infraestructura Docker

### 2.1. Iniciar Todos los Servicios

```bash
./scripts/start-system.sh
```

**Tiempo estimado:** 2-3 minutos

### 2.2. Verificar Contenedores

```bash
docker compose ps
```

**Contenedores esperados (10 en total):**

| Contenedor | Estado Esperado |
|------------|-----------------|
| `namenode` | Up (healthy) |
| `datanode` | Up (healthy) |
| `resourcemanager` | Up (healthy) |
| `nodemanager` | Up (healthy) |
| `spark-master` | Up |
| `spark-worker` | Up |
| `zookeeper` | Up |
| `kafka` | Up |
| `recs-api` | Up |
| `recs-dashboard` | Up |

### 2.3. Esperar InicializaciÃ³n Completa

```bash
# Esperar 60 segundos para que todos los servicios se inicialicen
echo "Esperando inicializaciÃ³n de servicios..."
sleep 60
```

---

## Paso 3: Verificar Servicios

### 3.1. VerificaciÃ³n AutomÃ¡tica

```bash
./scripts/run-all-tests.sh
```

**Tiempo estimado:** 3-5 minutos

**Tests ejecutados:**
- âœ… Conectividad de servicios
- âœ… HDFS (lectura/escritura)
- âœ… Kafka (topics/producer/consumer)
- âœ… Spark Standalone
- âœ… Spark + Kafka Integration

### 3.2. VerificaciÃ³n Manual de Servicios CrÃ­ticos

```bash
# HDFS
echo "=== HDFS ===" && curl -s http://localhost:9870 | grep -q "Hadoop" && echo "âœ… OK" || echo "âŒ ERROR"

# YARN
echo "=== YARN ===" && curl -s http://localhost:8088 | grep -q "cluster" && echo "âœ… OK" || echo "âŒ ERROR"

# Spark
echo "=== Spark ===" && curl -s http://localhost:8080 | grep -q "Spark" && echo "âœ… OK" || echo "âŒ ERROR"

# API
echo "=== API ===" && curl -s http://localhost:8000/metrics/health | grep -q "healthy" && echo "âœ… OK" || echo "âŒ ERROR"
```

### 3.3. Verificar Recursos de Spark

```bash
./scripts/check-spark-resources.sh
```

**Salida esperada:**
```
âœ… Servicios corriendo: spark-master, spark-worker
âœ… Workers registrados: 1
   Memoria: 4G
   Cores: 4-6
```

---

## Paso 4: Configurar Fair Scheduler

### 4.1. Verificar que fairscheduler.xml Existe

```bash
ls -la fairscheduler.xml
```

### 4.2. Copiar a Contenedores Spark

```bash
# Crear directorio de configuraciÃ³n
docker exec spark-master mkdir -p /opt/spark/conf
docker exec spark-worker mkdir -p /opt/spark/conf

# Copiar archivo
docker cp fairscheduler.xml spark-master:/opt/spark/conf/
docker cp fairscheduler.xml spark-worker:/opt/spark/conf/
```

### 4.3. Verificar ConfiguraciÃ³n

```bash
# Verificar en spark-master
docker exec spark-master cat /opt/spark/conf/fairscheduler.xml | head -10

# Verificar en spark-worker
docker exec spark-worker cat /opt/spark/conf/fairscheduler.xml | head -10
```

**Pools configurados:**
- `streaming` (prioridad ALTA, peso 2)
- `batch` (prioridad MEDIA, peso 1)
- `generator` (prioridad BAJA, peso 1)
- `default` (peso 1)

---

## Paso 5: Crear Estructura HDFS

### 5.1. Crear Directorios Necesarios

```bash
# Datos CSV originales
./scripts/recsys-utils.sh hdfs-mkdir /data/movielens/csv

# Datos Parquet procesados
./scripts/recsys-utils.sh hdfs-mkdir /data/movielens_parquet

# Features de contenido
./scripts/recsys-utils.sh hdfs-mkdir /data/content_features

# Streaming
./scripts/recsys-utils.sh hdfs-mkdir /streams/ratings

# Checkpoints
./scripts/recsys-utils.sh hdfs-mkdir /checkpoints

# Outputs de analytics
./scripts/recsys-utils.sh hdfs-mkdir /outputs/analytics
```

### 5.2. Verificar Estructura

```bash
./scripts/recsys-utils.sh hdfs-ls /
```

---

## Paso 6: Cargar Datos CSV

### 6.1. Subir Archivos CSV a HDFS

```bash
# Asegurarse de estar en el directorio raÃ­z del proyecto
cd /home/abraham/Escritorio/PGVD/Recomendacion-Gran-Escala

# Subir los 6 archivos CSV
./scripts/recsys-utils.sh hdfs-put Dataset/movie.csv /data/movielens/csv/
./scripts/recsys-utils.sh hdfs-put Dataset/rating.csv /data/movielens/csv/
./scripts/recsys-utils.sh hdfs-put Dataset/tag.csv /data/movielens/csv/
./scripts/recsys-utils.sh hdfs-put Dataset/genome_tags.csv /data/movielens/csv/
./scripts/recsys-utils.sh hdfs-put Dataset/genome_scores.csv /data/movielens/csv/
./scripts/recsys-utils.sh hdfs-put Dataset/link.csv /data/movielens/csv/
```

**Tiempo estimado:** 5-10 minutos (dependiendo del tamaÃ±o de datos)

### 6.2. Verificar Archivos Subidos

```bash
# Listar archivos en HDFS
./scripts/recsys-utils.sh hdfs-ls /data/movielens/csv
```

**Resultado esperado:** 6 archivos CSV

### 6.3. Verificar Integridad

```bash
./scripts/recsys-utils.sh spark-submit scripts/verify_csv_integrity.py
```

**Resultado esperado:** ~32 millones de registros totales

---

## Paso 7: Ejecutar Pipeline ETL

### 7.1. ETL: CSV a Parquet (Fase 3)

```bash
./scripts/recsys-utils.sh spark-submit movies/src/etl/etl_movielens.py
```

**Tiempo estimado:** 10-15 minutos  
**QuÃ© hace:** Convierte CSV a Parquet con schemas tipados y particionado inteligente

Verificar:
```bash
./scripts/recsys-utils.sh hdfs-ls /data/movielens_parquet
```

### 7.2. Generar Features de Contenido (Fase 4)

```bash
./scripts/recsys-utils.sh spark-submit movies/src/features/generate_content_features.py
```

**Tiempo estimado:** 5-8 minutos  
**QuÃ© hace:** Crea vectores de features (gÃ©neros + genome tags) para cada pelÃ­cula

Verificar:
```bash
./scripts/recsys-utils.sh hdfs-ls /data/content_features
```

---

## Paso 8: Configurar Kafka

### 8.1. Crear Topics

```bash
python3 movies/src/streaming/create_kafka_topics.py
```

**Tiempo estimado:** 30 segundos  
**Topics creados:**
- `ratings` (6 particiones)
- `metrics` (3 particiones)

### 8.2. Verificar Topics

```bash
./scripts/recsys-utils.sh kafka-topics
```

---

## Paso 9: Iniciar Pipeline de Streaming

### 9.1. Terminal 1 - Generador de Datos

```bash
# Generar ratings sintÃ©ticos (1 rating/segundo)
./scripts/run-latent-generator.sh 1
```

**QuÃ© hace:**
- ğŸ“Š Genera ratings basados en factores latentes (FactorizaciÃ³n Matricial)
- ğŸ“¤ EnvÃ­a datos al topic Kafka `ratings`
- ğŸ¯ Usa pool `generator` (prioridad baja)

**Salida esperada:**
```
âœ… STREAMING INICIADO
Topic Kafka: ratings
Throughput: 100 ratings/segundo
```

**Dejar correr 1-2 minutos**, luego puedes detenerlo con `Ctrl+C` o dejarlo en background.

### 9.2. Verificar Datos en Kafka

```bash
# Ver cuÃ¡ntos mensajes se han generado
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic ratings 2>/dev/null | \
  awk -F: '{sum += $NF} END {print "Total ratings:", sum}'

# Ver un mensaje de ejemplo
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ratings \
  --max-messages 3 \
  --timeout-ms 5000 2>/dev/null
```

### 9.3. Terminal 2 - Procesador de Streaming

```bash
./scripts/run-streaming-processor.sh
```

**QuÃ© hace:**
- ğŸ“¥ Lee del topic `ratings` de Kafka
- ğŸªŸ Calcula ventanas: Tumbling (1 min) y Sliding (5 min)
- ğŸ’¾ Guarda agregaciones en HDFS `/streams/ratings/`
- ğŸ“Š Publica mÃ©tricas al topic `metrics`
- ğŸ¯ Usa pool `streaming` (prioridad alta)

**Salida esperada:**
```
-------------------------------------------
Batch: 0
-------------------------------------------
Batch: 1
-------------------------------------------
```

âš ï¸ **IMPORTANTE:** Dejar este proceso corriendo

### 9.4. Terminal 3 - Analytics Batch (Opcional)

**Esperar 2-3 minutos** despuÃ©s de iniciar el streaming, luego:

```bash
./scripts/run-batch-analytics.sh
```

**QuÃ© hace:**
- ğŸ“Š Analiza distribuciÃ³n de ratings (global y por gÃ©nero)
- ğŸ† Calcula Top-N pelÃ­culas por periodo
- ğŸ“ˆ Identifica pelÃ­culas trending
- ğŸ’¾ Guarda resultados en HDFS `/outputs/analytics/`

---

## Paso 10: Verificar Sistema Completo

### 10.1. Probar Endpoints de la API

```bash
# Health check
curl -s http://localhost:8000/metrics/health | jq

# Resumen de mÃ©tricas
curl -s http://localhost:8000/metrics/summary | jq

# Top-N pelÃ­culas
curl -s http://localhost:8000/metrics/topn?limit=5 | jq

# MÃ©tricas por gÃ©nero
curl -s http://localhost:8000/metrics/genres | jq
```

### 10.2. Abrir Dashboard

```bash
# Abrir en navegador (Linux)
xdg-open http://localhost:8501
```

O manualmente: **http://localhost:8501**

**Verificar que se vea:**
- âœ… MÃ©tricas en tiempo real actualizÃ¡ndose
- âœ… GrÃ¡ficas de ratings por minuto
- âœ… Top pelÃ­culas
- âœ… DistribuciÃ³n de gÃ©neros

---

## Checklist Final

### Primera EjecuciÃ³n Completada

- [ ] Requisitos instalados (Docker, Python)
- [ ] Permisos dados a scripts (`chmod +x`)
- [ ] Infraestructura iniciada (10 contenedores corriendo)
- [ ] Tests pasados (suite completa)
- [ ] Fair Scheduler configurado
- [ ] Directorios HDFS creados
- [ ] CSVs subidos a HDFS (6 archivos)
- [ ] Integridad verificada
- [ ] ETL Parquet ejecutado
- [ ] Features de contenido generadas
- [ ] Topics Kafka creados
- [ ] Generador de datos funcionando
- [ ] Streaming processor funcionando
- [ ] API respondiendo
- [ ] Dashboard mostrando mÃ©tricas

### Estado Final Esperado

```
âœ… Infraestructura: HDFS, YARN, Spark, Kafka
âœ… Fair Scheduler: Configurado y funcionando
âœ… Datos: CSV â†’ Parquet â†’ Features
âœ… Generador Latente: Produciendo ratings sintÃ©ticos
âœ… Streaming Processor: Procesando y agregando datos
âœ… API: Respondiendo con mÃ©tricas en tiempo real
âœ… Dashboard: Mostrando visualizaciones actualizadas
```

---

## ğŸ†˜ Problemas Comunes en Primera EjecuciÃ³n

### Contenedores no inician

```bash
./scripts/stop-system.sh
docker compose down --volumes  # Solo si quieres limpiar todo
./scripts/start-system.sh
```

### Puerto en uso

```bash
# Identificar proceso usando el puerto
sudo lsof -i :8080

# Matar proceso si es necesario
sudo kill -9 <PID>
```

### HDFS no accesible

```bash
# Reiniciar namenode
docker restart namenode
sleep 30
```

### ModuleNotFoundError: numpy

```bash
./scripts/instalar-dependencias-spark.sh
```

### Memoria insuficiente

```bash
# Verificar recursos
docker stats

# Si es necesario, ajustar en docker-compose.yml
# SPARK_WORKER_MEMORY=2G  (reducir de 4G)
```

---

## â­ï¸ Siguiente Paso

Una vez completada la primera ejecuciÃ³n, consulta:
- **`GUIA_DESPLIEGUE_REGULAR.md`** - Para ejecuciones posteriores
- **`DOCUMENTACION.md`** - Para documentaciÃ³n tÃ©cnica completa

---

**Tiempo total estimado de primera ejecuciÃ³n:** 45-60 minutos
