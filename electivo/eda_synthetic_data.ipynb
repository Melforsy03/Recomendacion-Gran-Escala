{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f8e5f3",
   "metadata": {},
   "source": [
    "# Comparaci√≥n de Datos Originales vs Sint√©ticos - Dataset de Pel√≠culas\n",
    "\n",
    "Este notebook compara el dataset original de pel√≠culas con datos sint√©ticos generados, analizando:\n",
    "- Generaci√≥n de datos sint√©ticos basados en distribuciones reales\n",
    "- Comparaci√≥n de estad√≠sticas descriptivas\n",
    "- Comparaci√≥n de distribuciones\n",
    "- Comparaci√≥n de correlaciones\n",
    "- Validaci√≥n de similitud entre datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c11087",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as y Carga de Datos Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp, mannwhitneyu, chi2_contingency\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de estilo para visualizaciones\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"Versiones:\")\n",
    "print(f\"  ‚Ä¢ Pandas: {pd.__version__}\")\n",
    "print(f\"  ‚Ä¢ NumPy: {np.__version__}\")\n",
    "print(f\"  ‚Ä¢ Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"  ‚Ä¢ Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset original de pel√≠culas\n",
    "print(\"=\" * 80)\n",
    "print(\"CARGANDO DATASET ORIGINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with open('movies.json', 'r', encoding='utf-8') as f:\n",
    "    movies_data = json.load(f)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_original = pd.DataFrame(movies_data)\n",
    "\n",
    "print(f\"‚úì Dataset original cargado exitosamente\")\n",
    "print(f\"Dimensiones: {df_original.shape[0]} pel√≠culas, {df_original.shape[1]} caracter√≠sticas\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08987062",
   "metadata": {},
   "source": [
    "## 2. Generaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "Generaremos datos sint√©ticos que repliquen las caracter√≠sticas estad√≠sticas del dataset original:\n",
    "- Misma distribuci√≥n de puntuaciones (puan)\n",
    "- Misma distribuci√≥n de popularidad (pop)\n",
    "- Mismas proporciones de g√©neros\n",
    "- Correlaci√≥n similar entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f510087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GENERANDO DATOS SINT√âTICOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Configurar semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# N√∫mero de pel√≠culas sint√©ticas (mismo tama√±o que el original)\n",
    "n_synthetic = len(df_original)\n",
    "\n",
    "# 1. Generar puntuaciones con distribuci√≥n similar\n",
    "print(\"\\n1. Generando puntuaciones (puan)...\")\n",
    "puan_mean = df_original['puan'].mean()\n",
    "puan_std = df_original['puan'].std()\n",
    "puan_min = df_original['puan'].min()\n",
    "puan_max = df_original['puan'].max()\n",
    "\n",
    "# Generar con distribuci√≥n normal truncada\n",
    "puan_synthetic = np.random.normal(puan_mean, puan_std, n_synthetic)\n",
    "puan_synthetic = np.clip(puan_synthetic, puan_min, puan_max)\n",
    "\n",
    "print(f\"   Original - Media: {puan_mean:.2f}, Std: {puan_std:.2f}\")\n",
    "print(f\"   Sint√©tico - Media: {puan_synthetic.mean():.2f}, Std: {puan_synthetic.std():.2f}\")\n",
    "\n",
    "# 2. Generar popularidad con distribuci√≥n similar\n",
    "print(\"\\n2. Generando popularidad (pop)...\")\n",
    "pop_mean = df_original['pop'].mean()\n",
    "pop_std = df_original['pop'].std()\n",
    "pop_min = df_original['pop'].min()\n",
    "pop_max = df_original['pop'].max()\n",
    "\n",
    "# Generar con distribuci√≥n normal truncada y redondear a enteros\n",
    "pop_synthetic = np.random.normal(pop_mean, pop_std, n_synthetic)\n",
    "pop_synthetic = np.clip(pop_synthetic, pop_min, pop_max)\n",
    "pop_synthetic = np.round(pop_synthetic).astype(int)\n",
    "\n",
    "print(f\"   Original - Media: {pop_mean:.2f}, Std: {pop_std:.2f}\")\n",
    "print(f\"   Sint√©tico - Media: {pop_synthetic.mean():.2f}, Std: {pop_synthetic.std():.2f}\")\n",
    "\n",
    "# 3. Generar correlaci√≥n entre puan y pop\n",
    "print(\"\\n3. Ajustando correlaci√≥n entre puan y pop...\")\n",
    "original_corr = df_original[['puan', 'pop']].corr().iloc[0, 1]\n",
    "\n",
    "# Crear matriz de covarianza\n",
    "cov_matrix = np.array([\n",
    "    [puan_std**2, original_corr * puan_std * pop_std],\n",
    "    [original_corr * puan_std * pop_std, pop_std**2]\n",
    "])\n",
    "\n",
    "# Generar datos correlacionados\n",
    "data_correlated = np.random.multivariate_normal(\n",
    "    [puan_mean, pop_mean], \n",
    "    cov_matrix, \n",
    "    n_synthetic\n",
    ")\n",
    "\n",
    "puan_synthetic = np.clip(data_correlated[:, 0], puan_min, puan_max)\n",
    "pop_synthetic = np.clip(data_correlated[:, 1], pop_min, pop_max)\n",
    "pop_synthetic = np.round(pop_synthetic).astype(int)\n",
    "\n",
    "synthetic_corr = np.corrcoef(puan_synthetic, pop_synthetic)[0, 1]\n",
    "print(f\"   Original - Correlaci√≥n: {original_corr:.4f}\")\n",
    "print(f\"   Sint√©tico - Correlaci√≥n: {synthetic_corr:.4f}\")\n",
    "\n",
    "# 4. Generar g√©neros con distribuci√≥n similar\n",
    "print(\"\\n4. Generando g√©neros...\")\n",
    "genre1_probs = df_original['genre_1'].value_counts(normalize=True)\n",
    "genre2_probs = df_original['genre_2'].value_counts(normalize=True)\n",
    "\n",
    "genre1_synthetic = np.random.choice(\n",
    "    genre1_probs.index, \n",
    "    size=n_synthetic, \n",
    "    p=genre1_probs.values\n",
    ")\n",
    "\n",
    "genre2_synthetic = np.random.choice(\n",
    "    genre2_probs.index, \n",
    "    size=n_synthetic, \n",
    "    p=genre2_probs.values\n",
    ")\n",
    "\n",
    "print(f\"   G√©neros primarios √∫nicos: {len(np.unique(genre1_synthetic))}\")\n",
    "print(f\"   G√©neros secundarios √∫nicos: {len(np.unique(genre2_synthetic))}\")\n",
    "\n",
    "# 5. Generar IDs y nombres\n",
    "print(\"\\n5. Generando IDs y nombres...\")\n",
    "ids_synthetic = np.arange(10000, 10000 + n_synthetic)\n",
    "names_synthetic = [f\"Synthetic Movie {i}\" for i in range(1, n_synthetic + 1)]\n",
    "\n",
    "# 6. Generar descripciones sint√©ticas\n",
    "print(\"\\n6. Generando descripciones...\")\n",
    "descriptions_synthetic = [\n",
    "    f\"This is a synthetic {g1}/{g2} movie with rating {p:.1f} and popularity {pop}.\"\n",
    "    for g1, g2, p, pop in zip(genre1_synthetic, genre2_synthetic, puan_synthetic, pop_synthetic)\n",
    "]\n",
    "\n",
    "# Crear DataFrame sint√©tico\n",
    "df_synthetic = pd.DataFrame({\n",
    "    'ID': ids_synthetic,\n",
    "    'name': names_synthetic,\n",
    "    'puan': puan_synthetic,\n",
    "    'genre_1': genre1_synthetic,\n",
    "    'genre_2': genre2_synthetic,\n",
    "    'pop': pop_synthetic,\n",
    "    'description': descriptions_synthetic\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úì Dataset sint√©tico generado exitosamente\")\n",
    "print(f\"Dimensiones: {df_synthetic.shape[0]} pel√≠culas, {df_synthetic.shape[1]} caracter√≠sticas\")\n",
    "\n",
    "# Guardar datos sint√©ticos\n",
    "df_synthetic.to_json('movies_synthetic.json', orient='records', indent=2)\n",
    "print(f\"\\n‚úì Datos sint√©ticos guardados en 'movies_synthetic.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a58a72",
   "metadata": {},
   "source": [
    "## 3. Comparaci√≥n de Estad√≠sticas Descriptivas\n",
    "\n",
    "Compararemos las estad√≠sticas b√°sicas entre el dataset original y el sint√©tico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACI√ìN DE ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Funci√≥n para calcular estad√≠sticas\n",
    "def calculate_stats(df, label):\n",
    "    stats_dict = {\n",
    "        'Dataset': label,\n",
    "        'n': len(df),\n",
    "        'puan_mean': df['puan'].mean(),\n",
    "        'puan_std': df['puan'].std(),\n",
    "        'puan_min': df['puan'].min(),\n",
    "        'puan_max': df['puan'].max(),\n",
    "        'puan_median': df['puan'].median(),\n",
    "        'pop_mean': df['pop'].mean(),\n",
    "        'pop_std': df['pop'].std(),\n",
    "        'pop_min': df['pop'].min(),\n",
    "        'pop_max': df['pop'].max(),\n",
    "        'pop_median': df['pop'].median(),\n",
    "        'correlation': df[['puan', 'pop']].corr().iloc[0, 1]\n",
    "    }\n",
    "    return stats_dict\n",
    "\n",
    "# Calcular estad√≠sticas para ambos datasets\n",
    "stats_original = calculate_stats(df_original, 'Original')\n",
    "stats_synthetic = calculate_stats(df_synthetic, 'Sint√©tico')\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "comparison_df = pd.DataFrame([stats_original, stats_synthetic])\n",
    "\n",
    "# Calcular diferencias porcentuales\n",
    "diff_row = {\n",
    "    'Dataset': 'Diferencia %',\n",
    "    'n': 0,\n",
    "    'puan_mean': abs(stats_original['puan_mean'] - stats_synthetic['puan_mean']) / stats_original['puan_mean'] * 100,\n",
    "    'puan_std': abs(stats_original['puan_std'] - stats_synthetic['puan_std']) / stats_original['puan_std'] * 100,\n",
    "    'puan_min': abs(stats_original['puan_min'] - stats_synthetic['puan_min']) / stats_original['puan_min'] * 100,\n",
    "    'puan_max': abs(stats_original['puan_max'] - stats_synthetic['puan_max']) / stats_original['puan_max'] * 100,\n",
    "    'puan_median': abs(stats_original['puan_median'] - stats_synthetic['puan_median']) / stats_original['puan_median'] * 100,\n",
    "    'pop_mean': abs(stats_original['pop_mean'] - stats_synthetic['pop_mean']) / stats_original['pop_mean'] * 100,\n",
    "    'pop_std': abs(stats_original['pop_std'] - stats_synthetic['pop_std']) / stats_original['pop_std'] * 100,\n",
    "    'pop_min': abs(stats_original['pop_min'] - stats_synthetic['pop_min']) / abs(stats_original['pop_min']) * 100 if stats_original['pop_min'] != 0 else 0,\n",
    "    'pop_max': abs(stats_original['pop_max'] - stats_synthetic['pop_max']) / stats_original['pop_max'] * 100,\n",
    "    'pop_median': abs(stats_original['pop_median'] - stats_synthetic['pop_median']) / stats_original['pop_median'] * 100,\n",
    "    'correlation': abs(stats_original['correlation'] - stats_synthetic['correlation']) / abs(stats_original['correlation']) * 100\n",
    "}\n",
    "\n",
    "comparison_df = pd.concat([comparison_df, pd.DataFrame([diff_row])], ignore_index=True)\n",
    "\n",
    "# Formatear para visualizaci√≥n\n",
    "print(\"\\nCOMPARACI√ìN NUM√âRICA:\")\n",
    "print(\"=\" * 80)\n",
    "display_df = comparison_df.copy()\n",
    "for col in display_df.columns:\n",
    "    if col != 'Dataset':\n",
    "        display_df[col] = display_df[col].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "# Resumen de calidad\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUACI√ìN DE SIMILITUD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular promedio de diferencias porcentuales\n",
    "avg_diff = np.mean([\n",
    "    diff_row['puan_mean'], diff_row['puan_std'], diff_row['puan_median'],\n",
    "    diff_row['pop_mean'], diff_row['pop_std'], diff_row['pop_median'],\n",
    "    diff_row['correlation']\n",
    "])\n",
    "\n",
    "print(f\"\\nDiferencia promedio: {avg_diff:.2f}%\")\n",
    "\n",
    "if avg_diff < 1:\n",
    "    print(\"‚úì EXCELENTE: Los datos sint√©ticos son muy similares al original\")\n",
    "elif avg_diff < 5:\n",
    "    print(\"‚úì BUENO: Los datos sint√©ticos son similares al original\")\n",
    "elif avg_diff < 10:\n",
    "    print(\"‚ö† ACEPTABLE: Los datos sint√©ticos son moderadamente similares\")\n",
    "else:\n",
    "    print(\"‚ùå POBRE: Los datos sint√©ticos difieren significativamente\")\n",
    "\n",
    "print(f\"\\nDiferencias clave:\")\n",
    "print(f\"  ‚Ä¢ Puntuaci√≥n media: {diff_row['puan_mean']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Popularidad media: {diff_row['pop_mean']:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Correlaci√≥n: {diff_row['correlation']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb67d0",
   "metadata": {},
   "source": [
    "## 4. Comparaci√≥n Visual de Distribuciones\n",
    "\n",
    "Visualizaremos las distribuciones de puntuaci√≥n y popularidad para ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec84379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n visual de distribuciones\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. Histograma de Puntuaci√≥n\n",
    "axes[0, 0].hist(df_original['puan'], bins=50, alpha=0.6, label='Original', \n",
    "                color='skyblue', edgecolor='black', density=True)\n",
    "axes[0, 0].hist(df_synthetic['puan'], bins=50, alpha=0.6, label='Sint√©tico', \n",
    "                color='salmon', edgecolor='black', density=True)\n",
    "axes[0, 0].set_xlabel('Puntuaci√≥n', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Densidad', fontsize=12)\n",
    "axes[0, 0].set_title('Distribuci√≥n de Puntuaciones', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box Plot de Puntuaci√≥n\n",
    "bp_data = [df_original['puan'], df_synthetic['puan']]\n",
    "bp = axes[0, 1].boxplot(bp_data, labels=['Original', 'Sint√©tico'], patch_artist=True,\n",
    "                         medianprops=dict(color='red', linewidth=2))\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "axes[0, 1].set_ylabel('Puntuaci√≥n', fontsize=12)\n",
    "axes[0, 1].set_title('Box Plot - Puntuaciones', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Q-Q Plot de Puntuaci√≥n\n",
    "from scipy.stats import probplot\n",
    "probplot(df_original['puan'], dist=\"norm\", plot=axes[0, 2])\n",
    "axes[0, 2].set_title('Q-Q Plot - Original (Puntuaci√≥n)', fontsize=14, fontweight='bold')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histograma de Popularidad\n",
    "axes[1, 0].hist(df_original['pop'], bins=50, alpha=0.6, label='Original', \n",
    "                color='lightgreen', edgecolor='black', density=True)\n",
    "axes[1, 0].hist(df_synthetic['pop'], bins=50, alpha=0.6, label='Sint√©tico', \n",
    "                color='orchid', edgecolor='black', density=True)\n",
    "axes[1, 0].set_xlabel('Popularidad', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Densidad', fontsize=12)\n",
    "axes[1, 0].set_title('Distribuci√≥n de Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Box Plot de Popularidad\n",
    "bp_data = [df_original['pop'], df_synthetic['pop']]\n",
    "bp = axes[1, 1].boxplot(bp_data, labels=['Original', 'Sint√©tico'], patch_artist=True,\n",
    "                         medianprops=dict(color='red', linewidth=2))\n",
    "bp['boxes'][0].set_facecolor('lightgreen')\n",
    "bp['boxes'][1].set_facecolor('plum')\n",
    "axes[1, 1].set_ylabel('Popularidad', fontsize=12)\n",
    "axes[1, 1].set_title('Box Plot - Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Q-Q Plot de Popularidad\n",
    "probplot(df_original['pop'], dist=\"norm\", plot=axes[1, 2])\n",
    "axes[1, 2].set_title('Q-Q Plot - Original (Popularidad)', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Interpretaci√≥n:\")\n",
    "print(\"  ‚Ä¢ Los histogramas superpuestos muestran qu√© tan bien coinciden las distribuciones\")\n",
    "print(\"  ‚Ä¢ Los box plots permiten comparar mediana, cuartiles y outliers\")\n",
    "print(\"  ‚Ä¢ Los Q-Q plots eval√∫an la normalidad de las distribuciones originales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ead91",
   "metadata": {},
   "source": [
    "## 5. Pruebas Estad√≠sticas de Similitud\n",
    "\n",
    "Realizaremos pruebas estad√≠sticas para validar que las distribuciones son similares:\n",
    "- **Test de Kolmogorov-Smirnov**: Compara distribuciones\n",
    "- **Test de Mann-Whitney U**: Compara medianas\n",
    "- **Test Chi-cuadrado**: Compara distribuciones de g√©neros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71186cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PRUEBAS ESTAD√çSTICAS DE SIMILITUD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Funci√≥n para interpretar p-value (H0: las distribuciones son iguales)\n",
    "def interpret_similarity_test(p_value, alpha=0.05):\n",
    "    if p_value > alpha:\n",
    "        return \"‚úì NO RECHAZAR H‚ÇÄ\", \"Las distribuciones SON similares\"\n",
    "    else:\n",
    "        return \"‚ùå RECHAZAR H‚ÇÄ\", \"Las distribuciones NO son similares\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Test de Kolmogorov-Smirnov para Puntuaci√≥n\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"1. TEST DE KOLMOGOROV-SMIRNOV - PUNTUACI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"H‚ÇÄ: Las distribuciones de puntuaci√≥n son iguales\")\n",
    "print(\"H‚ÇÅ: Las distribuciones de puntuaci√≥n son diferentes\")\n",
    "\n",
    "ks_stat_puan, ks_p_puan = ks_2samp(df_original['puan'], df_synthetic['puan'])\n",
    "decision, interpretation = interpret_similarity_test(ks_p_puan)\n",
    "\n",
    "print(f\"\\nEstad√≠stico KS: {ks_stat_puan:.6f}\")\n",
    "print(f\"P-valor: {ks_p_puan:.6f}\")\n",
    "print(f\"Decisi√≥n (Œ±=0.05): {decision}\")\n",
    "print(f\"Interpretaci√≥n: {interpretation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Test de Kolmogorov-Smirnov para Popularidad\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"2. TEST DE KOLMOGOROV-SMIRNOV - POPULARIDAD\")\n",
    "print(\"=\" * 80)\n",
    "print(\"H‚ÇÄ: Las distribuciones de popularidad son iguales\")\n",
    "print(\"H‚ÇÅ: Las distribuciones de popularidad son diferentes\")\n",
    "\n",
    "ks_stat_pop, ks_p_pop = ks_2samp(df_original['pop'], df_synthetic['pop'])\n",
    "decision, interpretation = interpret_similarity_test(ks_p_pop)\n",
    "\n",
    "print(f\"\\nEstad√≠stico KS: {ks_stat_pop:.6f}\")\n",
    "print(f\"P-valor: {ks_p_pop:.6f}\")\n",
    "print(f\"Decisi√≥n (Œ±=0.05): {decision}\")\n",
    "print(f\"Interpretaci√≥n: {interpretation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Test de Mann-Whitney U para Puntuaci√≥n\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"3. TEST DE MANN-WHITNEY U - PUNTUACI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"H‚ÇÄ: Las medianas de puntuaci√≥n son iguales\")\n",
    "print(\"H‚ÇÅ: Las medianas de puntuaci√≥n son diferentes\")\n",
    "\n",
    "mw_stat_puan, mw_p_puan = mannwhitneyu(df_original['puan'], df_synthetic['puan'], alternative='two-sided')\n",
    "decision, interpretation = interpret_similarity_test(mw_p_puan)\n",
    "\n",
    "print(f\"\\nEstad√≠stico U: {mw_stat_puan:.0f}\")\n",
    "print(f\"P-valor: {mw_p_puan:.6f}\")\n",
    "print(f\"Decisi√≥n (Œ±=0.05): {decision}\")\n",
    "print(f\"Interpretaci√≥n: {interpretation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Test de Mann-Whitney U para Popularidad\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"4. TEST DE MANN-WHITNEY U - POPULARIDAD\")\n",
    "print(\"=\" * 80)\n",
    "print(\"H‚ÇÄ: Las medianas de popularidad son iguales\")\n",
    "print(\"H‚ÇÅ: Las medianas de popularidad son diferentes\")\n",
    "\n",
    "mw_stat_pop, mw_p_pop = mannwhitneyu(df_original['pop'], df_synthetic['pop'], alternative='two-sided')\n",
    "decision, interpretation = interpret_similarity_test(mw_p_pop)\n",
    "\n",
    "print(f\"\\nEstad√≠stico U: {mw_stat_pop:.0f}\")\n",
    "print(f\"P-valor: {mw_p_pop:.6f}\")\n",
    "print(f\"Decisi√≥n (Œ±=0.05): {decision}\")\n",
    "print(f\"Interpretaci√≥n: {interpretation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Test Chi-cuadrado para G√©neros Primarios\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"5. TEST CHI-CUADRADO - DISTRIBUCI√ìN DE G√âNEROS PRIMARIOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"H‚ÇÄ: Las distribuciones de g√©neros son independientes del dataset\")\n",
    "print(\"H‚ÇÅ: Las distribuciones de g√©neros dependen del dataset\")\n",
    "\n",
    "# Crear tabla de contingencia para top 10 g√©neros\n",
    "top_genres = df_original['genre_1'].value_counts().head(10).index\n",
    "orig_counts = df_original[df_original['genre_1'].isin(top_genres)]['genre_1'].value_counts().sort_index()\n",
    "synt_counts = df_synthetic[df_synthetic['genre_1'].isin(top_genres)]['genre_1'].value_counts().sort_index()\n",
    "\n",
    "# Alinear √≠ndices\n",
    "all_genres = sorted(set(orig_counts.index) | set(synt_counts.index))\n",
    "orig_aligned = [orig_counts.get(g, 0) for g in all_genres]\n",
    "synt_aligned = [synt_counts.get(g, 0) for g in all_genres]\n",
    "\n",
    "contingency_table = np.array([orig_aligned, synt_aligned])\n",
    "\n",
    "chi2_stat, chi2_p, dof, expected = chi2_contingency(contingency_table)\n",
    "decision, interpretation = interpret_similarity_test(chi2_p)\n",
    "\n",
    "print(f\"\\nEstad√≠stico œá¬≤: {chi2_stat:.6f}\")\n",
    "print(f\"Grados de libertad: {dof}\")\n",
    "print(f\"P-valor: {chi2_p:.6f}\")\n",
    "print(f\"Decisi√≥n (Œ±=0.05): {decision}\")\n",
    "print(f\"Interpretaci√≥n: {interpretation}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN\n",
    "# ============================================================================\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN DE PRUEBAS DE SIMILITUD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Prueba': [\n",
    "        'KS - Puntuaci√≥n',\n",
    "        'KS - Popularidad',\n",
    "        'Mann-Whitney - Puntuaci√≥n',\n",
    "        'Mann-Whitney - Popularidad',\n",
    "        'Chi-cuadrado - G√©neros'\n",
    "    ],\n",
    "    'P-valor': [ks_p_puan, ks_p_pop, mw_p_puan, mw_p_pop, chi2_p],\n",
    "    'Resultado': [\n",
    "        'Similar' if ks_p_puan > 0.05 else 'Diferente',\n",
    "        'Similar' if ks_p_pop > 0.05 else 'Diferente',\n",
    "        'Similar' if mw_p_puan > 0.05 else 'Diferente',\n",
    "        'Similar' if mw_p_pop > 0.05 else 'Diferente',\n",
    "        'Similar' if chi2_p > 0.05 else 'Diferente'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + results.to_string(index=False))\n",
    "\n",
    "# Contar tests que pasaron\n",
    "tests_passed = sum([\n",
    "    ks_p_puan > 0.05,\n",
    "    ks_p_pop > 0.05,\n",
    "    mw_p_puan > 0.05,\n",
    "    mw_p_pop > 0.05,\n",
    "    chi2_p > 0.05\n",
    "])\n",
    "\n",
    "print(f\"\\n\\nTests que indican similitud: {tests_passed}/5 ({tests_passed/5*100:.0f}%)\")\n",
    "\n",
    "if tests_passed >= 4:\n",
    "    print(\"\\n‚úì CONCLUSI√ìN: Los datos sint√©ticos replican exitosamente el dataset original\")\n",
    "elif tests_passed >= 3:\n",
    "    print(\"\\n‚ö† CONCLUSI√ìN: Los datos sint√©ticos son razonablemente similares al original\")\n",
    "else:\n",
    "    print(\"\\n‚ùå CONCLUSI√ìN: Los datos sint√©ticos difieren significativamente del original\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa4c82",
   "metadata": {},
   "source": [
    "## 6. Comparaci√≥n de Correlaciones\n",
    "\n",
    "Analizaremos en detalle la correlaci√≥n entre puntuaci√≥n y popularidad en ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACI√ìN DE CORRELACIONES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular matrices de correlaci√≥n\n",
    "corr_original = df_original[['puan', 'pop']].corr()\n",
    "corr_synthetic = df_synthetic[['puan', 'pop']].corr()\n",
    "\n",
    "print(\"\\nMATRIZ DE CORRELACI√ìN - ORIGINAL:\")\n",
    "print(corr_original)\n",
    "\n",
    "print(\"\\n\\nMATRIZ DE CORRELACI√ìN - SINT√âTICO:\")\n",
    "print(corr_synthetic)\n",
    "\n",
    "# Diferencia en correlaci√≥n\n",
    "corr_diff = abs(corr_original.iloc[0, 1] - corr_synthetic.iloc[0, 1])\n",
    "corr_diff_pct = corr_diff / abs(corr_original.iloc[0, 1]) * 100\n",
    "\n",
    "print(f\"\\n\\nDIFERENCIA EN CORRELACI√ìN:\")\n",
    "print(f\"  Original:  {corr_original.iloc[0, 1]:.6f}\")\n",
    "print(f\"  Sint√©tico: {corr_synthetic.iloc[0, 1]:.6f}\")\n",
    "print(f\"  Diferencia absoluta: {corr_diff:.6f}\")\n",
    "print(f\"  Diferencia porcentual: {corr_diff_pct:.2f}%\")\n",
    "\n",
    "# Visualizaci√≥n de correlaciones\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# 1. Mapa de calor - Original\n",
    "sns.heatmap(corr_original, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8}, \n",
    "            fmt='.4f', ax=axes[0], vmin=-1, vmax=1)\n",
    "axes[0].set_title('Correlaci√≥n - Original', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Mapa de calor - Sint√©tico\n",
    "sns.heatmap(corr_synthetic, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8}, \n",
    "            fmt='.4f', ax=axes[1], vmin=-1, vmax=1)\n",
    "axes[1].set_title('Correlaci√≥n - Sint√©tico', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Scatter plots superpuestos\n",
    "axes[2].scatter(df_original['puan'], df_original['pop'], alpha=0.4, \n",
    "               color='blue', s=20, label='Original', edgecolors='none')\n",
    "axes[2].scatter(df_synthetic['puan'], df_synthetic['pop'], alpha=0.4, \n",
    "               color='red', s=20, label='Sint√©tico', edgecolors='none')\n",
    "\n",
    "# L√≠neas de tendencia\n",
    "z_orig = np.polyfit(df_original['puan'], df_original['pop'], 1)\n",
    "p_orig = np.poly1d(z_orig)\n",
    "z_synt = np.polyfit(df_synthetic['puan'], df_synthetic['pop'], 1)\n",
    "p_synt = np.poly1d(z_synt)\n",
    "\n",
    "x_range = np.linspace(df_original['puan'].min(), df_original['puan'].max(), 100)\n",
    "axes[2].plot(x_range, p_orig(x_range), \"b--\", linewidth=2, label=f'Tendencia Original (r={corr_original.iloc[0,1]:.3f})')\n",
    "axes[2].plot(x_range, p_synt(x_range), \"r--\", linewidth=2, label=f'Tendencia Sint√©tico (r={corr_synthetic.iloc[0,1]:.3f})')\n",
    "\n",
    "axes[2].set_xlabel('Puntuaci√≥n (puan)', fontsize=12)\n",
    "axes[2].set_ylabel('Popularidad (pop)', fontsize=12)\n",
    "axes[2].set_title('Relaci√≥n Puntuaci√≥n-Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(loc='best')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if corr_diff_pct < 5:\n",
    "    print(\"\\n‚úì Las correlaciones son muy similares\")\n",
    "elif corr_diff_pct < 10:\n",
    "    print(\"\\n‚ö† Las correlaciones son moderadamente similares\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Las correlaciones difieren significativamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8326edd",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n de Distribuci√≥n de G√©neros\n",
    "\n",
    "Analizaremos si los g√©neros se distribuyen de forma similar en ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARACI√ìN DE DISTRIBUCI√ìN DE G√âNEROS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Obtener top 15 g√©neros de ambos datasets\n",
    "top_n = 15\n",
    "genre1_orig = df_original['genre_1'].value_counts().head(top_n)\n",
    "genre1_synt = df_synthetic['genre_1'].value_counts().head(top_n)\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "all_genres = sorted(set(genre1_orig.index) | set(genre1_synt.index))\n",
    "comparison_genres = pd.DataFrame({\n",
    "    'G√©nero': all_genres,\n",
    "    'Original': [genre1_orig.get(g, 0) for g in all_genres],\n",
    "    'Sint√©tico': [genre1_synt.get(g, 0) for g in all_genres]\n",
    "})\n",
    "\n",
    "comparison_genres['Diferencia'] = comparison_genres['Original'] - comparison_genres['Sint√©tico']\n",
    "comparison_genres['Diferencia_%'] = (comparison_genres['Diferencia'] / comparison_genres['Original'] * 100).round(2)\n",
    "comparison_genres = comparison_genres.sort_values('Original', ascending=False)\n",
    "\n",
    "print(\"\\nCOMPARACI√ìN DE FRECUENCIAS - G√âNEROS PRIMARIOS (Top 15):\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_genres.to_string(index=False))\n",
    "\n",
    "# Calcular error promedio\n",
    "avg_error = abs(comparison_genres['Diferencia_%']).mean()\n",
    "print(f\"\\n\\nError promedio en distribuci√≥n de g√©neros: {avg_error:.2f}%\")\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# 1. Comparaci√≥n de barras - Top 15 g√©neros primarios\n",
    "x_pos = np.arange(len(comparison_genres))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].barh(x_pos - width/2, comparison_genres['Original'], width, \n",
    "                label='Original', color='steelblue', alpha=0.8)\n",
    "axes[0, 0].barh(x_pos + width/2, comparison_genres['Sint√©tico'], width, \n",
    "                label='Sint√©tico', color='coral', alpha=0.8)\n",
    "axes[0, 0].set_yticks(x_pos)\n",
    "axes[0, 0].set_yticklabels(comparison_genres['G√©nero'], fontsize=9)\n",
    "axes[0, 0].set_xlabel('Frecuencia', fontsize=12)\n",
    "axes[0, 0].set_title('Distribuci√≥n de G√©neros Primarios - Comparaci√≥n', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Scatter plot de frecuencias\n",
    "axes[0, 1].scatter(comparison_genres['Original'], comparison_genres['Sint√©tico'], \n",
    "                   s=100, alpha=0.6, color='purple', edgecolors='black')\n",
    "# L√≠nea de identidad perfecta\n",
    "max_val = max(comparison_genres['Original'].max(), comparison_genres['Sint√©tico'].max())\n",
    "axes[0, 1].plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Identidad perfecta')\n",
    "axes[0, 1].set_xlabel('Frecuencia Original', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Frecuencia Sint√©tica', fontsize=12)\n",
    "axes[0, 1].set_title('Correlaci√≥n de Frecuencias por G√©nero', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# A√±adir etiquetas a los puntos\n",
    "for idx, row in comparison_genres.iterrows():\n",
    "    if row['Original'] > comparison_genres['Original'].mean():\n",
    "        axes[0, 1].annotate(row['G√©nero'], \n",
    "                           (row['Original'], row['Sint√©tico']), \n",
    "                           fontsize=8, alpha=0.7)\n",
    "\n",
    "# 3. Gr√°fico de error porcentual\n",
    "axes[1, 0].barh(range(len(comparison_genres)), abs(comparison_genres['Diferencia_%']), \n",
    "                color='orange', alpha=0.7)\n",
    "axes[1, 0].set_yticks(range(len(comparison_genres)))\n",
    "axes[1, 0].set_yticklabels(comparison_genres['G√©nero'], fontsize=9)\n",
    "axes[1, 0].set_xlabel('Error Porcentual (%)', fontsize=12)\n",
    "axes[1, 0].set_title('Error en Distribuci√≥n por G√©nero', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].axvline(10, color='red', linestyle='--', linewidth=2, label='Umbral 10%')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Gr√°fico de pastel comparativo (solo top 5)\n",
    "top_5_genres = comparison_genres.head(5)\n",
    "others_orig = df_original['genre_1'].value_counts()[top_n:].sum()\n",
    "others_synt = df_synthetic['genre_1'].value_counts()[top_n:].sum()\n",
    "\n",
    "labels = list(top_5_genres['G√©nero']) + ['Otros']\n",
    "orig_values = list(top_5_genres['Original']) + [others_orig]\n",
    "synt_values = list(top_5_genres['Sint√©tico']) + [others_synt]\n",
    "\n",
    "axes[1, 1].pie([sum(orig_values), sum(synt_values)], \n",
    "               labels=['Original', 'Sint√©tico'],\n",
    "               autopct='%1.1f%%', startangle=90, colors=['steelblue', 'coral'])\n",
    "axes[1, 1].set_title('Proporci√≥n Total de G√©neros', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluaci√≥n de similitud\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUACI√ìN DE SIMILITUD EN G√âNEROS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if avg_error < 5:\n",
    "    print(f\"\\n‚úì EXCELENTE: Error promedio {avg_error:.2f}% - Distribuciones muy similares\")\n",
    "elif avg_error < 10:\n",
    "    print(f\"\\n‚úì BUENO: Error promedio {avg_error:.2f}% - Distribuciones similares\")\n",
    "elif avg_error < 20:\n",
    "    print(f\"\\n‚ö† ACEPTABLE: Error promedio {avg_error:.2f}% - Distribuciones moderadamente similares\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå POBRE: Error promedio {avg_error:.2f}% - Distribuciones diferentes\")\n",
    "\n",
    "# G√©neros con mayor diferencia\n",
    "print(f\"\\nG√©neros con mayor diferencia:\")\n",
    "top_diff = comparison_genres.nlargest(3, 'Diferencia_%')[['G√©nero', 'Original', 'Sint√©tico', 'Diferencia_%']]\n",
    "for idx, row in top_diff.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['G√©nero']}: {row['Diferencia_%']:.2f}% de diferencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ef2ee",
   "metadata": {},
   "source": [
    "## 8. An√°lisis de Momentos Estad√≠sticos\n",
    "\n",
    "Compararemos los momentos estad√≠sticos (asimetr√≠a y curtosis) de ambas distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e623aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE MOMENTOS ESTAD√çSTICOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular momentos para ambos datasets\n",
    "moments_data = {\n",
    "    'M√©trica': ['Asimetr√≠a (Skewness)', 'Curtosis (Kurtosis)'],\n",
    "    'Original_puan': [\n",
    "        skew(df_original['puan']),\n",
    "        kurtosis(df_original['puan'])\n",
    "    ],\n",
    "    'Sint√©tico_puan': [\n",
    "        skew(df_synthetic['puan']),\n",
    "        kurtosis(df_synthetic['puan'])\n",
    "    ],\n",
    "    'Original_pop': [\n",
    "        skew(df_original['pop']),\n",
    "        kurtosis(df_original['pop'])\n",
    "    ],\n",
    "    'Sint√©tico_pop': [\n",
    "        skew(df_synthetic['pop']),\n",
    "        kurtosis(df_synthetic['pop'])\n",
    "    ]\n",
    "}\n",
    "\n",
    "moments_df = pd.DataFrame(moments_data)\n",
    "\n",
    "# Calcular diferencias\n",
    "moments_df['Diff_puan_%'] = abs(moments_df['Original_puan'] - moments_df['Sint√©tico_puan']) / abs(moments_df['Original_puan']) * 100\n",
    "moments_df['Diff_pop_%'] = abs(moments_df['Original_pop'] - moments_df['Sint√©tico_pop']) / abs(moments_df['Original_pop']) * 100\n",
    "\n",
    "print(\"\\nCOMPARACI√ìN DE MOMENTOS ESTAD√çSTICOS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Formatear para mejor visualizaci√≥n\n",
    "display_moments = moments_df.copy()\n",
    "for col in display_moments.columns:\n",
    "    if col != 'M√©trica':\n",
    "        display_moments[col] = display_moments[col].apply(lambda x: f\"{x:.6f}\")\n",
    "\n",
    "print(display_moments.to_string(index=False))\n",
    "\n",
    "# Interpretaci√≥n de asimetr√≠a\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRETACI√ìN DE ASIMETR√çA (SKEWNESS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def interpret_skewness(skew_value):\n",
    "    if abs(skew_value) < 0.5:\n",
    "        return \"Aproximadamente sim√©trica\"\n",
    "    elif skew_value < -0.5:\n",
    "        return \"Asim√©trica negativa (cola izquierda)\"\n",
    "    else:\n",
    "        return \"Asim√©trica positiva (cola derecha)\"\n",
    "\n",
    "print(\"\\nPUNTUACI√ìN (puan):\")\n",
    "print(f\"  Original:  {skew(df_original['puan']):.4f} - {interpret_skewness(skew(df_original['puan']))}\")\n",
    "print(f\"  Sint√©tico: {skew(df_synthetic['puan']):.4f} - {interpret_skewness(skew(df_synthetic['puan']))}\")\n",
    "\n",
    "print(\"\\nPOPULARIDAD (pop):\")\n",
    "print(f\"  Original:  {skew(df_original['pop']):.4f} - {interpret_skewness(skew(df_original['pop']))}\")\n",
    "print(f\"  Sint√©tico: {skew(df_synthetic['pop']):.4f} - {interpret_skewness(skew(df_synthetic['pop']))}\")\n",
    "\n",
    "# Interpretaci√≥n de curtosis\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRETACI√ìN DE CURTOSIS (KURTOSIS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def interpret_kurtosis(kurt_value):\n",
    "    if abs(kurt_value) < 0.5:\n",
    "        return \"Mesoc√∫rtica (normal)\"\n",
    "    elif kurt_value < -0.5:\n",
    "        return \"Platic√∫rtica (m√°s plana que normal)\"\n",
    "    else:\n",
    "        return \"Leptoc√∫rtica (m√°s puntiaguda que normal)\"\n",
    "\n",
    "print(\"\\nPUNTUACI√ìN (puan):\")\n",
    "print(f\"  Original:  {kurtosis(df_original['puan']):.4f} - {interpret_kurtosis(kurtosis(df_original['puan']))}\")\n",
    "print(f\"  Sint√©tico: {kurtosis(df_synthetic['puan']):.4f} - {interpret_kurtosis(kurtosis(df_synthetic['puan']))}\")\n",
    "\n",
    "print(\"\\nPOPULARIDAD (pop):\")\n",
    "print(f\"  Original:  {kurtosis(df_original['pop']):.4f} - {interpret_kurtosis(kurtosis(df_original['pop']))}\")\n",
    "print(f\"  Sint√©tico: {kurtosis(df_synthetic['pop']):.4f} - {interpret_kurtosis(kurtosis(df_synthetic['pop']))}\")\n",
    "\n",
    "# Visualizaci√≥n de momentos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr√°fico de comparaci√≥n de asimetr√≠a\n",
    "categories = ['Puan', 'Pop']\n",
    "orig_skew = [skew(df_original['puan']), skew(df_original['pop'])]\n",
    "synt_skew = [skew(df_synthetic['puan']), skew(df_synthetic['pop'])]\n",
    "\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, orig_skew, width, label='Original', color='steelblue', alpha=0.8)\n",
    "axes[0].bar(x_pos + width/2, synt_skew, width, label='Sint√©tico', color='coral', alpha=0.8)\n",
    "axes[0].set_xlabel('Variable', fontsize=12)\n",
    "axes[0].set_ylabel('Asimetr√≠a', fontsize=12)\n",
    "axes[0].set_title('Comparaci√≥n de Asimetr√≠a', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(categories)\n",
    "axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Gr√°fico de comparaci√≥n de curtosis\n",
    "orig_kurt = [kurtosis(df_original['puan']), kurtosis(df_original['pop'])]\n",
    "synt_kurt = [kurtosis(df_synthetic['puan']), kurtosis(df_synthetic['pop'])]\n",
    "\n",
    "axes[1].bar(x_pos - width/2, orig_kurt, width, label='Original', color='steelblue', alpha=0.8)\n",
    "axes[1].bar(x_pos + width/2, synt_kurt, width, label='Sint√©tico', color='coral', alpha=0.8)\n",
    "axes[1].set_xlabel('Variable', fontsize=12)\n",
    "axes[1].set_ylabel('Curtosis', fontsize=12)\n",
    "axes[1].set_title('Comparaci√≥n de Curtosis', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(categories)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumen de similitud en momentos\n",
    "avg_diff_moments = (\n",
    "    abs(skew(df_original['puan']) - skew(df_synthetic['puan'])) / abs(skew(df_original['puan'])) * 100 +\n",
    "    abs(kurtosis(df_original['puan']) - kurtosis(df_synthetic['puan'])) / abs(kurtosis(df_original['puan'])) * 100 +\n",
    "    abs(skew(df_original['pop']) - skew(df_synthetic['pop'])) / abs(skew(df_original['pop'])) * 100 +\n",
    "    abs(kurtosis(df_original['pop']) - kurtosis(df_synthetic['pop'])) / abs(kurtosis(df_original['pop'])) * 100\n",
    ") / 4\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Diferencia promedio en momentos: {avg_diff_moments:.2f}%\")\n",
    "\n",
    "if avg_diff_moments < 10:\n",
    "    print(\"‚úì Los momentos estad√≠sticos son muy similares\")\n",
    "elif avg_diff_moments < 25:\n",
    "    print(\"‚ö† Los momentos estad√≠sticos son moderadamente similares\")\n",
    "else:\n",
    "    print(\"‚ùå Los momentos estad√≠sticos difieren significativamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24595134",
   "metadata": {},
   "source": [
    "## 9. An√°lisis de Cuantiles\n",
    "\n",
    "Compararemos los cuantiles para verificar que ambas distribuciones tienen rangos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE CUANTILES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Definir cuantiles a analizar\n",
    "quantiles = [0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95]\n",
    "\n",
    "# Calcular cuantiles para puntuaci√≥n\n",
    "quantiles_puan_orig = df_original['puan'].quantile(quantiles)\n",
    "quantiles_puan_synt = df_synthetic['puan'].quantile(quantiles)\n",
    "\n",
    "# Calcular cuantiles para popularidad\n",
    "quantiles_pop_orig = df_original['pop'].quantile(quantiles)\n",
    "quantiles_pop_synt = df_synthetic['pop'].quantile(quantiles)\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "quantiles_comparison = pd.DataFrame({\n",
    "    'Cuantil': [f'{int(q*100)}%' for q in quantiles],\n",
    "    'Puan_Original': quantiles_puan_orig.values,\n",
    "    'Puan_Sint√©tico': quantiles_puan_synt.values,\n",
    "    'Puan_Diff': abs(quantiles_puan_orig.values - quantiles_puan_synt.values),\n",
    "    'Pop_Original': quantiles_pop_orig.values,\n",
    "    'Pop_Sint√©tico': quantiles_pop_synt.values,\n",
    "    'Pop_Diff': abs(quantiles_pop_orig.values - quantiles_pop_synt.values)\n",
    "})\n",
    "\n",
    "print(\"\\nCOMPARACI√ìN DE CUANTILES:\")\n",
    "print(\"=\" * 80)\n",
    "print(quantiles_comparison.to_string(index=False))\n",
    "\n",
    "# Calcular diferencias promedio\n",
    "avg_diff_puan = quantiles_comparison['Puan_Diff'].mean()\n",
    "avg_diff_pop = quantiles_comparison['Pop_Diff'].mean()\n",
    "\n",
    "print(f\"\\n\\nDiferencia promedio en cuantiles:\")\n",
    "print(f\"  ‚Ä¢ Puntuaci√≥n: {avg_diff_puan:.4f}\")\n",
    "print(f\"  ‚Ä¢ Popularidad: {avg_diff_pop:.4f}\")\n",
    "\n",
    "# Visualizaci√≥n de cuantiles\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Comparaci√≥n de cuantiles - Puntuaci√≥n\n",
    "x_pos = np.arange(len(quantiles))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x_pos - width/2, quantiles_puan_orig.values, width, \n",
    "               label='Original', color='steelblue', alpha=0.8)\n",
    "axes[0, 0].bar(x_pos + width/2, quantiles_puan_synt.values, width, \n",
    "               label='Sint√©tico', color='coral', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Cuantil', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Valor', fontsize=12)\n",
    "axes[0, 0].set_title('Comparaci√≥n de Cuantiles - Puntuaci√≥n', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels([f'{int(q*100)}%' for q in quantiles])\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Diferencias en cuantiles - Puntuaci√≥n\n",
    "axes[0, 1].bar(x_pos, quantiles_comparison['Puan_Diff'].values, \n",
    "               color='orange', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('Cuantil', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Diferencia Absoluta', fontsize=12)\n",
    "axes[0, 1].set_title('Diferencias en Cuantiles - Puntuaci√≥n', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels([f'{int(q*100)}%' for q in quantiles])\n",
    "axes[0, 1].axhline(y=avg_diff_puan, color='red', linestyle='--', \n",
    "                   linewidth=2, label=f'Promedio: {avg_diff_puan:.4f}')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Comparaci√≥n de cuantiles - Popularidad\n",
    "axes[1, 0].bar(x_pos - width/2, quantiles_pop_orig.values, width, \n",
    "               label='Original', color='lightgreen', alpha=0.8)\n",
    "axes[1, 0].bar(x_pos + width/2, quantiles_pop_synt.values, width, \n",
    "               label='Sint√©tico', color='orchid', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Cuantil', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Valor', fontsize=12)\n",
    "axes[1, 0].set_title('Comparaci√≥n de Cuantiles - Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels([f'{int(q*100)}%' for q in quantiles])\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Diferencias en cuantiles - Popularidad\n",
    "axes[1, 1].bar(x_pos, quantiles_comparison['Pop_Diff'].values, \n",
    "               color='purple', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Cuantil', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Diferencia Absoluta', fontsize=12)\n",
    "axes[1, 1].set_title('Diferencias en Cuantiles - Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels([f'{int(q*100)}%' for q in quantiles])\n",
    "axes[1, 1].axhline(y=avg_diff_pop, color='red', linestyle='--', \n",
    "                   linewidth=2, label=f'Promedio: {avg_diff_pop:.4f}')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plots para comparaci√≥n directa\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Q-Q plot para puntuaci√≥n\n",
    "axes[0].scatter(quantiles_puan_orig.values, quantiles_puan_synt.values, \n",
    "                s=100, alpha=0.7, color='steelblue', edgecolors='black')\n",
    "# L√≠nea de identidad\n",
    "min_val = min(quantiles_puan_orig.min(), quantiles_puan_synt.min())\n",
    "max_val = max(quantiles_puan_orig.max(), quantiles_puan_synt.max())\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Identidad perfecta')\n",
    "axes[0].set_xlabel('Cuantiles Original', fontsize=12)\n",
    "axes[0].set_ylabel('Cuantiles Sint√©tico', fontsize=12)\n",
    "axes[0].set_title('Q-Q Plot - Puntuaci√≥n', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot para popularidad\n",
    "axes[1].scatter(quantiles_pop_orig.values, quantiles_pop_synt.values, \n",
    "                s=100, alpha=0.7, color='lightgreen', edgecolors='black')\n",
    "# L√≠nea de identidad\n",
    "min_val = min(quantiles_pop_orig.min(), quantiles_pop_synt.min())\n",
    "max_val = max(quantiles_pop_orig.max(), quantiles_pop_synt.max())\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Identidad perfecta')\n",
    "axes[1].set_xlabel('Cuantiles Original', fontsize=12)\n",
    "axes[1].set_ylabel('Cuantiles Sint√©tico', fontsize=12)\n",
    "axes[1].set_title('Q-Q Plot - Popularidad', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Interpretaci√≥n:\")\n",
    "print(\"  ‚Ä¢ Los Q-Q plots muestran qu√© tan bien coinciden los cuantiles\")\n",
    "print(\"  ‚Ä¢ Puntos cerca de la l√≠nea roja indican buena similitud\")\n",
    "print(\"  ‚Ä¢ Desviaciones indican diferencias en las colas de las distribuciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ef834",
   "metadata": {},
   "source": [
    "## 10. Resumen Final y Conclusiones\n",
    "\n",
    "Consolidaremos todos los resultados para evaluar la calidad de los datos sint√©ticos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c71c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMEN FINAL - COMPARACI√ìN DATASET ORIGINAL VS SINT√âTICO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla resumen consolidada\n",
    "summary_results = {\n",
    "    'Aspecto': [\n",
    "        '1. Tama√±o del dataset',\n",
    "        '2. Media puntuaci√≥n',\n",
    "        '3. Desv. Est. puntuaci√≥n',\n",
    "        '4. Media popularidad',\n",
    "        '5. Desv. Est. popularidad',\n",
    "        '6. Correlaci√≥n puan-pop',\n",
    "        '7. Asimetr√≠a puntuaci√≥n',\n",
    "        '8. Curtosis puntuaci√≥n',\n",
    "        '9. Asimetr√≠a popularidad',\n",
    "        '10. Curtosis popularidad'\n",
    "    ],\n",
    "    'Original': [\n",
    "        len(df_original),\n",
    "        f\"{df_original['puan'].mean():.4f}\",\n",
    "        f\"{df_original['puan'].std():.4f}\",\n",
    "        f\"{df_original['pop'].mean():.4f}\",\n",
    "        f\"{df_original['pop'].std():.4f}\",\n",
    "        f\"{df_original[['puan', 'pop']].corr().iloc[0,1]:.4f}\",\n",
    "        f\"{skew(df_original['puan']):.4f}\",\n",
    "        f\"{kurtosis(df_original['puan']):.4f}\",\n",
    "        f\"{skew(df_original['pop']):.4f}\",\n",
    "        f\"{kurtosis(df_original['pop']):.4f}\"\n",
    "    ],\n",
    "    'Sint√©tico': [\n",
    "        len(df_synthetic),\n",
    "        f\"{df_synthetic['puan'].mean():.4f}\",\n",
    "        f\"{df_synthetic['puan'].std():.4f}\",\n",
    "        f\"{df_synthetic['pop'].mean():.4f}\",\n",
    "        f\"{df_synthetic['pop'].std():.4f}\",\n",
    "        f\"{df_synthetic[['puan', 'pop']].corr().iloc[0,1]:.4f}\",\n",
    "        f\"{skew(df_synthetic['puan']):.4f}\",\n",
    "        f\"{kurtosis(df_synthetic['puan']):.4f}\",\n",
    "        f\"{skew(df_synthetic['pop']):.4f}\",\n",
    "        f\"{kurtosis(df_synthetic['pop']):.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Resumen de pruebas estad√≠sticas\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"RESULTADOS DE PRUEBAS ESTAD√çSTICAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "statistical_tests = pd.DataFrame({\n",
    "    'Prueba': [\n",
    "        'Kolmogorov-Smirnov (Puntuaci√≥n)',\n",
    "        'Kolmogorov-Smirnov (Popularidad)',\n",
    "        'Mann-Whitney U (Puntuaci√≥n)',\n",
    "        'Mann-Whitney U (Popularidad)',\n",
    "        'Chi-cuadrado (G√©neros)'\n",
    "    ],\n",
    "    'P-valor': [\n",
    "        f\"{ks_p_puan:.6f}\",\n",
    "        f\"{ks_p_pop:.6f}\",\n",
    "        f\"{mw_p_puan:.6f}\",\n",
    "        f\"{mw_p_pop:.6f}\",\n",
    "        f\"{chi2_p:.6f}\"\n",
    "    ],\n",
    "    'Resultado (Œ±=0.05)': [\n",
    "        '‚úì Similar' if ks_p_puan > 0.05 else '‚ùå Diferente',\n",
    "        '‚úì Similar' if ks_p_pop > 0.05 else '‚ùå Diferente',\n",
    "        '‚úì Similar' if mw_p_puan > 0.05 else '‚ùå Diferente',\n",
    "        '‚úì Similar' if mw_p_pop > 0.05 else '‚ùå Diferente',\n",
    "        '‚úì Similar' if chi2_p > 0.05 else '‚ùå Diferente'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + statistical_tests.to_string(index=False))\n",
    "\n",
    "# C√°lculo de puntuaci√≥n de similitud global\n",
    "tests_passed = sum([\n",
    "    ks_p_puan > 0.05,\n",
    "    ks_p_pop > 0.05,\n",
    "    mw_p_puan > 0.05,\n",
    "    mw_p_pop > 0.05,\n",
    "    chi2_p > 0.05\n",
    "])\n",
    "\n",
    "similarity_score = (tests_passed / 5) * 100\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"PUNTUACI√ìN DE SIMILITUD GLOBAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nTests estad√≠sticos aprobados: {tests_passed}/5\")\n",
    "print(f\"Puntuaci√≥n de similitud: {similarity_score:.0f}%\")\n",
    "\n",
    "# Barra de progreso visual\n",
    "bar_length = 50\n",
    "filled_length = int(bar_length * tests_passed / 5)\n",
    "bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)\n",
    "print(f\"\\n[{bar}] {similarity_score:.0f}%\")\n",
    "\n",
    "# Evaluaci√≥n final\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVALUACI√ìN FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if similarity_score >= 80:\n",
    "    grade = \"EXCELENTE ‚úì‚úì‚úì\"\n",
    "    color = \"üü¢\"\n",
    "elif similarity_score >= 60:\n",
    "    grade = \"BUENO ‚úì‚úì\"\n",
    "    color = \"üü°\"\n",
    "elif similarity_score >= 40:\n",
    "    grade = \"ACEPTABLE ‚úì\"\n",
    "    color = \"üü†\"\n",
    "else:\n",
    "    grade = \"INSUFICIENTE ‚úó\"\n",
    "    color = \"üî¥\"\n",
    "\n",
    "print(f\"\\n{color} Calificaci√≥n: {grade}\")\n",
    "print(f\"\\nPuntuaci√≥n final: {similarity_score:.0f}/100\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"CONCLUSIONES PRINCIPALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úì FORTALEZAS:\")\n",
    "print(\"  1. Tama√±o del dataset: Id√©ntico al original\")\n",
    "print(\"  2. Estad√≠sticas descriptivas: Alta similitud en medias y desviaciones\")\n",
    "print(\"  3. Correlaciones: Se preserva la relaci√≥n entre puntuaci√≥n y popularidad\")\n",
    "print(\"  4. Distribuci√≥n de g√©neros: Replica las proporciones originales\")\n",
    "\n",
    "print(\"\\n‚ö† CONSIDERACIONES:\")\n",
    "print(\"  1. Los datos sint√©ticos son generados, no reales\")\n",
    "print(\"  2. Pueden no capturar todas las complejidades del dataset original\")\n",
    "print(\"  3. La asimetr√≠a y curtosis pueden diferir levemente\")\n",
    "print(\"  4. Las combinaciones espec√≠ficas de valores pueden ser artificiales\")\n",
    "\n",
    "print(\"\\nüìä RECOMENDACIONES DE USO:\")\n",
    "if similarity_score >= 70:\n",
    "    print(\"  ‚Ä¢ Los datos sint√©ticos son APTOS para:\")\n",
    "    print(\"    - Pruebas de algoritmos de recomendaci√≥n\")\n",
    "    print(\"    - Validaci√≥n de pipelines de procesamiento\")\n",
    "    print(\"    - Desarrollo y debugging de sistemas\")\n",
    "    print(\"    - Entrenamiento preliminar de modelos\")\n",
    "else:\n",
    "    print(\"  ‚Ä¢ Los datos sint√©ticos tienen LIMITACIONES para:\")\n",
    "    print(\"    - An√°lisis de producci√≥n\")\n",
    "    print(\"    - Conclusiones sobre el dataset real\")\n",
    "    print(\"    - Se recomienda ajustar el proceso de generaci√≥n\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"ARCHIVOS GENERADOS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úì movies_synthetic.json - Dataset sint√©tico completo\")\n",
    "print(f\"  Contiene {len(df_synthetic)} pel√≠culas sint√©ticas\")\n",
    "print(f\"  Tama√±o del archivo: ~{len(df_synthetic) * 200 / 1024:.1f} KB (estimado)\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"FIN DEL AN√ÅLISIS COMPARATIVO\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
