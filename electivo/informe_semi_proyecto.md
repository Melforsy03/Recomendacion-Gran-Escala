# üé¨ Informe del Semi-Proyecto ‚Äî An√°lisis de Pel√≠culas con Big Data

## üß† Descripci√≥n del Proyecto

**Objetivo:**  
Procesar, analizar y visualizar informaci√≥n de un dataset de pel√≠culas utilizando tecnolog√≠as del ecosistema **Big Data (HDFS, YARN y Spark)**.  
El proyecto busca construir un pipeline completo que simule un flujo real de an√°lisis distribuido, incluyendo etapas de **ingesta, limpieza, procesamiento y an√°lisis** de datos a gran escala.

---

## üéûÔ∏è Dataset Seleccionado

**Nombre:** `movies.json`  
**Fuente:** Dataset simulado con informaci√≥n de pel√≠culas (nombre, puntuaci√≥n, g√©neros, popularidad, descripci√≥n).  
**Formato:** JSON (convertido a Parquet para procesamiento eficiente con Spark).

**Ejemplo de registro:**
```json
{
  "ID": 1,
  "name": "The Godfather",
  "puan": 9.2,
  "genre_1": "Crime",
  "genre_2": "Drama",
  "pop": 99,
  "description": "A timeless saga of a mafia family and their pursuit of power and loyalty."
}
```

---

## üìä Justificaci√≥n del Dataset

### Volumen  
El dataset puede escalarse f√°cilmente, permitiendo simular **vol√∫menes masivos de datos** al duplicar o combinar distintas fuentes.  
Su estructura uniforme lo hace ideal para probar rendimiento de Spark y almacenamiento distribuido en HDFS.

### Caracter√≠sticas  
- Campos heterog√©neos (num√©ricos, categ√≥ricos, texto).  
- Atributos derivados (niveles de popularidad, categor√≠as de rating).  
- Compatible con distintos formatos de almacenamiento (JSON, Parquet).  
- Permite an√°lisis de tipo **exploratorio y predictivo**.

### Pertinencia  
Permite aplicar el ciclo completo del procesamiento Big Data:
1. **Ingesta de datos** desde archivos JSON locales.  
2. **Carga y persistencia en HDFS.**  
3. **Procesamiento distribuido con Spark sobre YARN.**  
4. **An√°lisis exploratorio local y visualizaci√≥n de m√©tricas clave.**

---

## ‚öôÔ∏è Arquitectura Propuesta

### Tipo de enfoque:  
**H√≠brido (Batch + Streaming Simulado)**  
- **Batch:** procesamiento de grandes vol√∫menes con Spark sobre YARN.  
- **Streaming:** simulado en fases posteriores mediante Kafka (a integrar).

### Pipeline general

```
movies.json
   ‚îÇ
   ‚ñº
[movies_producer.py]
   ‚îú‚îÄ Carga dataset JSON
   ‚îú‚îÄ Verifica HDFS y YARN
   ‚îî‚îÄ Escribe datos crudos en HDFS (/user/movies/raw/)
   ‚îÇ
   ‚ñº
[movies_processor.py]
   ‚îú‚îÄ Limpieza y validaci√≥n
   ‚îú‚îÄ Creaci√≥n de columnas derivadas
   ‚îî‚îÄ Guarda datos procesados (/user/movies/processed/)
   ‚îÇ
   ‚ñº
[movie_analysis.py]
   ‚îú‚îÄ Carga desde HDFS (modo local)
   ‚îú‚îÄ Estad√≠sticas por g√©nero, rating y popularidad
   ‚îî‚îÄ Visualizaci√≥n de resultados en consola o dashboard
```

---

## üß© Componentes Principales

### 1Ô∏è‚É£ **Producer ‚Äî `movies_producer.py`**
- Carga `movies.json` con `SparkSession` en modo YARN.  
- Verifica servicios HDFS y YARN antes de ejecutar.  
- Escribe datos en HDFS tanto en formato **Parquet** como **JSON**.  
- Genera salida:  
  ```
  hdfs://localhost:9000/user/movies/raw/movies_dataset
  ```

### 2Ô∏è‚É£ **Processor ‚Äî `movies_processor.py`**
- Lee los datos crudos desde HDFS.  
- Aplica transformaciones:  
  - Filtra nulos y valores inv√°lidos.  
  - Genera columna `genres` como arreglo.  
  - Clasifica pel√≠culas seg√∫n **popularidad** (`Alta`, `Media`, `Baja`).  
  - Clasifica puntuaciones en categor√≠as (`Excelente`, `Muy Bueno`, etc.).  
- Escribe resultados en:
  ```
  hdfs://localhost:9000/user/movies/processed/cleaned_movies
  ```

### 3Ô∏è‚É£ **Analysis ‚Äî `movie_analysis.py`**
- Carga los datos procesados desde HDFS o ruta local.  
- Genera estad√≠sticas:
  - **Top 5 pel√≠culas mejor puntuadas.**
  - **Distribuci√≥n de g√©neros.**
  - **Promedios de popularidad y rating.**
- Visualiza en consola y puede exportarse a dashboards (Plotly o Streamlit).

---

## üß± Infraestructura

Los servicios fueron gestionados mediante scripts:

- `iniciar_servicios.sh` ‚Üí Levanta **HDFS**, **YARN**, y **Spark**.  
- `detener_servicios.sh` ‚Üí Detiene los servicios de Hadoop.  
- `configurar_spark.sh` ‚Üí Configura variables y paths del entorno Spark.  
- `ejecutar_proyecto.sh` ‚Üí Orquesta el pipeline completo (Producer ‚Üí Processor ‚Üí Analysis).

---

## üöÄ Avances Realizados

‚úÖ **Infraestructura operativa**:  
Configuraci√≥n funcional de HDFS, YARN y Spark con validaciones de conexi√≥n.  

‚úÖ **Carga inicial de dataset**:  
Subset cargado en HDFS mediante `movies_producer.py`.  

‚úÖ **Procesamiento distribuido**:  
`movies_processor.py` ejecutado correctamente sobre YARN.  

‚úÖ **Resultados procesados**:  
Datos transformados y guardados en `/user/movies/processed/cleaned_movies`.  

‚úÖ **Primer an√°lisis exploratorio**:  
Ejecuci√≥n de `movie_analysis.py` para obtener estad√≠sticas descriptivas y distribuciones.

---

## üìà Pr√≥ximos Pasos

- Integrar **Kafka** para recibir nuevos eventos de pel√≠culas en tiempo real.  
- Incorporar un **dashboard interactivo** (Streamlit o Dash).  
- Extender el dataset con metadatos adicionales (a√±o, pa√≠s, duraci√≥n, etc.).  
- Implementar consultas SQL distribuidas con **Spark SQL o Hive**.  

---

## üß© Conclusi√≥n

El semi-proyecto demuestra la integraci√≥n de tecnolog√≠as del ecosistema Hadoop:
- **Ingesta y almacenamiento distribuido (HDFS)**  
- **Procesamiento paralelo (Spark sobre YARN)**  
- **An√°lisis y visualizaci√≥n local**

Esta arquitectura es una base s√≥lida para escalar hacia un pipeline de an√°lisis **real-time** y **batch**, aplicable a entornos empresariales o acad√©micos.

---