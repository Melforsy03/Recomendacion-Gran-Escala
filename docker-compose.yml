networks:
  datapipeline:
    driver: bridge

services:
  # --- HDFS & YARN Cluster (Hadoop 3.2.1 with Java 8) ---
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=datapipeline
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_webhdfs_enabled=true
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./shared:/shared
    ports:
      - "9870:9870"
      - "9000:9000"
    networks:
      - datapipeline
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9870"]
      interval: 5s
      timeout: 5s
      retries: 20

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    hostname: datanode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_permissions_enabled=false
    volumes:
      - datanode_data:/hadoop/dfs/data
      - ./shared:/shared
    depends_on:
      - namenode
    networks:
      - datapipeline
    healthcheck:
      test: ["CMD", "test", "-d", "/hadoop/dfs/data"]
      interval: 5s
      timeout: 5s
      retries: 20

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    hostname: resourcemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_log___aggregation___enable=true
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031
      - YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle
      - YARN_CONF_yarn_nodemanager_resource_memory___mb=4096
      - YARN_CONF_yarn_scheduler_maximum___allocation___mb=4096
      - YARN_CONF_yarn_scheduler_minimum___allocation___mb=512
    volumes:
      - ./shared:/shared
    depends_on:
      - namenode
    ports:
      - "8088:8088"
      - "8032:8032"
    networks:
      - datapipeline
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8088/ws/v1/cluster/info"]
      interval: 5s
      timeout: 5s
      retries: 30

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    hostname: nodemanager
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_resourcemanager_address=resourcemanager:8032
      - YARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030
      - YARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031
      - YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle
      - YARN_CONF_yarn_nodemanager_resource_memory___mb=4096
      - YARN_CONF_yarn_nodemanager_resource_cpu___vcores=2
      - YARN_CONF_yarn_nodemanager_vmem___check___enabled=false
      - YARN_CONF_yarn_nodemanager_pmem___check___enabled=false
    volumes:
      - ./shared:/shared
    depends_on:
      - namenode
      - resourcemanager
    ports:
      - "8042:8042"
    networks:
      - datapipeline

  # --- Spark 3.4.1 with support for YARN and Kafka (using official Apache Spark image) ---
  spark-master:
    image: apache/spark:3.4.1
    container_name: spark-master
    hostname: spark-master
    user: root
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_WEBUI_PORT=8080
      - HADOOP_CONF_DIR=/opt/hadoop-conf
      - YARN_CONF_DIR=/opt/hadoop-conf
      - PATH=/opt/spark/bin:/opt/spark/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - PIP_DEFAULT_TIMEOUT=300
      - PIP_RETRIES=5
      - PYTHONWARNINGS=ignore:Unverified HTTPS request
    volumes:
      - ./shared:/opt/spark/work-dir
      - spark-ivy-cache:/root/.ivy2
      - ./hadoop-conf:/opt/hadoop-conf:ro
      - spark_master_data:/opt/spark/data
      - ./requirements.txt:/tmp/requirements.txt:ro
      - spark-pip-cache:/root/.cache/pip
      - spark-python-libs:/opt/spark-python-libs
      - ./fairscheduler.xml:/opt/spark/conf/fairscheduler.xml:ro
    ports:
      - "7077:7077"
      - "8080:8080"
      - "4040:4040"
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - datapipeline
    command: >
      bash -c "
      echo 'üîç Verificando dependencias de Python...' &&
      PYTHON_VERSION=$$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2) &&
      SITE_PACKAGES=/opt/spark-python-libs/lib/python$$PYTHON_VERSION/site-packages &&
      export PYTHONPATH=$$SITE_PACKAGES:$$PYTHONPATH &&
      mkdir -p $$SITE_PACKAGES &&
      if python3 -c 'import numpy, pandas, kafka' 2>/dev/null; then
        echo '‚úÖ Dependencias ya instaladas y funcionando'
      else
        echo 'üì¶ Instalando dependencias en volumen persistente...' &&
        MAX_ATTEMPTS=3 &&
        ATTEMPT=1 &&
        INSTALL_SUCCESS=false &&
        while [ $$ATTEMPT -le $$MAX_ATTEMPTS ] && [ \"$$INSTALL_SUCCESS\" = false ]; do
          echo \"üîÑ Intento $$ATTEMPT de $$MAX_ATTEMPTS...\" &&
          if pip install --no-warn-script-location --target=$$SITE_PACKAGES --trusted-host pypi.org --trusted-host files.pythonhosted.org -r /tmp/requirements.txt; then
            echo '‚úÖ Instalaci√≥n exitosa!' &&
            INSTALL_SUCCESS=true
          else
            echo \"‚ùå Intento $$ATTEMPT fall√≥\" &&
            if [ $$ATTEMPT -lt $$MAX_ATTEMPTS ]; then
              echo '‚è≥ Esperando 10 segundos antes de reintentar...' &&
              sleep 10
            fi &&
            ATTEMPT=$$((ATTEMPT + 1))
          fi
        done &&
        if [ \"$$INSTALL_SUCCESS\" = false ]; then
          echo '‚ö†Ô∏è Advertencia: No se pudieron instalar todas las dependencias de Python' &&
          echo 'El contenedor continuar√° ejecut√°ndose, pero puede haber funcionalidad limitada'
        fi
      fi &&
      echo 'üöÄ Iniciando Spark Master...' &&
      /opt/spark/sbin/start-master.sh && tail -f /dev/null
      "
    healthcheck:
      # Chequea que el proceso java de Spark Master est√© corriendo
      test: ["CMD-SHELL", "pgrep -f 'org.apache.spark.deploy.master.Master'"]
      interval: 5s
      timeout: 3s
      retries: 30

  spark-worker:
    image: apache/spark:3.4.1
    container_name: spark-worker
    hostname: spark-worker
    user: root
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=6
      - SPARK_WORKER_WEBUI_PORT=8081
      - HADOOP_CONF_DIR=/opt/hadoop-conf
      - YARN_CONF_DIR=/opt/hadoop-conf
      - PATH=/opt/spark/bin:/opt/spark/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - PIP_DEFAULT_TIMEOUT=300
      - PIP_RETRIES=5
      - PYTHONWARNINGS=ignore:Unverified HTTPS request
    volumes:
      - ./shared:/opt/spark/work-dir
      - spark-ivy-cache:/root/.ivy2
      - ./hadoop-conf:/opt/hadoop-conf:ro
      - spark_worker_data:/opt/spark/data
      - ./requirements.txt:/tmp/requirements.txt:ro
      - spark-pip-cache:/root/.cache/pip
      - spark-python-libs:/opt/spark-python-libs
      - ./fairscheduler.xml:/opt/spark/conf/fairscheduler.xml:ro
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    networks:
      - datapipeline
    command: >
      bash -c "
      echo '‚è≥ Esperando 30 segundos para evitar saturar la red...' &&
      sleep 30 &&
      echo 'üîç Verificando dependencias de Python...' &&
      PYTHON_VERSION=$$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1,2) &&
      SITE_PACKAGES=/opt/spark-python-libs/lib/python$$PYTHON_VERSION/site-packages &&
      export PYTHONPATH=$$SITE_PACKAGES:$$PYTHONPATH &&
      mkdir -p $$SITE_PACKAGES &&
      if python3 -c 'import numpy, pandas, kafka' 2>/dev/null; then
        echo '‚úÖ Dependencias ya instaladas y funcionando'
      else
        echo 'üì¶ Instalando dependencias en volumen persistente...' &&
        MAX_ATTEMPTS=3 &&
        ATTEMPT=1 &&
        INSTALL_SUCCESS=false &&
        while [ $$ATTEMPT -le $$MAX_ATTEMPTS ] && [ \"$$INSTALL_SUCCESS\" = false ]; do
          echo \"üîÑ Intento $$ATTEMPT de $$MAX_ATTEMPTS...\" &&
          if pip install --no-warn-script-location --target=$$SITE_PACKAGES --trusted-host pypi.org --trusted-host files.pythonhosted.org -r /tmp/requirements.txt; then
            echo '‚úÖ Instalaci√≥n exitosa!' &&
            INSTALL_SUCCESS=true
          else
            echo \"‚ùå Intento $$ATTEMPT fall√≥\" &&
            if [ $$ATTEMPT -lt $$MAX_ATTEMPTS ]; then
              echo '‚è≥ Esperando 10 segundos antes de reintentar...' &&
              sleep 10
            fi &&
            ATTEMPT=$$((ATTEMPT + 1))
          fi
        done &&
        if [ \"$$INSTALL_SUCCESS\" = false ]; then
          echo '‚ö†Ô∏è Advertencia: No se pudieron instalar todas las dependencias de Python' &&
          echo 'El contenedor continuar√° ejecut√°ndose, pero puede haber funcionalidad limitada'
        fi
      fi &&
      echo 'üöÄ Iniciando Spark Worker...' &&
      /opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null
      "

  # --- Kafka 3.5 Cluster (Java 8 compatible) ---

  # --- Kafka 3.5 Cluster (Java 8 compatible) ---
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - datapipeline

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    volumes:
      - kafka_data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      PATH: /usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/sbin:/bin
    depends_on:
      - zookeeper
    networks:
      - datapipeline

  # --- API para m√©tricas y dashboard en tiempo real ---
  api:
    build:
      context: ./movies/api
      dockerfile: Dockerfile
    container_name: recs-api
    hostname: api
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - METRICS_TOPIC=metrics
      - PYTHONPATH=/app:/app/src
    volumes:
      - ./movies/trained_models:/app/trained_models:ro
      - ./Dataset/movie.csv:/app/movies_metadata.csv:ro
      - ./movies/src:/app/movies/src:ro
      - ./movies/api/services:/app/services:ro
      - ./movies/api/routes:/app/routes:ro
    depends_on:
      - kafka
    ports:
      - "8000:8000"
    networks:
      - datapipeline
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/recommendations/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --- Dashboard Streamlit para visualizaci√≥n en tiempo real ---
  dashboard:
    build:
      context: ./movies/dashboard
      dockerfile: Dockerfile
    container_name: recs-dashboard
    hostname: dashboard
    environment:
      - API_BASE_URL=http://api:8000
    depends_on:
      - api
    ports:
      - "8501:8501"
    networks:
      - datapipeline
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  namenode_data:
  datanode_data:
  spark_master_data:
  spark_worker_data:
  zookeeper_data:
  zookeeper_log:
  kafka_data:
  spark-ivy-cache:
    driver: local
  spark-pip-cache:
    driver: local
  spark-python-libs:
    driver: local