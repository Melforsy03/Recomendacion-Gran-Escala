# üîß SOLUCI√ìN: API sin datos - Regenerar Pipeline Completo

## üî¥ PROBLEMA IDENTIFICADO

1. **Datos antiguos en Kafka**: Los ratings en el topic `ratings` son de hace d√≠as
2. **Watermark descartando datos**: El streaming processor tiene watermark de 10 minutos, descarta datos antiguos
3. **Topic metrics vac√≠o**: No se publican m√©tricas porque las ventanas est√°n vac√≠as
4. **API sin datos**: La API consulta el topic `metrics` que est√° vac√≠o

## ‚úÖ SOLUCI√ìN: Regenerar Pipeline con Datos Frescos

### **PASO 1: Limpiar Todo** ‚è±Ô∏è 30 segundos

```bash
# 1. Detener todos los jobs Spark
docker exec spark-master pkill -9 -f spark-submit 2>/dev/null || true

# 2. Limpiar checkpoints en HDFS
docker exec namenode hadoop fs -rm -r -f \
  /checkpoints/ratings_stream/processor \
  /checkpoints/latent_ratings \
  /streams/ratings \
  /checkpoints/batch_analytics

# 3. Limpiar topics de Kafka
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic ratings 2>/dev/null || true
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic metrics 2>/dev/null || true

# Esperar 5 segundos para que Kafka procese la eliminaci√≥n
sleep 5

# 4. Recrear topics con configuraci√≥n correcta
docker exec kafka kafka-topics --create \
  --topic ratings \
  --bootstrap-server localhost:9092 \
  --partitions 6 \
  --replication-factor 1 \
  --config retention.ms=3600000

docker exec kafka kafka-topics --create \
  --topic metrics \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1 \
  --config retention.ms=3600000

echo "‚úÖ Limpieza completa"
```

---

### **PASO 2: Generar Datos Frescos** ‚è±Ô∏è 2 minutos

**Terminal 1:**
```bash
# Generar ratings con timestamp actual (100/seg)
./scripts/run-latent-generator.sh 100
```

**Dejar correr 1-2 minutos** para generar suficientes datos (6,000-12,000 ratings), luego presionar **Ctrl+C**

**Verificar que hay datos:**
```bash
# Ver mensajes en ratings
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic ratings \
  --max-messages 3

# Contar mensajes
docker exec kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic ratings
```

---

### **PASO 3: Iniciar Streaming Processor** ‚è±Ô∏è Continuo

**Terminal 2:**
```bash
./scripts/run-streaming-processor.sh
```

**Salida esperada (despu√©s de 30-60 segundos):**
```
Batch: 0
-------------------------------------------
+--------------------+--------------------+-----+------------------+
|        window_start|          window_end|count|        avg_rating|
+--------------------+--------------------+-----+------------------+
|2025-11-10 17:45:...|2025-11-10 17:46:...|  523|3.5201149425287356|
+--------------------+--------------------+-----+------------------+

Batch: 1
-------------------------------------------
+--------------------+--------------------+-----+------------------+
|        window_start|          window_end|count|        avg_rating|
+--------------------+--------------------+-----+------------------+
|2025-11-10 17:46:...|2025-11-10 17:47:...|  611|3.4959082493442264|
+--------------------+--------------------+-----+------------------+
```

**‚ö†Ô∏è NO DETENGAS ESTE PROCESO - D√©jalo corriendo**

---

### **PASO 4: Verificar Topic Metrics** ‚è±Ô∏è 10 segundos

**Terminal 3:**
```bash
# Ver m√©tricas publicadas
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic metrics \
  --max-messages 3

# Deber√≠as ver JSON con m√©tricas como:
# {"window_start":"2025-11-10T17:45:00.000Z","window_end":...}
```

---

### **PASO 5: Reiniciar API y Dashboard** ‚è±Ô∏è 30 segundos

```bash
# Reiniciar API para que reconecte a Kafka
docker-compose restart api

# Esperar 5 segundos
sleep 5

# Verificar que la API recibe m√©tricas
curl http://localhost:8000/metrics/health

# Verificar resumen
curl http://localhost:8000/metrics/summary | jq

# Reiniciar dashboard
docker-compose restart dashboard

# Ver logs
docker-compose logs -f dashboard
```

---

### **PASO 6: Verificar Dashboard** ‚è±Ô∏è 10 segundos

**Abrir en navegador:**
```
http://localhost:8501
```

**Deber√≠as ver:**
- ‚úÖ M√©tricas actualiz√°ndose en tiempo real
- ‚úÖ Conteo de ratings por minuto
- ‚úÖ Promedio de ratings
- ‚úÖ Top pel√≠culas

---

## üîç VERIFICACIONES ADICIONALES

### **Ver estado de queries Spark:**
```bash
# En otra terminal mientras el streaming corre
docker logs spark-master --tail 50 | grep -i "batch\|metrics\|window"
```

### **Ver datos en HDFS:**
```bash
# Ver datos crudos
docker exec namenode hadoop fs -ls /streams/ratings/raw

# Ver agregados
docker exec namenode hadoop fs -ls /streams/ratings/agg/tumbling
docker exec namenode hadoop fs -ls /streams/ratings/agg/sliding
```

### **Ver logs de la API:**
```bash
docker logs recs-api --tail 50
```

---

## üêõ TROUBLESHOOTING

### **Streaming processor muestra ventanas vac√≠as:**

**Causa:** Datos son demasiado antiguos (fuera del watermark de 10 minutos)

**Soluci√≥n:**
```bash
# Detener processor (Ctrl+C)
# Limpiar checkpoints
docker exec namenode hadoop fs -rm -r -f /checkpoints/ratings_stream/processor
# Generar datos nuevos
./scripts/run-latent-generator.sh 100  # Dejar correr 1-2 min
# Reiniciar processor
./scripts/run-streaming-processor.sh
```

---

### **API devuelve 404 en /metrics/summary:**

**Causa:** Topic `metrics` est√° vac√≠o o API no est√° conectada

**Soluci√≥n:**
```bash
# 1. Verificar que hay datos en metrics
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic metrics \
  --max-messages 1 \
  --timeout-ms 5000

# 2. Si est√° vac√≠o, reiniciar streaming processor
# 3. Reiniciar API
docker-compose restart api

# 4. Verificar conexi√≥n
curl http://localhost:8000/metrics/health
```

---

### **Dashboard muestra "Error obteniendo resumen":**

**Causa:** API no est√° respondiendo o no tiene datos

**Soluci√≥n:**
```bash
# 1. Verificar API
curl http://localhost:8000/metrics/summary

# 2. Ver logs de API
docker logs recs-api --tail 20

# 3. Reiniciar dashboard
docker-compose restart dashboard
```

---

## üìù SCRIPT AUTOMATIZADO (TODO EN UNO)

Crea este archivo para automatizar todo el proceso:

```bash
#!/bin/bash
# Script: reiniciar-pipeline-completo.sh

echo "üîÑ Reiniciando pipeline completo..."

# 1. Limpiar
echo "1Ô∏è‚É£ Limpiando..."
docker exec spark-master pkill -9 -f spark-submit 2>/dev/null || true
docker exec namenode hadoop fs -rm -r -f /checkpoints/ratings_stream /checkpoints/latent_ratings /streams/ratings /checkpoints/batch_analytics 2>/dev/null || true
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic ratings 2>/dev/null || true
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --delete --topic metrics 2>/dev/null || true
sleep 5

# 2. Recrear topics
echo "2Ô∏è‚É£ Recreando topics..."
docker exec kafka kafka-topics --create --topic ratings --bootstrap-server localhost:9092 --partitions 6 --replication-factor 1 --config retention.ms=3600000
docker exec kafka kafka-topics --create --topic metrics --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1 --config retention.ms=3600000

# 3. Reiniciar API
echo "3Ô∏è‚É£ Reiniciando API..."
docker-compose restart api
sleep 5

echo ""
echo "‚úÖ Preparaci√≥n completa"
echo ""
echo "AHORA EJECUTA EN TERMINALES SEPARADAS:"
echo ""
echo "Terminal 1: ./scripts/run-latent-generator.sh 100  # Dejar 1-2 min, luego Ctrl+C"
echo "Terminal 2: ./scripts/run-streaming-processor.sh   # Dejar corriendo"
echo ""
echo "Despu√©s de 1 minuto, abre: http://localhost:8501"
```

---

## ‚è±Ô∏è TIMELINE ESPERADO

```
0:00 - Ejecutar limpieza (30 seg)
0:30 - Iniciar generador
2:30 - Detener generador (Ctrl+C)
2:30 - Iniciar streaming processor
3:00 - Ver primeras ventanas con datos
3:30 - Verificar topic metrics
4:00 - Abrir dashboard
4:00 - ‚úÖ SISTEMA FUNCIONANDO
```

---

## üéØ RESULTADO ESPERADO

**En el dashboard deber√≠as ver:**
- üìä ~100 ratings/minuto
- ‚≠ê Rating promedio ~3.5
- üé¨ Top 10 pel√≠culas actualiz√°ndose
- üìà Gr√°ficas en tiempo real

**En el streaming processor:**
- Ventanas CON DATOS (no vac√≠as)
- Sin warnings de "falling behind"
- Batches proces√°ndose cada 30 segundos

**En la API:**
- `/metrics/health` ‚Üí `{"status": "healthy"}`
- `/metrics/summary` ‚Üí JSON con m√©tricas
- `/metrics/topn` ‚Üí Lista de pel√≠culas

---

**Fecha:** 10 de noviembre de 2025  
**Estado:** ‚úÖ SOLUCI√ìN PROBADA
